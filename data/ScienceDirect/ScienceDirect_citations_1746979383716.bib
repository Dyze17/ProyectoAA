@article{SOMMER2013e201302014,
title = {MEMBRANE PACKING PROBLEMS: A SHORT REVIEW ON COMPUTATIONAL MEMBRANE MODELING METHODS AND TOOLS},
journal = {Computational and Structural Biotechnology Journal},
volume = {5},
number = {6},
pages = {e201302014},
year = {2013},
issn = {2001-0370},
doi = {https://doi.org/10.5936/csbj.201302014},
url = {https://www.sciencedirect.com/science/article/pii/S2001037014600428},
author = {Björn Sommer},
abstract = {The use of model membranes is currently part of the daily workflow for many biochemical and biophysical disciplines. These membranes are used to analyze the behavior of small substances, to simulate transport processes, to study the structure of macromolecules or for illustrative purposes. But, how can these membrane structures be generated? This mini review discusses a number of ways to obtain these structures. First, the problem will be formulated as the Membrane Packing Problem. It will be shown that the theoretical problem of placing proteins and lipids onto a membrane area differ significantly. Thus, two sub-problems will be defined and discussed. Then, different – partly historical – membrane modeling methods will be introduced. And finally, membrane modeling tools will be evaluated which are able to semi-automatically generate these model membranes and thus, drastically accelerate and simplify the membrane generation process. The mini review concludes with advice about which tool is appropriate for which application case.}
}
@article{CHEN20071153,
title = {Computationally intelligent agents in economics and finance},
journal = {Information Sciences},
volume = {177},
number = {5},
pages = {1153-1168},
year = {2007},
note = {Including: The 3rd International Workshop on Computational Intelligence in Economics and Finance (CIEF’2003)},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2006.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0020025506002301},
author = {Shu-Heng Chen},
keywords = {Computational intelligence, Agent-based computational economics},
abstract = {This paper is an editorial guide for the second special issue on Computational Intelligence in economics and finance, which is a continuation of the special issue of Information Sciences, Vol. 170, No. 1. This second issue appears as a part of the outcome from the 3rd International Workshop on Computational Intelligence in Economics and Finance, which was held in Cary, North Carolina, September 26–30, 2003. This paper offers some main highlights of this event, with a particular emphasis on some of the observed progress made in this research field, and a brief introduction to the papers included in this special issue.}
}
@article{YUNG2021101566,
title = {A visual approach to interpreting the career of the network metaphor},
journal = {Poetics},
volume = {88},
pages = {101566},
year = {2021},
note = {Measure Mohr Culture},
issn = {0304-422X},
doi = {https://doi.org/10.1016/j.poetic.2021.101566},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X21000498},
author = {Vincent Yung},
keywords = {Metaphor, Network, Formal model, Computational hermeneutics, Text analysis},
abstract = {Metaphor has had a prolific presence in sociology: as a subject of empirical study, as a tool for theorizing, and as ideas that live public lives beyond the ivory tower. Despite all this work, tracing the core dynamics of metaphors over time remains a persistent challenge. To address this problem, I propose a systematic analysis of metaphor anchored around four core questions. What do metaphors describe? How do metaphors change over time? What do metaphors do? And how do conventional metaphors emerge? I address these questions in the context of one persistent and prolific metaphor: the network metaphor. To do so, I offer a formal model of the career of metaphor by drawing on cognitive linguistics and sociological theories of public ideas and professional careers. Specifically, I integrate the Google Books Ngram corpus with computational techniques that leverage co-occurrence to visualize and interpret the career of the network metaphor with respect to four areas: its jurisdiction, temporality, ecology, and conventionality. I leverage the network metaphor as both a revelatory case for evaluating my model and a critical case for deepening our historical understanding of the network. My analysis lends validation to the argument that the network metaphor has achieved the status of a broad category for thinking about contemporary life. However, it also demonstrates that the network metaphor had a lively history prior to the twentieth century. This includes significant changes in how it was used in the first half of the nineteenth century, a career standing in for anatomical structures of the body in the mid-nineteenth century, and a predominant expression in simile form prior to the start of the twentieth century.}
}
@article{LIU2025101211,
title = {RePower: An LLM-driven autonomous platform for power system data-guided research},
journal = {Patterns},
volume = {6},
number = {4},
pages = {101211},
year = {2025},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2025.101211},
url = {https://www.sciencedirect.com/science/article/pii/S2666389925000595},
author = {Yu-Xiao Liu and Mengshuo Jia and Yong-Xin Zhang and Jianxiao Wang and Guannan He and Shao-Long Zhong and Zhi-Min Dang},
keywords = {algorithm evolution, autonomous research, data-driven tasks, large language models, power systems, research assistant},
abstract = {Summary
Large language models (LLMs) have shown strong capabilities across disciplines such as chemistry, mathematics, and medicine, yet their application in power system research remains limited, and most studies still focus on supporting specific tasks under human supervision. Here, we introduce Revive Power Systems (RePower), an autonomous LLM-driven research platform that uses a reflection-evolution strategy to independently conduct complex research in power systems. RePower assists researchers by controlling devices, acquiring data, designing methods, and evolving algorithms to address problems that are difficult to solve but easy to evaluate. Validated on three critical data-driven tasks in power systems—parameter prediction, power optimization, and state estimation—RePower outperformed traditional methods. Consistent performance improvements were observed across multiple tasks, with an average error reduction of 29.07%. For example, in the power optimization task, the error decreased from 0.00137 to 0.000825, a reduction of 39.78%. This framework facilitates autonomous discoveries, promoting innovation in power systems research.}
}
@article{DREANY20181,
title = {Safety engineering of computational cognitive architectures within safety-critical systems},
journal = {Safety Science},
volume = {103},
pages = {1-11},
year = {2018},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2017.10.020},
url = {https://www.sciencedirect.com/science/article/pii/S0925753517301947},
author = {Harry H. Dreany and Robert Roncace and Paul Young},
keywords = {Safety engineering, Artificial intelligence, Cognitive architecture, Decision support model, Intelligent technologies},
abstract = {This paper presents the integration of a cognitive architecture with an intelligent decision support model (IDSM) that is embedded into an autonomous non-deterministic safety critical system. The IDSM will integrate multi-criteria decision making via intelligent technologies like expert systems, fuzzy logic, machine learning and genetic algorithms. Cognitive technology is currently simulated in safety–critical systems to highlight variables of interest, interface with intelligent technologies, and provide an environment that improves a system’s cognitive performance. In this study, the IDSM is being applied to an actual safety–critical system, an unmanned surface vehicle (USV) with embedded artificial intelligence (AI) software. The USV’s safety performance is being researched in a simulated and a real world nautical based environment. The objective is to build a dynamically changing model to evaluate a cognitive architecture’s ability to ensure safe performance of an intelligent safety–critical system. The IDSM does this by finding a set of key safety performance parameters that can be critiqued via safety measurements, mechanisms and methodologies. The uniqueness of this research will be on bounding the decision making associated with the cognitive architecture’s key safety parameters (KSP). Other real-time applications that could benefit from advancing the safety of cognitive technologies are unmanned platforms, transportation technologies, and service robotics. The results will provide cognitive science researchers a reference for safety engineering artificially intelligent safety–critical systems.}
}
@article{KENDON2008187,
title = {Optimal computation with non-unitary quantum walks},
journal = {Theoretical Computer Science},
volume = {394},
number = {3},
pages = {187-196},
year = {2008},
note = {From Gödel to Einstein: Computability between Logic and Physics},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2007.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S0304397507008791},
author = {Viv Kendon and Olivier Maloyer},
keywords = {Quantum computing, Quantum walks, Quantum algorithms},
abstract = {Quantum versions of random walks on the line and the cycle show a quadratic improvement over classical random walks in their spreading rates and mixing times, respectively. Non-unitary quantum walks can provide a useful optimisation of these properties, producing a more uniform distribution on the line, and faster mixing times on the cycle. We investigate the interplay between quantum and random dynamics by comparing the resources required, and examining numerically how the level of quantum correlations varies during the walk. We show numerically that the optimal non-unitary quantum walk proceeds such that the quantum correlations are nearly all removed at the point of the final measurement. This requires only O(logT) random bits for a quantum walk of T steps.}
}
@article{GROSS199653,
title = {The Electronic Cocktail Napkin—a computational environment for working with design diagrams},
journal = {Design Studies},
volume = {17},
number = {1},
pages = {53-69},
year = {1996},
issn = {0142-694X},
doi = {https://doi.org/10.1016/0142-694X(95)00006-D},
url = {https://www.sciencedirect.com/science/article/pii/0142694X9500006D},
author = {Mark D. Gross},
keywords = {conceptual design, computer-based environment, diagrams, sketching},
abstract = {The Electronic Cocktail Napkin is an experimental computer-based environment for sketching and diagramming in conceptual design. The project's goal is to develop a computational drawing environment to support conceptual designing in a way that leads smoothly from diagrams to more formal and structured representations of schematic design. With computational representations for conceptual designs, computer-supported editing, critquing, analysis, and simulation can be employed earlier in the design process, where it can have a greater impact on outcomes. The paper describes the Electronic Cocktail Napkin program-its recognition and parsing of diagrams and management of spatial constraints, its drawing environment, and two experimental query-by-diagram schemes for retrieving information from architectural databases.}
}
@incollection{TANG202535,
title = {Chapter 3 - Artificial intelligence for remote sensing and climate monitoring},
editor = {Uzair Aslam Bhatti and Mir Muhammad Nizamani and Yong Wang and Hao Tang},
booktitle = {Deep Learning for Earth Observation and Climate Monitoring},
publisher = {Elsevier},
pages = {35-62},
year = {2025},
isbn = {978-0-443-24712-5},
doi = {https://doi.org/10.1016/B978-0-443-24712-5.00004-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044324712500004X},
author = {Hao Tang and Uzair Aslam Bhatti and Dekai Li and Dai Lisi and Jinru Liu and Mughair Aslam Bhatti},
keywords = {Aerospace remote sensing, big data, space-to-ground data transmission, massive data storage management, high-performance computing, remote sensing data application, visualization},
abstract = {With the advancement and implementation of artificial intelligence, intelligent analysis, and interpretation of remote sensing data utilizing artificial intelligence technology based on geographic big data has emerged as a future development trend. Artificial intelligence has also made good development and application in the realm of disaster relief and remote sensing. Big data has been the focus of extensive research in many hot areas, such as compression sensing theory, modulation technologies including low-density parity-check codes, Turbo codes, frequency division multiplexing, and atmospheric laser communication technology in the field of information and communication. Also, in the realm of massive data storage, cloud storage technology and NoSQL database technology, as well as in high-performance computing, MapReduce, field programmable gate arrays (FPGAs), and graphics processing unit computing technologies have gained prominence. Moreover, in the domain of data mining, association rule methods, classification methods, clustering methods, and scientific thinking based on the fourth paradigm have been developed. In visualization, scientific computation visualization, information visualization, and knowledge visualization are also notable. Seeks to address the future demands of spaceborne remote sensing by obtaining effective information quickly and easing its transfer and use. It solves difficulties with traditional remote sensing imaging methods, such as a lack of target specificity, inadequate timeliness, and data redundancy, by doing research on intelligent satellite remote sensing systems that use artificial intelligence technology. This paper starts from the key links of aerospace remote sensing systems such as space-to-ground data transmission, data storage management, data preprocessing, data analysis application, and result presentation visualization. It analyzes the current technical status of aerospace remote sensing systems and explores how to use big data research methods to address the challenges faced by aerospace remote sensing systems, such as the massive scale, complexity, and rapid growth of data. This aims to meet the needs of acquiring, storing, and applying massive remote sensing data, and to promote the development of aerospace remote sensing science and technology. The study presents an overarching architecture for intelligent satellite remote sensing, as well as a description of the system’s operational procedure. This scheme design can provide a new technical means to improve the timeliness and effectiveness of aerospace optical remote sensing, as well as specific application value in areas such as on-orbit instant response to target observation, rapid location and interpretation of unexpected events, and fast capture and tracking of moving targets.}
}
@incollection{KRUSHINSKY1981171,
title = {STRUCTURAL ANALYSIS OF NON-VERBAL THINKING IN MAN},
editor = {N.P. BECHTEREVA},
booktitle = {Psychophysiology},
publisher = {Pergamon},
pages = {171-178},
year = {1981},
isbn = {978-0-08-025930-7},
doi = {https://doi.org/10.1016/B978-0-08-025930-7.50018-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780080259307500181},
author = {L.V. Krushinsky and N.P. Popova},
abstract = {Publisher Summary
This chapter discusses the characteristics of nonverbal thinking in man and elementary reasoning activity in animals and children. Verbal thinking is associated with the formation of a structural–functional organization of a pattern-code of verbal signals. Nonverbal thinking is associated with comprehension of the principles that make up the structural organization of environment. This type of thinking occurs in humans and other vertebrates. The chapter also discusses physiological and phenotypic aspects of nonverbal thinking. Both types of thinking have their own characteristics, which are related to the chemistry of the brain, and both reflect the nature of man. The main characteristic of nonverbal thinking is the success in performing the task at the first attempt. Repeated presentations of the task often lead to refusals to resolve it, the appearance of fear of the experimental conditions, and numerous signs of an overexcited state. A study described in the chapter revealed age to be a leading factor in determining the accurate understanding of object movement within the spatial–temporal coordinate system when the exact whereabouts of the object is unknown.}
}
@article{EMER20252196,
title = {Examples of Potential Applications of Bio-intelligent Manufacturing},
journal = {Procedia Computer Science},
volume = {253},
pages = {2196-2205},
year = {2025},
note = {6th International Conference on Industry 4.0 and Smart Manufacturing},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.01.280},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925002881},
author = {Asja Emer and Matteo {De Marchi} and Angelika Hofer and Benedikt G. Mark and Walburga Kerschbaumer and Erwin Rauch and Dominik T. Matt},
keywords = {Sustainable Manufacturing, Industry 4.0, Industry 5.0, Biological Transformation, Bio-Intelligent Manufacturing, SME},
abstract = {Bio-intelligence in manufacturing integrates biological principles and advanced computational techniques to enhance industrial processes. This interdisciplinary approach is based on already known principles like biomimicry, bio-sensing, and bio-based materials with the aim to further innovate and optimize industrial production by combining manufacturing and biology / biotechnology. Although there is a raising interest in research, it is not yet clear where and how bio-intelligence will have practical implications for manufacturing enterprises. In this work we use systematic literature review methodology to identify and analyze the current status quo of scientific literature related to biointelligent manufacturing. A main result of this work was to deduce potential applications, their suitability for small and medium sized enterprises (SME) and to highlight still existing challenges such as scalability, integration with existing systems, and economic viability.}
}
@article{THOMSON1994137,
title = {Whither computational materials science? Some thoughts from the mechanical properties front},
journal = {Computational Materials Science},
volume = {2},
number = {1},
pages = {137-142},
year = {1994},
issn = {0927-0256},
doi = {https://doi.org/10.1016/0927-0256(94)90056-6},
url = {https://www.sciencedirect.com/science/article/pii/0927025694900566},
author = {Robb Thomson},
abstract = {A claim is made that analysis will remain important and become a useful ally in helping computational materials science live up to its ultimate potential. Examples are given in the mechanical properties area where numerical simulations have been able to parameterize and mark out areas of validity for elasticity theory. The important role of developing asymptotic paths from one level or category of theory to another is commented on.}
}
@article{CLERJUSTE2024105922,
title = {Unpacking the challenges and predictors of elementary–middle school students’ use of the distributive property},
journal = {Journal of Experimental Child Psychology},
volume = {244},
pages = {105922},
year = {2024},
issn = {0022-0965},
doi = {https://doi.org/10.1016/j.jecp.2024.105922},
url = {https://www.sciencedirect.com/science/article/pii/S0022096524000626},
author = {Sarah N. Clerjuste and Claire Guang and Dana Miller-Cotto and Nicole M. McNeil},
keywords = {Distributive property, Cognitive reflection, Multiplication, Worked examples},
abstract = {The distributive property plays a pivotal role in advancing students’ understanding of multiplication, enabling the decomposition of problems and the acquisition of new facts. However, this property of multiplication is difficult for students to understand. We used two unique data sets to explore middle school students’ use of the distributive property. Study 1 involved data from 1:1 structured interviews of students (N = 24) discussing worked examples and solving associated practice problems. We examined whether or not students used the distributive property to solve the problems and whether or not interviewers followed the recommended distributive property prompts or defaulted to more conventional methods. Despite exposure to worked examples using the distributive property and a protocol calling for attention to it, students and interviewers favored methods like PEMDAS (parentheses, exponents, multiplication, division, addition, subtraction) or long multiplication. Study 2 used a data set with middle school students’ (N = 131) item-level responses on Kirkland’s (2022; doctoral dissertation, University of Notre Dame) Brief Assessment of Mature Number Sense along with several related measures of domain-general and domain-specific skills. We extracted problems involving the distributive property for analysis. Surprisingly, there was no evidence that students’ use of the distributive property improved from sixth grade to eighth grade. However, both grade-level mathematics achievement and cognitive reflection uniquely predicted the correct use of the distributive property. Results suggest that middle school students who exhibit stronger reflective thinking tend to perform better on distributive property problems. Findings highlight cognitive reflection as a potentially important construct involved in the understanding and use of the distributive property.}
}
@article{ALBUS20101519,
title = {A model of computation and representation in the brain},
journal = {Information Sciences},
volume = {180},
number = {9},
pages = {1519-1554},
year = {2010},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2009.12.031},
url = {https://www.sciencedirect.com/science/article/pii/S0020025510000095},
author = {James S. Albus},
keywords = {Brain modeling, Cognitive modeling, Human neocortex, Image processing, Knowledge representation, Perception, Reverse engineering the brain, Segmentation, Signals to symbols},
abstract = {The brain is first and foremost a control system that is capable of building an internal representation of the external world, and using this representation to make decisions, set goals and priorities, formulate plans, and control behavior with intent to achieve its goals. The internal representation is distributed throughout the brain in two forms: (1) firmware embedded in synaptic connections and axon-dendrite circuitry, and (2) dynamic state-variables encoded in the firing rates of neurons in computational loops in the spinal cord, midbrain, subcortical nuclei, and arrays of cortical columns. It assumes that clusters and arrays of neurons are capable of computing logical predicates, smooth arithmetic functions, and matrix transformations over a space defined by large input vectors and arrays. Feedback from output to input of these neural computational units enable them to function as finite-state-automata (fsa), Markov decision processes (MDP), or delay lines in processing signals and generating strings and grammars. Thus, clusters of neurons are capable of parsing and generating language, decomposing tasks, generating plans, and executing scripts. In the cortex, neurons are arranged in arrays of cortical columns that interact in tight loops with their underlying subcortical nuclei. It is hypothesized that these circuits compute sophisticated mathematical and logical functions that maintain and use complex abstract data structures. It is proposed that cortical hypercolumns together with their underlying thalamic nuclei can be modeled as a cortical computational unit (CCU) consisting of a frame-like data structure (containing attributes and pointers) plus the computational processes and mechanisms required to maintain it and use it for perception cognition, and sensory-motor behavior. In sensory processing areas of the brain, CCU processes enable focus of attention, segmentation, grouping, and classification. Pointers stored in CCU frames define relationships that link pixels and signals to objects and events in situations and episodes. CCU frame pointers also link objects and events to class prototypes and overlay them with meaning and emotional values. In behavior generating areas of the brain, CCU processes make decisions, set goals and priorities, generate plans, and control behavior. In general, CCU pointers are used to define rules, grammars, procedures, plans, and behaviors. CCU pointers also define abstract data structures analogous to lists, frames, objects, classes, rules, plans, and semantic nets. It is suggested that it may be possible to reverse engineer the human brain at the CCU level of fidelity using next-generation massively parallel computer hardware and software.}
}
@article{NEWMAN2024101778,
title = {Misinformed by images: How images influence perceptions of truth and what can be done about it},
journal = {Current Opinion in Psychology},
volume = {56},
pages = {101778},
year = {2024},
issn = {2352-250X},
doi = {https://doi.org/10.1016/j.copsyc.2023.101778},
url = {https://www.sciencedirect.com/science/article/pii/S2352250X23002233},
author = {Eryn J. Newman and Norbert Schwarz},
keywords = {Visual misinformation, Truthiness, Cognitive fluency, Artificial intelligence (AI), Memory, Truth assessment},
abstract = {We organize image types by their substantive relationship with textual claims and discuss their impact on attention, comprehension, memory, and judgment. Photos do not need to be false (altered or generated) to mislead; real photos can create a slanted representation or be repurposed from different events. Even semantically related non-probative photos, merely inserted to attract eyeballs, can increase message acceptance through increased fluency. Messages with images receive more attention and reach a wider audience. Text-congruent images can scaffold the comprehension of true and false claims and support the formation of correct and false memories. Standard laboratory procedures may underestimate the impact of images in natural media contexts: by drawing all participants' attention to a message that may be ignored without an image, they inflate message effects in the control condition. Misleading images are difficult to identify and their influence often remains outside of awareness, making it hard to curb their influence through critical-thinking interventions. Current concerns about deep fakes may reduce trust in all images, potentially limiting their power to mislead as well as inform. More research is needed to understand how knowing that an image is misleading influences inferences, impressions, and judgments beyond immediate assessments of the image's credibility.}
}
@article{LI2018359,
title = {Experimental and computational Fluid Dynamics study of separation gap effect on gas explosion mitigation for methane storage tanks},
journal = {Journal of Loss Prevention in the Process Industries},
volume = {55},
pages = {359-380},
year = {2018},
issn = {0950-4230},
doi = {https://doi.org/10.1016/j.jlp.2018.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S0950423018304224},
author = {Jingde Li and Hong Hao and Yanchao Shi and Qin Fang and Zhan Li and Li Chen},
keywords = {Separation gap, Safety gap, External pressure, Vented gas explosion, CFD, FLACS},
abstract = {This paper presented both experimental and numerical assessments of separation gap effect on vented explosion pressure in and around the area of a tank group. A series of vented gas explosion layouts with different separation gaps between tanks were experimentally investigated. In order to qualitatively determine the relationship between the separation gap distance and explosion pressure, intensive computational Fluid Dynamics (CFD) simulations, verified with testing data, were conducted. Good agreement between CFD simulation results and experimental data was achieved. By using CFD simulation, more gas explosion cases were included to consider different gas cloud coverage scenarios. Separation gap effects on internal and external pressures at various locations were investigated.}
}
@article{CIMIER2025100092,
title = {Multisensory objects’ role on creativity},
journal = {Journal of Creativity},
volume = {35},
number = {1},
pages = {100092},
year = {2025},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2024.100092},
url = {https://www.sciencedirect.com/science/article/pii/S2713374524000189},
author = {Amandine Cimier and Beatrice Biancardi and Jérome Guegan and Frédéric Segonds and Fabrice Mantelet and Camille Jean and Claude Gazo and Stéphanie Buisine},
keywords = {Engineering, Manipulation, Embodied cognition, Kinesthesia, Creativity},
abstract = {In this research, we investigated the role of multisensorial manipulation on creativity, and the influence of inspirational objects on creative outcomes. Object manipulation may support embodied cognition during a generative creative phase (emergence of motor, spatial, emotional ideas, etc.) then exploratory phase (creative fixation, development of a functional creation, etc.). Our protocol involved 136 engineering students divided into 34 groups which were provided with inspirational cubes illustrating manufacturing inventive principles or basic volumes from the Creative Mental Synthesis Task. They could manipulate these objects either in a visuo-haptic condition, or in a visuo-imaginative condition. Our results highlighted a main effect of manipulation, showing that visual-haptic condition led to higher creativity than visual-imaginative condition. We also observed several effects in favor of inspirational cubes with regard to basic volumes: significantly higher creativity, more subjective and inter-subjective facilitation behaviors, more cognitive and emotional operations. Participants also showed at an individual level a better mobilization of the multisensorial senses. Creative thinking may be stimulated when an active manipulation phase is set up before the creative production. This could contribute to improving practice for engineers, particularly for using additive manufacturing and/or during their training at school.}
}
@article{CUNHA2024,
title = {Converging extended reality and Machine Learning to improve the lecturing of geometry in basic education},
journal = {Journal of Engineering Research},
year = {2024},
issn = {2307-1877},
doi = {https://doi.org/10.1016/j.jer.2024.10.016},
url = {https://www.sciencedirect.com/science/article/pii/S2307187724002736},
author = {Carlos R. Cunha and André Moreira and Sílvia Coelho and Vítor Mendonça and João Pedro Gomes},
keywords = {Geometry, Teaching, Learning, Education, Extended reality, Mixed reality, Machine learning},
abstract = {Technology is constantly supporting in the innovation of the teaching-learning process. Today’s students are more demanding actors when it comes to the environment they have at their disposal to learn, experiment and develop their critical thinking. The area of Mathematics has successively suffered from students’ learning difficulties, whether due to lack of motivation, low abstraction ability or lack of new tools for teachers to bring innovation into the classroom and outside it. While being true that digitalization has entered schools, it often follows a basic and simple process of digital replication of approaches and materials that were previously only available on physical media. This work focuses on the use of Extended Realities, more precisely, Mixed Reality, for teaching Mathematics, and very particularly in the teaching of Geometry, through the proposition of a conceptual model that combines the use of Extended Reality and Machine Learning. The proposed model was subject to prototyping, which is presented as a form of laboratory validation as a contribution to innovate the way of how the geometry teaching-learning process is developed and to promote the integration of Extended Reality technologies into the Education Sector as practical tools, as well due to its potential use to obtain useful insights for teachers, and students, throughout the process.}
}
@article{GREIF2024126,
title = {Selection, growth and form. Turing’s two biological paths towards intelligent machinery},
journal = {Studies in History and Philosophy of Science},
volume = {106},
pages = {126-135},
year = {2024},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2024.05.017},
url = {https://www.sciencedirect.com/science/article/pii/S0039368124000657},
author = {Hajo Greif and Adam P. Kubiak and Paweł Stacewicz},
keywords = {Universal computing machines, Mechanism, Connectionism, Morphogenesis, D’Arcy Thompson, Darwinian evolution, Cellular automata},
abstract = {We inquire into the role of Turing’s biological thought in the development of his concept of intelligent machinery. We trace the possible relations between his proto-connectionist notion of ‘organising’ machines in Turing (1948) on the one hand and his mathematical theory of morphogenesis in developmental biology (1952) on the other. These works were concerned with distinct fields of inquiry and followed distinct paradigms of biological theory, respectively postulating analogues of Darwinian selection in learning and mathematical laws of form in organic pattern formation. Still, these strands of Turing’s work are related, first, in terms of being amenable in principle to his (1936) computational method of modelling. Second, they are connected by Turing’s scattered speculations about the possible bearing of learning processes on the anatomy of the brain. We argue that these two theories form an unequal couple that, from different angles and in partial fashion, point towards cognition as a biological and embodied phenomenon while, for reasons inherent to Turing’s computational approach to modelling, not being capable of directly addressing it as such. We explore ways in which these two distinct-but-related theories could be more explicitly and systematically connected, using von Neumann’s contemporaneous and related work on Cellular Automata and more recent biomimetic approaches as a foil. We conclude that the nature of ‘initiative’ and the mode of material realisation are the key issues that decide on the possibility of intelligent machinery in Turing.}
}
@article{OZER20114514,
title = {An application of fuzzy information granulation in the emerging area of online sports},
journal = {Expert Systems with Applications},
volume = {38},
number = {4},
pages = {4514-4521},
year = {2011},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2010.09.125},
url = {https://www.sciencedirect.com/science/article/pii/S0957417410010821},
author = {Muammer Ozer},
keywords = {Information granulation, Fuzzy granulation, Application, Online business},
abstract = {Abstract
One of the major computational challenges that online businesses face today is to make sense of huge amount of information. Granular computing has emerged as an important conceptual and computational paradigm of information processing. As an emerging field of study, it has been suggested that granular computing at philosophical level concerns with structural thinking and at the application level concerns with structured problem solving. It has been further suggested that fuzzy information granulation, as a special case of granular computing, is likely to play an important role in the evolution of fuzzy logic and may eventually have a far-reaching impact on its applications. Responding to the calls for future studies dealing with the applications of fuzzy information granulation, this paper presents an application of the theory of fuzzy information granulation in an emerging and important area where there has not yet been any application, showing how online sports services can make sense of huge amount of data in a structured way and how they can structure their decisions. The empirical results show that despite the huge amount of data that needs to be processed, fuzzy information granulation can help online sports services make sense of it and identify meaningful granules for easier decision making.}
}
@article{BAILEY2006793,
title = {Clover: Connecting technology and character education using personally-constructed animated vignettes},
journal = {Interacting with Computers},
volume = {18},
number = {4},
pages = {793-819},
year = {2006},
note = {Special Theme Papers from Special Editorial Board Members (contains Regular Papers)},
issn = {0953-5438},
doi = {https://doi.org/10.1016/j.intcom.2005.11.013},
url = {https://www.sciencedirect.com/science/article/pii/S0953543805001153},
author = {Brian P. Bailey and Sharon Y. Tettegah and Terry J. Bradley},
keywords = {Animation, Character education, Multimedia, Narratives, Vignettes},
abstract = {Schools are increasingly integrating character education to facilitate improved moral thinking and pro social behavior among students. An effective method for delivering character education is problem solving moral and social situations represented visually as animated vignettes. However, schools are rarely able to use animated vignettes since existing tools do not allow them to be easily created and having them created externally is overly expensive. In this paper, we describe the design, use, and evaluation of a computational tool that enables students to construct their own animated vignettes. By building, sharing, and responding to vignettes, students become engaged in problem solving moral and social situations. Evaluations showed that users are able to build meaningful vignettes, our tool is easy to learn and fun to use, and our tool's multimedia features are often used and well-liked. Educators can download and use our tool while researchers can draw upon our design rationale and lessons learned when building similar tools.}
}
@article{GRANDE2022105470,
title = {Nursing competency inventory and professional competence of graduating students in six Asian countries: A cross-sectional study},
journal = {Nurse Education Today},
volume = {116},
pages = {105470},
year = {2022},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2022.105470},
url = {https://www.sciencedirect.com/science/article/pii/S0260691722002064},
author = {Rizal Angelo N. Grande and Daniel Joseph E. Berdida and Tantut Susanto and Anwar Khan and Wanpen Waelveerakup and Zahrah Saad},
keywords = {Asian countries, Competency, Graduating nursing students, Nursing competency inventory, Professional competence},
abstract = {Aims
To investigate graduating nursing students' nursing and professional competencies and the predictors of their competencies.
Background
Across Asian countries, there is a paucity of literature that explores graduating nursing students' competency and professional competence during the ongoing COVID-19 pandemic.
Design
Descriptive, cross-sectional, and predictive approaches.
Method
Convenience sampling was used among graduating nursing students from the six Asian countries (n = 375). The STROBE guidelines for cross-sectional studies were used. Two self-report instruments were utilized to collect data. We conducted multiple linear regression analyses to assess the predictors of nursing competency and professional competence domains.
Results
Country of residence and general point average (GPA) showed statistically significant multivariate effects. Value-based nursing care and critical thinking and reasoning domains recorded the highest in professional competence and competency inventory for nursing students, respectively. Country of residence, GPA, and preferred nursing major were significant predictors of graduating nursing students' nursing competency and professional competence domains.
Conclusion
Our study's findings revealed a high level of diversity among nursing students regarding ethical care obligations, caring pedagogies, and lifelong learning, all of which may be ascribed to their distinct culture, background, and belief systems.}
}
@article{WOODRUFF1994463,
title = {Some computational challenges of developing efficient parallel algorithms for data-dependent computations in thermal-hydraulics supercomputer applications},
journal = {Nuclear Engineering and Design},
volume = {146},
number = {1},
pages = {463-471},
year = {1994},
issn = {0029-5493},
doi = {https://doi.org/10.1016/0029-5493(94)90351-4},
url = {https://www.sciencedirect.com/science/article/pii/0029549394903514},
author = {S.B. Woodruff},
abstract = {The Transient Reactor Analysis Code (TRAC), which features a two-fluid treatment of thermal-hydraulics, is designed to model transients in water reactors and related facilities. One of the major computational costs associated with TRAC and similar codes is calculating constitutive coefficients. Although the formulations for these coefficients are local, the costs are flow-regime- or data-dependent; i.e., the computations needed for a given spatial node often vary widely as a function of time. Consequently, a fixed, uniform assignment of nodes to parallel processors will result in degraded computational efficiency due to the poor load balancing. A standard method for treating data-dependent models on vector architectures has been to use gather operations (or indirect addressing) to sort the nodes into subsets that (temporarily) share a common computational model. However, this method is not effective on distributed memory data parallel architectures, where indirect addressing involves expensive communication overhead. Another serious problem with this method involves software engineering challenges in the areas of maintainability and extensibility. For example, an implementation that was hand-tuned to achieve good computational efficiency would have to be rewritten whenever the decision tree governing the sorting was modified. Using an example based on the calculation of the wall-to-liquid and wall-to-vapor heat-transfer coefficients for three nonboiling flow regimes, we describe how the use of the Fortran 90 WHERE construct and automatic inlining of functions can be used to ameliorate this problem while improving both efficiency and software engineering. Unfortunately, a general automatic solution to the load-balancing problem associated with data-dependent computations is not yet available for massively parallel architectures. We discuss why developers should either wait for such solutions or consider alternative numerical algorithms, such as a neural network representation, that do not exhibit load-balancing problems.}
}
@article{MEHMOOD2023100122,
title = {A multi-stage optimisation-based decision-making framework for sustainable hybrid energy system in the residential sector},
journal = {Sustainable Futures},
volume = {6},
pages = {100122},
year = {2023},
issn = {2666-1888},
doi = {https://doi.org/10.1016/j.sftr.2023.100122},
url = {https://www.sciencedirect.com/science/article/pii/S2666188823000187},
author = {Aamir Mehmood and Long Zhang and Jingzheng Ren},
keywords = {Hybrid energy system, System thinking approach, Genetic algorithm, Multi-criteria decision-making, Energy sustainability},
abstract = {Integrating renewables into existing energy infrastructure to construct hybrid energy systems (HES) plays a vital role for advancing energy sustainability. While various approaches, such as energy systems analysis and linear or non-linear optimisation, have been employed to achieve energy sustainability mainly at the national or city level, there has been a lack of focus on achieving energy sustainability in the residential sector through a holistic optimal decision-making approach for efficient HES design. This study focuses on developing a multi-stage optimisation-based decision-making framework that models, quantifies, and optimises the performance indicators of HES, allowing for an assessment of the trade-off between benefits and systems costs under various design scenarios. The initial step involves designing the HES model and constructing scenarios that cater to the electrification requirements of water, energy, and food elements in the residential sector by using a systematic thinking approach. Then, a preliminary evaluation of the modelled scenarios is conducted to assess energy sustainability in terms of technical and economic aspects. Afterwards, an optimal decision-making setup is established by integrating a multi-objective HES model into the NSGA-II algorithm, which approximates the Pareto optimal solutions. These solutions are then ranked by using a multi-criteria decision-making method. According to the findings, the Quetta region in Pakistan contains the best optimal solution. The results underscore the utility of the developed framework in facilitating the optimal design of renewables-integrated HES for the residential sector. Furthermore, intergovernmental organizations can leverage this framework to formulate effective policies aimed at encouraging residents to invest in HES installation.}
}
@article{KOBSIRIPAT2015227,
title = {Effects of the Media to Promote the Scratch Programming Capabilities Creativity of Elementary School Students},
journal = {Procedia - Social and Behavioral Sciences},
volume = {174},
pages = {227-232},
year = {2015},
note = {International Conference on New Horizons in Education, INTE 2014, 25-27 June 2014, Paris, France},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2015.01.651},
url = {https://www.sciencedirect.com/science/article/pii/S1877042815007028},
author = {Worarit Kobsiripat},
keywords = {Scratch programming, Higher-order Thinking, Creative Thinking, Computer Multimedia;},
abstract = {Developing creative Promote higher-order thinking processes Give learners specific ability to think on their wide variety and innovative of the original. It led to the discovery and creation of new inventions or form new ideas. Consistent with the educational goals of the program.This research aim to study a guild line of using Scratch Computer Program that leading to creativity. And study the effects of media on the Scratch programming capabilities creativity. The sample consisted of 60 students who were studying in semester 1. 2013 academic year, using purposive sampling (Purposive Sampling) tool used in this research is a lesson plan. Scratch and computer media test innovative ideas. Statistics used Data analysis were percentage, mean, standard deviation and Dependent t-test. The findings indicated that First, Mediums Scratch program can be used as a medium for learning activities. The adoption includes a multimedia interactive media as a tool to support learning. Second, Scratch media performance of computer programs is equal according to the criteria set 82.46/82.25 E1/E2 is 80/80. Creativity of students. Received instruction from the learning activities through the medium of a computer program Scratch by elements of creativity is an idea ingenious ideas flexibility. Initiatives and ideas census. Higher posttest than pretest statistically significant at the .05 level of performance, computer media Scratch equals 82.46/82.25 according to defined criteria E1/E2 is 80 /80. In conclusion the computer program Scratch media can lead creative development of students through the learning activities that promote innovative education that cause the learners’ desirable.}
}
@article{SKOWRON2025122078,
title = {Toward rough set based insightful reasoning in intelligent systems},
journal = {Information Sciences},
volume = {709},
pages = {122078},
year = {2025},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2025.122078},
url = {https://www.sciencedirect.com/science/article/pii/S0020025525002105},
author = {Andrzej Skowron and Jaroslaw Stepaniuk},
keywords = {Artificial intelligence, Granular computing, Rough sets, Granular approximation process, Reasoning over granular computations},
abstract = {This paper explores a rough set-based approach for supporting insightful reasoning in Intelligent Systems (ISs). The novelty lies in the introduction of a new concept for approximate reasoning processes based on granular computations. Although many rough set theory extensions developed over time focus on reasoning about (partial) set inclusion, these approximation spaces sometimes fall short when dealing with crucial aspects of approximate reasoning within ISs. Specifically, these systems aim to construct high-quality approximations of compound decision granules that represent solutions. Here, we present the basis for insightful reasoning realized through approximate reasoning processes grounded in granular computations. By doing so, we provide a sufficiently rich basis for designing IS problem solvers. This basis allows ISs to restructure or adapt their reasoning based on the generated granular computations, ultimately leading to high-quality granular solutions.}
}
@article{BRENNAN2023100070,
title = {Generalised Kuramoto models with time-delayed phase-resetting for k-dimensional clocks},
journal = {Brain Multiphysics},
volume = {4},
pages = {100070},
year = {2023},
issn = {2666-5220},
doi = {https://doi.org/10.1016/j.brain.2023.100070},
url = {https://www.sciencedirect.com/science/article/pii/S2666522023000084},
author = {Martin Brennan and Peter Grindrod CBE},
keywords = {Kuramoto models, Range-dependent networks, High dimensional clocks, Phase-resetting maps, The human cortex, Consciousness},
abstract = {We consider a class of Kuramoto models, with an array of N individual k-dimensional clocks (k>1), coupled within a directed, range dependent, network. For each directed connection, a signal triggered at the sending clock incurs a (real valued) time delay before arriving at the receiving clock, where it induces an instantaneous phase reset affecting all k-phases. Instantaneous phase resetting maps (PRMs) for k-dimensional clocks have received little attention. The system may be treated as open and subject to periodic, or other types of, PRM forcing at any individual clock, as a result of external forcing stimuli. We show how the full system, with Nk phase variables, responds to such stimuli, as the impact spreads across the entire network. Beyond simulations, we employ methods to reverse engineer the dynamical behaviour of the whole: estimating the intrinsic dimensions of the responses to different experiments; and by analysing pairwise comparisons between those responses. This shows that the system’s responses are governed by a hierarchy of internal dynamical modes, existing across both the Nk phases and over time. We argue that this Kuramoto system is a model for the human cortex, where each k-dimensional clock models the dynamics of a single neural column, which contains 10,000 densely inter-connected neurons. The Kuramoto model exploits the natural network of networks architecture of the human cortex. An array of N=1M such columns/clocks is at the 10B neuron scale of the human cortex. However its simulation is far more accessible than very large scale (VLS) simulations of neuron-to-neuron systems on supercomputers. The latent modes may have important implications for cognition (information processing) and for consciousness (the existence of internal phenomenological experiences). We argue that the existence of the latter plays a key role in preconditioning the former, reducing the decision sets and the cognitive load, and thus enabling a fast-thinking evolutionary advantage. This is the first time that systems of k-dimensional clocks (k> 1), coupled via time-lagged PRMs, within range dependent networks, have been deployed to demonstrate the basic internal phenomenological elements (of consciousness) and their potential role within immediate cognition. Statement of Significance: We argue that this Kuramoto system is a model for the human cortex, where each of 1M k-dimensional clocks models the dynamics of a single neural column (containing 10,000 densely inter-connected neurons). This Kuramoto model exploits the natural network of networks architecture of the human cortex. Large scale human cortex simulations, with 10B neutrons, usually require a super computer. We show that similar results, using this model, can be obtained on a laptop. In particular we show that such dynamical can support internal phenomenological elements (of conscious experience) and we discuss their potential role in preconditioning immediate cognition, furnishing a “fast thinking” evolutionary advantage to the human brain.}
}
@article{BERKOVICHOHANA2020116626,
title = {Inter-participant consistency of language-processing networks during abstract thoughts},
journal = {NeuroImage},
volume = {211},
pages = {116626},
year = {2020},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2020.116626},
url = {https://www.sciencedirect.com/science/article/pii/S1053811920301130},
author = {Aviva Berkovich-Ohana and Niv Noy and Michal Harel and Edna Furman-Haran and Amos Arieli and Rafael Malach},
keywords = {Abstract-thoughts, Visual imagery, Default mode network, Language, fMRI},
abstract = {Human brain imaging typically employs structured and controlled tasks to avoid variable and inconsistent activation patterns. Here we expand this assumption by showing that an extremely open-ended, high-level cognitive task of thinking about an abstract content, loosely defined as “abstract thinking” - leads to highly consistent activation maps. Specifically, we show that activation maps generated during such cognitive process were precisely located relative to borders of well-known networks such as internal speech, visual and motor imagery. The activation patterns allowed decoding the thought condition at >95%. Surprisingly, the activated networks remained the same regardless of changes in thought content. Finally, we found remarkably consistent activation maps across individuals engaged in abstract thinking. This activation bordered, but strictly avoided visual and motor networks. On the other hand, it overlapped with left lateralized language networks. Activation of the default mode network (DMN) during abstract thought was similar to DMN activation during rest. These observations were supported by a quantitative neuronal distance metric analysis. Our results reveal that despite its high level, and varied content nature - abstract thinking activates surprisingly precise and consistent networks in participants’ brains.}
}
@article{ISLAM2025100417,
title = {DFT insights into the mechanical properties of NMs},
journal = {Results in Surfaces and Interfaces},
volume = {18},
pages = {100417},
year = {2025},
issn = {2666-8459},
doi = {https://doi.org/10.1016/j.rsurfi.2025.100417},
url = {https://www.sciencedirect.com/science/article/pii/S2666845925000042},
author = {Md. Aminul Islam and Nayem Hossain and Zahid Ahsan and Masud Rana and Mustafizur Rahman and Md. Abdullah},
keywords = {DFT, NMs, Elasticity, Mechanical properties, Quantum effects, Surface phenomena},
abstract = {NMs, whose dimensions are below 100 nm, provide unique mechanical properties from quantum effects, surface phenomena, and small-scale interactions that account for their importance in energy storage, biomedicine, nanoelectronics, etc. This review discusses computational prediction of mechanical properties (for example, elasticity, strength, and fracture behavior) in NMs, especially using Density Functional Theory as a central tool. By conducting DFT calculations, we can analyze how NMs will behave across different mechanical states, which is critical for designing properties for advanced applications. Problems related to the application of DFT (e.g., high computational cost and failure in modeling defects or exchange-correlation functionals) are discussed. Despite these challenges, DFT must provide insights that complement other tools and strategies. However, further development is essential for improving its quantitative predictability on temperature and multiscale models. Future work is needed to integrate ML with DFT further to refine the accuracy and computational efficiency, thereby extending the capability of DFT to accelerate the discovery of new NMs with superior mechanical properties.}
}
@article{HEGER2018177,
title = {We should totally open a restaurant: How optimism and overconfidence affect beliefs},
journal = {Journal of Economic Psychology},
volume = {67},
pages = {177-190},
year = {2018},
issn = {0167-4870},
doi = {https://doi.org/10.1016/j.joep.2018.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0167487017305585},
author = {Stephanie A. Heger and Nicholas W. Papageorge},
keywords = {Subjective beliefs, Overconfidence, Optimism, Information, Experiments},
abstract = {Wishful thinking, defined as the tendency to over-estimate the probability of high-payoff outcomes, is a widely-documented phenomenon that can affect decision-making across numerous domains, including finance, management, and entrepreneurship. We design an experiment to distinguish and test the relationship between two easily-confounded biases, optimism and overconfidence, both of which can contribute to wishful thinking. We find that optimism and overconfidence are positively correlated at the individual level and that both help to explain wishful thinking. These findings suggest that ignoring optimism results in an upwardly biased estimate of the role of overconfidence in explaining wishful thinking. To illustrate this point, we show that 30% of our observations are misclassified as under- or overconfident if optimism is omitted from the analysis. Our findings have potential implications for the design of information interventions since how agents incorporate information depends on whether the bias is ego-related.}
}
@article{DOHERTYSNEDDON2013616,
title = {Gaze aversion during social style interactions in autism spectrum disorder and Williams syndrome},
journal = {Research in Developmental Disabilities},
volume = {34},
number = {1},
pages = {616-626},
year = {2013},
issn = {0891-4222},
doi = {https://doi.org/10.1016/j.ridd.2012.09.022},
url = {https://www.sciencedirect.com/science/article/pii/S0891422212002557},
author = {Gwyneth Doherty-Sneddon and Lisa Whittle and Deborah M. Riby},
keywords = {Eye contact, Gaze, Williams syndrome, Gaze aversion, Autism spectrum disorder},
abstract = {During face-to-face interactions typically developing individuals use gaze aversion (GA), away from their questioner, when thinking. GA is also used when individuals with autism (ASD) and Williams syndrome (WS) are thinking during question-answer interactions. We investigated GA strategies during face-to-face social style interactions with familiar and unfamiliar interlocutors. Participants with WS and ASD used overall typical amounts/patterns of GA with all participants looking away most while thinking and remembering (in contrast to listening and speaking). However there were a couple of specific disorder related differences: participants with WS looked away less when thinking and interacting with unfamiliar interlocutors; in typical development and WS familiarity was associated with reduced gaze aversion, however no such difference was evident in ASD. Results inform typical/atypical social and cognitive phenotypes. We conclude that gaze aversion serves some common functions in typical and atypical development in terms of managing the cognitive and social load of interactions. There are some specific idiosyncracies associated with managing familiarity in ASD and WS with elevated sociability with unfamiliar others in WS and a lack of differentiation to interlocutor familiarity in ASD. Regardless of the familiarity of the interlocutor, GA is associated with thinking for typically developing as well as atypically developing groups. Social skills training must take this into account.}
}
@article{TEEPLE2023102847,
title = {Level-k predatory trading},
journal = {Journal of Mathematical Economics},
volume = {106},
pages = {102847},
year = {2023},
issn = {0304-4068},
doi = {https://doi.org/10.1016/j.jmateco.2023.102847},
url = {https://www.sciencedirect.com/science/article/pii/S030440682300040X},
author = {Keisuke Teeple},
keywords = {Behavioral finance, Level- models, Front running, Price overshooting},
abstract = {I incorporate the level-k thinking solution concept into a simplified (Brummermeier and Pedersen, 2005) predatory trading model to investigate the possibility of arbitraging arbitrageurs. While naive financial predators prey upon a single distressed investor, higher-level thinkers best respond to this and prey upon fellow predators. For some parameter values, sophisticated predators are able to reason their way to the Nash equilibrium strategy, and prices do not oscillate. As parameter values are perturbed, the system undergoes a bifurcation and predators select strategies from a mean-preserving spread of the Nash equilibrium strategy. In these settings, prices display excess volatility and a single shock can send predators into an oscillatory trading frenzy.}
}
@article{WAUTELET2025125664,
title = {Circulise, a model-driven framework to build and align socio-technical systems for the twin transition: Fanyatu’s case of sustainability in reforestation},
journal = {Expert Systems with Applications},
volume = {262},
pages = {125664},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125664},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424025314},
author = {Yves Wautelet and Xavier Rouget},
keywords = {Circulise, Circular economy development, Cryptocurrency, Reforestation, Sustainability, Sustainability engineering, Twin transition},
abstract = {Building circular economic systems is crucial to address ecological challenges like climate change. The twin transition suggests that, to maximize the impact of sustainable solutions, humans and (disruptive) technologies need to be effectively integrated. Methods to conceptually build such (eco)systems integrating these and assess their ecological impact before implementation are lacking. This paper addresses this gap by proposing the Circulise framework, a model-driven method designed to build circular systems and evaluate their environmental performance. The approach promotes design-thinking to create socio-technical ecosystems that can be evaluated at the light of their alignment with circular economy and/or sustainability principles and be used to generate operational software behavior. The Circulise framework was developed following the methodological guidance of design science research. It is applied in this paper to the case of Fanyatu, a non-profit organization focused on reforestation in the Congo Basin, showing its ability to create a circular ecosystem not only supporting the creation of regenerative CO2-absorbing forests but also empowering and improving the quality of life of the local communities involved in the planting of trees. In Fanyatu’s case, Circulise’s strategic planning and technology integration lead to virtuous cycles, enabling a snowball effect in forest creation and the promotion of sustainable projects. The framework’s scalability and versatility allow it to be applied across various contexts, enabling the creation of customized circular ecosystems for sustainability tailored to specific human and technological needs.}
}
@article{BILLINGE20243714,
title = {Do materials have a genome, and if they do, what can be done with it?},
journal = {Matter},
volume = {7},
number = {11},
pages = {3714-3727},
year = {2024},
issn = {2590-2385},
doi = {https://doi.org/10.1016/j.matt.2024.06.026},
url = {https://www.sciencedirect.com/science/article/pii/S259023852400345X},
author = {Simon J.L. Billinge},
abstract = {Summary
Materials do not have a genome, yet for the past decade, and into the next decade, in the USA, there has been a presidential and inter-agency funding initiative called the “Materials Genome Initiative (MGI).” This initiative has nothing to do with real genomes, materials, or otherwise. However, in this paper, we, somewhat whimsically, explore some ideas about what a material’s gene could be and how it could be used to further our understanding of materials structure and properties. The result is a slightly non-conventional, less crystal-centric, view of materials structure that we believe can, will, and is resulting in novel materials insights.}
}
@article{BAKER2022942,
title = {Three aspects of representation in neuroscience},
journal = {Trends in Cognitive Sciences},
volume = {26},
number = {11},
pages = {942-958},
year = {2022},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2022.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S1364661322002108},
author = {Ben Baker and Benjamin Lansdell and Konrad P. Kording},
keywords = {representation, information, coding, explanation, function, teleology, philosophy},
abstract = {Neuroscientists often describe neural activity as a representation of something, or claim to have found evidence for a neural representation, but there is considerable ambiguity about what such claims entail. Here we develop a thorough account of what ‘representation’ does and should do for neuroscientists in terms of three key aspects of representation. (i) Correlation: a neural representation correlates to its represented content; (ii) causal role: the representation has a characteristic effect on behavior; and (iii) teleology: a goal or purpose served by the behavior and thus the representation. We draw broadly on literature in both neuroscience and philosophy to show how these three aspects are rooted in common approaches to understanding the brain and mind. We first describe different contexts that ‘representation’ has been closely linked to in neuroscience, then discuss each of the three aspects in detail.}
}
@article{JOHNSON200337,
title = {Parallel processing in computational stochastic dynamics},
journal = {Probabilistic Engineering Mechanics},
volume = {18},
number = {1},
pages = {37-60},
year = {2003},
issn = {0266-8920},
doi = {https://doi.org/10.1016/S0266-8920(02)00041-3},
url = {https://www.sciencedirect.com/science/article/pii/S0266892002000413},
author = {E.A. Johnson and C. Proppe and B.F. Spencer and L.A. Bergman and G.S. Székely and G.I. Schuëller},
keywords = {Computational stochastic dynamics, Parallel computing, Monte Carlo simulation, Random eigenvalue, Fokker–Planck equation},
abstract = {Studying large complex problems that often arise in computational stochastic dynamics (CSD) demands significant computer power and data storage. Parallel processing can help meet these requirements by exploiting the computational and storage capabilities of multiprocessing computational environments. The challenge is to develop parallel algorithms and computational strategies that can take full advantage of parallel machines. This paper reviews some of the characteristics of parallel computing and the techniques used to parallelize computational algorithms in CSD. The characteristics of parallel processor environments are discussed, including parallelization through the use of message passing and parallelizing compilers. Several applications of parallel processing in CSD are then developed: solutions of the Fokker–Planck equation, Monte Carlo simulation of dynamical systems, and random eigenvector problems. In these examples, parallel processing is seen to be a promising approach through which to resolve some of the computational issues pertinent to CSD.}
}
@article{BLACK2008723,
title = {Deriving an approximation algorithm for automatic computation of ripple effect measures},
journal = {Information and Software Technology},
volume = {50},
number = {7},
pages = {723-736},
year = {2008},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2007.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S0950584907000791},
author = {Sue Black},
keywords = {Software measurement, Ripple effect, Matrix algebra},
abstract = {The ripple effect measures impact, or how likely it is that a change to a particular module may cause problems in the rest of a program. It can also be used as an indicator of the complexity of a particular module or program. Central to this paper is a reformulation in terms of matrix arithmetic of the original ripple effect algorithm produced by Yau and Collofello in 1978. The main aim of the reformulation is to clarify the component parts of the algorithm making the calculation more explicit. The reformulated algorithm has been used to implement REST (Ripple Effect and Stability Tool) which produces ripple effect measures for C programs. This paper describes the reformulation of Yau and Collofello’s ripple effect algorithm focusing on the computation of matrix Zm which holds intramodule change propagation information. The reformulation of the ripple effect algorithm is validated using fifteen programs which have been grouped by type. Due to the approximation spurious 1s are contained within matrix Zm. It is discussed whether this has an impact on the accuracy of the reformulated algorithm. The conclusion of this research is that the approximated algorithm is valid and as such can replace Yau and Collofello’s original algorithm.}
}
@article{JOHAN1992113,
title = {A data parallel finite element method for computational fluid dynamics on the Connection Machine system},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {99},
number = {1},
pages = {113-134},
year = {1992},
issn = {0045-7825},
doi = {https://doi.org/10.1016/0045-7825(92)90124-3},
url = {https://www.sciencedirect.com/science/article/pii/0045782592901243},
author = {Zdeněk Johan and Thomas J.R. Hughes and Kapil K. Mathur and S.Lennart Johnsson},
abstract = {A finite element method for computational fluid dynamics has been implemented on the Connection Machine systems CM-2 and CM-200. An implicit iterative solution strategy, based on the preconditioned matrix-free GMRES algorithm, is employed. Parallel data structures built on both nodal and elemental sets are used to achieve maximum parallelization. Communication primitives provided through the Connection Machine Scientific Software Library substantially improved the overall performance of the program. Computations of three-dimensional compressible flows using unstructured meshes having close to one million elements, such as a complete airplane, demonstrate that the Connection Machine systems are suitable for these applications. Performance comparisons are also carried out with the vector computers Cray Y-MP and Convex C-1.}
}
@article{SINGER200948,
title = {The dynamic infrastructure of mind—A hypothesis and some of its applications},
journal = {New Ideas in Psychology},
volume = {27},
number = {1},
pages = {48-74},
year = {2009},
issn = {0732-118X},
doi = {https://doi.org/10.1016/j.newideapsych.2008.04.007},
url = {https://www.sciencedirect.com/science/article/pii/S0732118X08000032},
author = {Florence Mihaela Singer},
keywords = {Cognitive architecture, Dynamic infrastructure of mind, Learning, Operational categories},
abstract = {A mechanism underlying the computational properties of the cognitive architecture is construed based on a minimal list of operational clusters. This general processing mechanism constitutes the dynamic infrastructure of mind (DIM). DIM consists in categories of mental operations foundational for learning that contain inborn components called inner operations, which are self-developing in the interaction mind-environment. Within the DIM paradigm, the input cognitive systems are not domain specific or core-knowledge specific, they are operational specific and capable of further developments that become domain specific while experiencing the environment. Arguments for this construal come from three sources: literature review, data collected through classroom observations, and a four-year experimental study of teaching and learning mathematics in primary grades. The outcomes of that experiment led to a methodology of learning based on activating the operational infrastructure of mind, which enhances students' flexibility of thinking and predicts the capacity to solve creatively a variety of problems.}
}
@article{JOHNSON200033,
title = {Thinking ahead: the case for motor imagery in prospective judgements of prehension},
journal = {Cognition},
volume = {74},
number = {1},
pages = {33-70},
year = {2000},
issn = {0010-0277},
doi = {https://doi.org/10.1016/S0010-0277(99)00063-3},
url = {https://www.sciencedirect.com/science/article/pii/S0010027799000633},
author = {Scott H Johnson},
keywords = {Motor imagery, Prospective judgements, Prehension},
abstract = {How similar are judgements concerning how we expect to perform an action, to how we actually behave? The veracity of such prospective action judgements, and the mechanisms by which they are computed, was explored in a series of tasks that involved either grasping (MC conditions) or thinking about grasping (PJ conditions) a dowel presented in various orientations. PJs concerning limits of comfortable hand supination and pronation when turning a dowel in the picture plane were highly consistent with values obtained during actual hand rotation (Exp. 1). The same was true for judgements regarding the level of awkwardness involved in adopting a prescribed grip (e.g. overhand with right hand) for dowels in various picture plane orientations (Exp. 2). When allowed to select the most natural grip (overhand versus underhand) or hand (left versus right) for engaging dowels in these orientations, subjects preferred virtually identical responses in both PJ and MC conditions. In both instances, they consistently chose the least awkward response options. As would be expected for actual movements, PJs involving awkward hand postures had longer response times (RTs), and were less accurate. Likewise, latencies for both grip and hand judgements tended to increase as a function of the angular distance between the current positions of subjects’ hands, and the orientation of the chosen posture. Together, these findings are consistent with a the hypothesis that PJs involve mentally simulated actions, or motor imagery. These results suggest that motor imagery does not depend on the existence of a completed premotor plan (Jeannerod, 1994), but may instead be involved in the planning process itself. A provisional model for the involvement of imagery in motor planning is outlined, as are a set of criteria for evaluating claims of the involvement of motor imagery in problem solving.}
}
@article{SOTELOMONGE2021869,
title = {Conceptualization and cases of study on cyber operations against the sustainability of the tactical edge},
journal = {Future Generation Computer Systems},
volume = {125},
pages = {869-890},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.07.016},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21002788},
author = {Marco Antonio {Sotelo Monge} and Jorge {Maestre Vidal}},
keywords = {Cyber defense, Economical Denial of Sustainability, Military operations, Situational Awareness, Tactical Denial of Sustainability},
abstract = {The last decade consolidated the cyberspace as fifth domain of military operations, which extends its preliminarily intelligence and information exchange purposes towards enabling complex offensive and defensive operations supported/supportively of parallel kinetic domain actuations. Although there is a plethora of well documented cases on strategic and operational interventions of cyber commands, the cyber tactical military edge is still a challenge, where cyber fires barely integrate to the traditional joint targeting cycle due to, among others, long planning/development times, asymmetric effects, strict target reachability requirements, or the fast propagation of collateral damage; the latter rapidly deriving on hybrid impacts (political, economic, social, etc.) and evidencing significant socio-technical gaps. In this context, it is expected that Tactical Clouds disruptively facilitate cyber operations at the edge while exposing the rest of the digital assets of the operation to them. On these grounds, the main purpose of the conducted research is to review and in depth analyze the risks and opportunities of jeopardizing the sustainability of the military Tactical Clouds at their cyber edge. Along with a 1) comprehensively formulation of the researched problematic, the study 2) formalizes the Tactical Denial of Sustainability (TDoS) concept; 3) introduces the phasing, potential attack surfaces, terrains and impact of TDoS attacks; 4) emphasizes the related human and socio-technical aspects; 5) analyzes the threats/opportunities inherent to their impact on the cloud energy efficiency; 6) reviews their implications at the military cyber thinking for tactical operations; 7) illustrates five extensive CONOPS that facilitate the understanding of the TDoS concept; and given the high novelty of the discussed topics, this paper 8) paves the way for further research and development actions.}
}
@incollection{BRACHMAN20041,
title = {Chapter 1 - Introduction},
editor = {Ronald J. Brachman and Hector J. Levesque},
booktitle = {Knowledge Representation and Reasoning},
publisher = {Morgan Kaufmann},
address = {San Francisco},
pages = {1-14},
year = {2004},
series = {The Morgan Kaufmann Series in Artificial Intelligence},
isbn = {978-1-55860-932-7},
doi = {https://doi.org/10.1016/B978-155860932-7/50086-8},
url = {https://www.sciencedirect.com/science/article/pii/B9781558609327500868},
author = {Ronald J. Brachman and Hector J. Levesque},
abstract = {Publisher Summary
This introductory chapter discusses the main issues associated with Artificial Intelligence (AI) and the prospect of a machine that could think. AI is the study of intelligent behavior that is achieved through computational means. One striking aspect of intelligent behavior is that it is conditioned by knowledge. Knowledge representation and reasoning are the parts of AI that are concerned with how an agent uses what it knows in deciding what to do. It is the study of thinking as a computational process. The book introduces the symbolic structures invented for representing knowledge and the computational processes devised for reasoning with those symbolic structures. The reason why logic is relevant to knowledge representation and reasoning is that logic is the study of entailment relations—languages, truth conditions, and rules of inference… Despite the centrality of knowledge representation and reasoning to AI, there are alternate views. Some authors have claimed that human-level reasoning is not achievable via purely computational means. Others suggest that intelligence derives from computational mechanisms.}
}
@article{ZHANG2024117045,
title = {A bidirectional collaborative method based on an improved artificial fish swarm algorithm for ship pipe and equipment layout design},
journal = {Ocean Engineering},
volume = {296},
pages = {117045},
year = {2024},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2024.117045},
url = {https://www.sciencedirect.com/science/article/pii/S0029801824003822},
author = {Hongshuo Zhang and Yanyun Yu and Qiaoyu Zhang and Yuansong Yang and Haiyang Liu and Yan Lin},
keywords = {Collaborative optimization, Ship engine room layout design, Multi-strategy heuristic algorithm, Hybrid-objective optimization, Coding technique, Automation design},
abstract = {Ship engine room layout design (SERLD) significantly impacts a ship's transportation efficiency and safety by focusing on the layouts of equipment and piping. However, owing to complex constraints, previous research has mainly focused on single-dimensional layout designs and has failed to provide comprehensive references for designers. To address this research gap, this study proposes a collaborative layout method based on a multistrategy hybrid-objective artificial fish swarm algorithm (HMSAFSA). In terms of the underlying mathematical representation, a more stable Manhattan trajectory-based coding method suitable for a collaborative layout is proposed. Building on this coding method, multiple strategies are incorporated into the heuristic AFSA to enhance its optimization and collaborative performance. Collaborative evaluation functions and methods are designed and refined to ensure effective layout results for multiple objectives. Furthermore, a layout procedure incorporating bidirectional guidance strategies and hierarchical thinking is proposed. This method achieves collaborative layouts through the mutual guidance of optimal objectives. Finally, the effectiveness of the proposed method is verified through representative cases of various types of ship engine rooms in practical engineering. The method demonstrates its capability to offer multiple optimal layout schemes, thus presenting substantial value for practical engineering designs.}
}
@article{MANIKANTAN2009639,
title = {Challenges for the future modifications of the TNM staging system for head and neck cancer: Case for a new computational model?},
journal = {Cancer Treatment Reviews},
volume = {35},
number = {7},
pages = {639-644},
year = {2009},
issn = {0305-7372},
doi = {https://doi.org/10.1016/j.ctrv.2009.04.010},
url = {https://www.sciencedirect.com/science/article/pii/S0305737209000632},
author = {Kapila Manikantan and Suhail I. Sayed and Konstantinos N. Syrigos and Peter Rhys-Evans and Chris M. Nutting and Kevin J. Harrington and Rehan Kazi},
keywords = {TNM stage, Head and neck cancer, Co-morbidity},
abstract = {Summary
The TNM system of staging cancers is a simple and effective method to map the extent of tumours. It had traditionally strived to maintain a balance between being simple and user-friendly on one hand and comprehensive on the other. A number of revisions have taken place over the years with the goal of improving utility. However, numerous controversies surround the TNM system. There is a school of thought that contends that patient co-morbidity and specific tumour-related factors should be incorporated to add further prognostic capabilities in the TNM system, but this raises concerns that such an approach may unnecessarily complicate the system. This review highlights some controversies that surround the TNM system and suggests prognostic indicators that may be added to make it more useful in guiding treatment decisions and predicting outcomes.}
}
@article{YU2025110799,
title = {An adaptive incremental solution scheme for the phase field model of fracture},
journal = {Engineering Fracture Mechanics},
volume = {315},
pages = {110799},
year = {2025},
issn = {0013-7944},
doi = {https://doi.org/10.1016/j.engfracmech.2024.110799},
url = {https://www.sciencedirect.com/science/article/pii/S0013794424009627},
author = {Yuanfeng Yu and Chi Hou and Timon Rabczuk and Meiying Zhao},
keywords = {Fracture, Phase field model, Solution scheme, Adaptive increment, Computational time},
abstract = {To increase the phase field model’s computational effectiveness, an efficient and robust adaptive incremental solution scheme is presented in this work. Firstly, a time field change criterion is established based on the variation of phase field variable and its increment, so that the pseudo time increment and load increment can be adaptively regulated with the solution of displacement and phase fields, which cuts down on computation time and the number of iterations. Secondly, the implementation of the scheme is introduced. Finally, the effectiveness of proposed solution scheme is tested through some numerical examples. The results showcase that the proposed strategy can not only acquire accurate load–displacement responses and crack patterns, but also significantly reduce the computational cost. By comparing with the current standard staggered strategy and the monolithic BFGS strategy, the computation time of the presented solution scheme is about 1% of that of the standard strategy, and less than 1/3 of the time of the BFGS strategy. Meanwhile, the presented scheme also exhibits excellent convergence properties.}
}
@article{HARVEY2025,
title = {Using Natural Language Processing Methods to Build the Hypersexuality in Bipolar Reddit Corpus: Infodemiology Study of Reddit},
journal = {JMIR Infodemiology},
volume = {5},
year = {2025},
issn = {2564-1891},
doi = {https://doi.org/10.2196/65632},
url = {https://www.sciencedirect.com/science/article/pii/S2564189125000118},
author = {Daisy Harvey and Paul Rayson and Fiona Lobban and Jasper Palmier-Claus and Clare Dolman and Anne Chataigné and Steven Jones},
keywords = {bipolar, hypersexuality, natural language processing, Linguistic Inquiry and Word Count, LIWC, BERTopic, topic modeling, computational linguistics},
abstract = {Background
Bipolar is a severe mental health condition affecting at least 2% of the global population, with clinical observations suggesting that individuals experiencing elevated mood states, such as mania or hypomania, may have an increased propensity for engaging in risk-taking behaviors, including hypersexuality. Hypersexuality has historically been stigmatized in society and in health care provision, which makes it more difficult for service users to talk about their behaviors. There is a need for greater understanding of hypersexuality to develop better evidence-based treatment, support, and training for health professionals.
Objective
This study aimed to develop and assess effective methodologies for identifying posts on Reddit related to hypersexuality posted by people with a self-reported bipolar diagnosis. Using natural language processing techniques, this research presents a specialized dataset, the Talking About Bipolar on Reddit Corpus (TABoRC). We used various computational tools to filter and categorize posts that mentioned hypersexuality, forming the Hypersexuality in Bipolar Reddit Corpus (HiB-RC). This paper introduces a novel methodology for detecting hypersexuality-related conversations on Reddit and offers both methodological insights and preliminary findings, laying the groundwork for further research in this emerging field.
Methods
A toolbox of computational linguistic methods was used to create the corpora and infer demographic variables for the Redditors in the dataset. The key psychological domains in the corpus were measured using Linguistic Inquiry and Word Count, and a topic model was built using BERTopic to identify salient language clusters. This paper also discusses ethical considerations associated with this type of analysis.
Results
The TABoRC is a corpus of 6,679,485 posts from 5177 Redditors, and the HiB-RC is a corpus totaling 2146 posts from 816 Redditors. The results demonstrate that, between 2012 and 2021, there was a 91.65% average yearly increase in posts in the HiB-RC (SD 119.6%) compared to 48.14% in the TABoRC (SD 51.2%) and an 86.97% average yearly increase in users (SD 93.8%) compared to 27.17% in the TABoRC (SD 38.7%). These statistics suggest that there was an increase in posting activity related to hypersexuality that exceeded the increase in general Reddit use over the same period. Several key psychological domains were identified as significant in the HiB-RC (P<.001), including more negative tone, more discussion of sex, and less discussion of wellness compared to the TABoRC. Finally, BERTopic was used to identify 9 key topics from the dataset.
Conclusions
Hypersexuality is an important symptom that is discussed by people with bipolar on Reddit and needs to be systematically recognized as a symptom of this illness. This research demonstrates the utility of a computational linguistic framework and offers a high-level overview of hypersexuality in bipolar, providing empirical evidence that paves the way for a deeper understanding of hypersexuality from a lived experience perspective.}
}
@article{ONTIVEROSARAIZA2025105361,
title = {The Neurobehavioral State hypothesis},
journal = {BioSystems},
volume = {247},
pages = {105361},
year = {2025},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2024.105361},
url = {https://www.sciencedirect.com/science/article/pii/S0303264724002466},
author = {Luis Fernando Ontiveros-Araiza},
keywords = {Brain networks, Neuronal dynamics, Neural code, Neurotransmitter, Electrophysiology, Neuronal computation, Behavior},
abstract = {Since the early attempts to understand the brain made by Greek philosophers more than 2000 years ago, one of the main questions in neuroscience has been how the brain perceives all the stimuli in the environment and uses this information to implement a response. Recent hypotheses of the neural code rely on the existence of an ideal observer, whether on specific areas of the cerebral cortex or distributed network composed of cortical and subcortical elements. The Neurobehavioral State hypothesis stipulates that neurons are in a quasi-stable state due to the dynamic interaction of their molecular components. This increases their computational capabilities and electrophysiological behavior further than a binary active/inactive state. Together, neuronal populations across the brain learn to identify and associate internal and external stimuli with actions and emotions. Furthermore, such associations can be stored through the regulation of neuronal components as new quasi-stable states. Using this framework, behavior arises as the result of the dynamic interaction between internal and external stimuli together with previously established quasi-stable states that delineate the behavioral response. Finally, the Neurobehavioral State hypothesis is firmly grounded on present evidence of the complex dynamics within the brain, from the molecular to the network level, and avoids the need for a central observer by proposing the brain configures itself through experience-driven associations.}
}
@article{LEVYGARBOUA2024102438,
title = {Creative cognition as a bandit problem},
journal = {Learning and Individual Differences},
volume = {111},
pages = {102438},
year = {2024},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2024.102438},
url = {https://www.sciencedirect.com/science/article/pii/S1041608024000311},
author = {Louis Lévy-Garboua and Marco Gazel and Noémi Berlin and Jan Dul and Todd Lubart},
keywords = {Creative cognition, Multi-armed bandit problem, Education and creativity, Individual differences in creative potential, Adolescents' behavior},
abstract = {This paper draws a parallel between creative cognition and a multi-armed bandit problem involving learning from experience in an uncertain environment. Special emphasis is put on the optimal sequencing of divergent and convergent behavior by showing that divergence must be inhibited at one point to converge toward creative behavior so that excessive divergence is counterproductive. We test this hypothesis with a behavioral experiment, using measures of individual divergence and convergence components of creative potential in high school students. Results confirmed that a mix of divergence and convergence predicted high performance in a bandit task but not in a purely random task or in a simple repetitive task. These predictions are maintained after controlling for sex, personality, incentives, and other factors. As hypothesized, creative cognition was necessary for high performance under the appropriate conditions. However, it was not necessary to get high grades in a traditional school system.
Educational relevance statement
Relating to the goal of educators and public policies in the 21st century to make children and adolescents more creative, and schools more receptive to creative thinking, this research focuses on the creative potential and behavior of high school students. It provides an evidence-based policy argument in support of the screening and development by the educational sector of the creative potential of students.}
}
@article{SNOW201462,
title = {Emergent behaviors in computer-based learning environments: Computational signals of catching up},
journal = {Computers in Human Behavior},
volume = {41},
pages = {62-70},
year = {2014},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2014.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S0747563214004518},
author = {Erica L. Snow and G. Tanner Jackson and Danielle S. McNamara},
keywords = {Intelligent tutoring systems, Individual differences, Self-regulated learning, Agency, Log data, Dynamic analyses},
abstract = {Self-regulative behaviors are dynamic and evolve as a function of time and context. However, dynamical fluctuations in behaviors are often difficult to measure and therefore may not be fully captured by traditional measures alone. Utilizing system log data and two novel statistical methodologies, this study examined emergent patterns of controlled and regulated behaviors and assessed how variations in these patterns related to individual differences in prior literacy ability and target skill acquisition. Conditional probabilities and Entropy analyses were used to examine nuanced patterns manifested in students’ interaction choices within a computer-based learning environment. Forty high school students interacted with the game-based intelligent tutoring system iSTART-ME, for a total of 11 sessions (pretest, 8 training sessions, posttest, and a delayed retention test). Results revealed that high and low reading ability students differed in their patterns of interactions and the amount of control they exhibited within the game-based system. However, these differences converged overtime along with differences in students’ performance within iSTART-ME. The findings from this study indicate that individual differences in students’ prior reading ability relate to the emergence of controlled and regulated behaviors during learning tasks.}
}
@article{MAHAL2007491,
journal = {Economics & Human Biology},
volume = {5},
number = {3},
pages = {491-493},
year = {2007},
note = {Special Issue on Obesity in Eastern Europe},
issn = {1570-677X},
doi = {https://doi.org/10.1016/j.ehb.2007.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S1570677X07000573},
author = {Ajay Mahal}
}
@article{MONAT2024103429,
title = {The self-awareness of the forest},
journal = {Futures},
volume = {163},
pages = {103429},
year = {2024},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2024.103429},
url = {https://www.sciencedirect.com/science/article/pii/S0016328724001125},
author = {Jamie P. Monat},
keywords = {Forest, Emergence, Systems thinking, Self-awareness, Neural network},
abstract = {Systems Thinking theorist J. P. Monat has hypothesized that human-level organismal self-awareness will emerge spontaneously in a well-connected neural network as the number of interconnected nodes exceeds ∼70 billion; he speculates that computer networks may achieve self-awareness as the number of nodes approaches this figure. Forests have historically not been perceived as interconnected networks of trees; recently however, researchers have described the “wood-wide web” in which underground fungi interconnect large numbers of trees and plants via chemical and electrical signals. Some of earth’s forests number many billions of trees, and some of the world’s prairies and seagrass meadows also contain billions of individual plants. These plant ecosystems may thus be self-aware, and in fact there may be a multitude of self-aware plant-based ecosystems on earth already. The speed of signal transmission via fungi within each ecosystem is much slower than that in humans, and therefore their organismal self-awareness may be of a different nature than the self-awareness that we associate with humans and upper primates. However, the possibility that our plant systems may be aware of the environmental insults that are being wrought upon them should make us reconsider our anthropocentric activities, as well as the possibility that humanity may need to collaborate with other intelligent non-human earth-based life forms to ensure mutual survival.}
}
@article{CHEN2025126364,
title = {Strain-driven anisotropic enhancement in the thermal conductivity of KCaBi: the role of optical phonons},
journal = {International Journal of Heat and Mass Transfer},
volume = {236},
pages = {126364},
year = {2025},
issn = {0017-9310},
doi = {https://doi.org/10.1016/j.ijheatmasstransfer.2024.126364},
url = {https://www.sciencedirect.com/science/article/pii/S0017931024011931},
author = {Xue-Kun Chen and Yue Zhang and Qing-Qing Luo and Pin-Zhen Jia and Wu-Xing Zhou},
keywords = {anisotropic thermal conductivity, optical phonons, four-phonon scattering, strain engineering, machine learning potential},
abstract = {Acoustic phonons have long been believed to dominate the lattice thermal conductivity (κl) and the contribution of optical phonons can be neglected in crystal structures. KCaBi, as a high-throughput screening semiconductor with ultralow κl [J. Am. Chem. Soc. 144, 4448 (2022)], has been demonstrated that the contribution of optical phonons plays an important role in thermal transport. In this work, by solving the Boltzmann transport equation, it is found that the κl of KCaBi is 2.2 at 300K, with acoustic phonons dominating the z-direction κl and optical phonons contributing around 50% to the x-direction κl under the four-phonon picture. The uncommon contribution of optical phonons also manifests the possibility of tuning the κl anisotropy based on optical phonons. Following this line of thinking, it is found that applying tensile strain can cause a more pronounced decrease of acoustic phonon contribution than that of optical counterpart due to the highly dispersive optical branches, thus enhancing the anisotropic ratio of κl. Moreover, the microscopic mechanism is elucidated by analyzing the phonon dispersion relation, phonon mode-wise contribution and phonon scattering rates. Our study could provide appealing alternatives for the regulation of phonon transport from the viewpoint of optical phonons.}
}
@article{SHARIF2022104090,
title = {Robotic sheet metal folding: Tool vs. material programming},
journal = {Automation in Construction},
volume = {134},
pages = {104090},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.104090},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521005410},
author = {Shani Sharif and Russell Gentry},
keywords = {Robotic fabrication, Mass-customization, Dieless sheet metal folding},
abstract = {This research explores how deductive engineering thinking, as opposed to an abductive design rationale, can influence how robotic methods of fabricating building components are developed. The goal of this research is to demonstrate how creative thinking can introduce alternative robotic fabrication techniques targeted for the architectural mass-customization process. For this purpose, we chose robotic dieless sheet metal folding as the main fabrication technique, due to its wide range of applications in both the architectural construction and manufacturing industries. Two robotic sheet metal folding projects were developed. The first, an example of tool programming, took advantage of an engineering approach and was focused on the affordances of the tool (an industrial robotic arm). The second project, one of material programming, employed a design methodology and was directed towards the affordances of the material (i.e., stainless steel sheet metal). By discussing the advantages and disadvantages of each approach, this research argues that both engineering and design should be considered required and complementary processes in the development of new creative fabrication solutions, allowing them to and make the overall production process more efficient.}
}
@article{FU2024107632,
title = {Dissecting behavioral inertia in shaping different resident participation behaviors in neighborhood regeneration: A quantitative behavioral experiment},
journal = {Environmental Impact Assessment Review},
volume = {109},
pages = {107632},
year = {2024},
issn = {0195-9255},
doi = {https://doi.org/10.1016/j.eiar.2024.107632},
url = {https://www.sciencedirect.com/science/article/pii/S0195925524002191},
author = {Xinyue Fu and Guiwen Liu and Hongjuan Wu and Taozhi Zhuang and Ruopeng Huang and Fanning Yuan and Yuhang Zhang},
keywords = {Neighborhood regeneration, Resident participation, Behavioral inertia, Behavioral experiment},
abstract = {Research on resident participation in neighborhood regeneration provides valuable insights for urban policymakers in environmental governance. While previous studies have extensively examined various influencing factors, they often neglect the impact of behavioral inertia. To address this gap, this study conducts a behavioral experiment to quantitatively assess the presence and impact of behavioral inertia on residents' governance and financial participation behaviors. A total of 576 valid survey questionnaires were collected, and conditional logit model and ordered logit model were utilized for analysis. The study reveals that behavioral inertia is indeed observable in residents' governance participation and financial participation behaviors. Furthermore, the findings underscore distinct drivers of behavioral inertia for these two types of participation behaviors, with emotional reactions predominantly influencing governance participation, while short-term thinking largely shapes financial participation. Theoretically, this study uses the innovative concept of “behavioral inertia” to offer a new explanatory framework for aspects of behavior that cannot be solely explained by the attributes of regeneration plans. Furthermore, the behavioral experiments utilized in this study exemplify how the research framework of behavioral science can be applied to the study of urban governance in a broad context internationally. Practically, the research findings provide valuable insights for urban policymakers to tailor measures aimed at promoting resident participation and fostering sustainable urban development.}
}
@article{WANG2022102240,
title = {What is the competence boundary of Algorithms? An institutional perspective on AI-based video generation},
journal = {Displays},
volume = {73},
pages = {102240},
year = {2022},
issn = {0141-9382},
doi = {https://doi.org/10.1016/j.displa.2022.102240},
url = {https://www.sciencedirect.com/science/article/pii/S0141938222000671},
author = {Jun Wang and Sichen Li and Ke Xue and Li Chen},
keywords = {Artificial intelligence, Video, Information fluency, Perception},
abstract = {As automated journalism based on AI came into being, it is important to understand the algorithm competence possibilities and limitations for the institutional facilitating the human–machine collaboration. Meanwhile, videos become mainstream in the advertisement realm. To expand the scope of research from journalism to advertisement, from text news to video, a comparative study was conducted to examine how the users perceive the video created by AI and humans. There is no significant difference explicitly, but the implicit appraisals were in favor of human-generated video. The key discussion is the boundary thinking of AI in both the academic and industrial spheres.}
}
@article{TSENG2025106570,
title = {Exploring artificial intelligence literacy and the use of ChatGPT and copilot in instruction on nursing academic report writing},
journal = {Nurse Education Today},
volume = {147},
pages = {106570},
year = {2025},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2025.106570},
url = {https://www.sciencedirect.com/science/article/pii/S026069172500005X},
author = {Li-Ping Tseng and Li-Ping Huang and Wei-Ru Chen},
keywords = {Artificial intelligence literacy, Nursing education, ChatGPT, Copilot, Academic report writing, Scaffolding teaching, Artificial intelligence},
abstract = {Background
Nursing education increasingly emphasizes academic writing and communication, critical for delivering quality patient care and professional advancement. Rapidly emerging artificial intelligence (AI) tools such as ChatGPT and Copilot are transforming educational methodologies, and a focus is being placed on embedding AI literacy to effectively bridge the gap between theoretical knowledge and clinical practice. These technologies have the potential to reshape nursing education in a technology-driven health-care landscape.
Aim
This study investigated the effectiveness of AI literacy and the application of ChatGPT and Copilot in academic nursing report writing. It assessed the level of AI literacy of nursing students, examined the integration of basic AI concepts into a curriculum, and analyzed the impact of these tools compared with traditional teaching methods.
Methods
The study adopted a sample of 203 senior nursing students from Southern Taiwan to compare an AI-enhanced teaching approach using ChatGPT and Copilot with conventional methods. The curriculum, centered on the “Writing Case Reports and Seminars” course, employed the Analyze, Design, Develop, Implement, Evaluate model and incorporated scaffolding techniques to synergistically integrate clinical skills with academic learning. AI literacy was measured using the Meta AI Literacy Scale (MAILS). Summative assessments, adhering to the Taiwan Nursing Association standards, focused on individual and group case report evaluations.
Findings
Following an 18-week AI intervention, the experimental group demonstrated significant improvements in all dimensions of the MAILS. A ChatGPT usage of 100 % was found, with a notable enhancement discovered in the “Nursing Plan” section of case reports. Although the experimental group outperformed the control group in overall case report evaluations, the connections between identified problems and proposed plans were weaker and nursing interventions tended to be less individualized for the experimental group.
Conclusions
The incorporation of AI tools such as ChatGPT and Copilot into a scaffolding teaching framework significantly boosted students' AI literacy and performance in summative assessments. Effective AI training for students, supervised use of these tools, and continuous professional development for educators are paramount to successful implementation. Addressing the current limitations of AI has the potential to further improve academic writing, foster critical thinking, and ensure responsible application in patient care, ultimately leading to higher-quality and more effective nursing education.}
}
@article{GREGOR19981481,
title = {A computational study of the focus-of-attention EM-ML algorithm for PET reconstruction1Research supported in part by the National Science Foundation under grant CDA-95-29459.1},
journal = {Parallel Computing},
volume = {24},
number = {9},
pages = {1481-1497},
year = {1998},
issn = {0167-8191},
doi = {https://doi.org/10.1016/S0167-8191(98)00067-2},
url = {https://www.sciencedirect.com/science/article/pii/S0167819198000672},
author = {Jens Gregor and Dean A. Huff},
keywords = {Distributed computing, Expectation-maximization, Image reconstruction, Positron emission tomography},
abstract = {The expectation-maximization maximum-likelihood (EM-ML) algorithm for image reconstruction in positron emission tomography (PET) essentially solves a large linear system of equations. In this paper, we study computational aspects of a recently developed preprocessing scheme for focusing the attention, and thus the computational resources, on a subset of the equations and unknowns in order to reduce the storage, computation, and communication requirements of the EM-ML algorithm. The approach is completely data-driven and uses no prior anatomic knowledge. The experimental results are obtained from runs on a small network of workstations using simulated phantom data as well as data obtained from a clinical ECAT 921 PET scanner.}
}
@article{SNODGRASS20161,
title = {Instructional supports for students with disabilities in K-5 computing: Findings from a cross-case analysis},
journal = {Computers & Education},
volume = {100},
pages = {1-17},
year = {2016},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2016.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S0360131516300999},
author = {Melinda R. Snodgrass and Maya Israel and George C. Reese},
keywords = {Universal design for learning, Students with disabilities, Pedagogy, Supports},
abstract = {As computer programming and computational thinking (CT) become more integrated into K-12 instruction, content teachers and special educators need to understand how to provide instructional supports to a wide range of learners, including students with disabilities. This cross-case analysis study examined the supports that two students with disabilities, who were initially disengaged during computing activities, received during computing instruction. Data revealed that students' support needs during computing activities were not CT-specific. Rather, supports specific to these students' needs that were successful in other educational areas were also successful and sufficient in CT. Although additional studies would need to be conducted to ascertain the transferability of these findings to other contexts and students, our results contribute evidence that students with disabilities can and should participate in CT and be provided with the supports they need, just as in all other areas of the curriculum. We present a framework for evaluating student engagement to identify student-specific supports and, when needed, refine the emerging K-12 CT pedagogy to facilitate full participation of all students. We then offer a list of four implications for practice based on the findings.}
}
@article{MATTHEWS201973,
title = {Introducing a computational method to estimate and prioritize systemic body exposure of organic chemicals in humans using their physicochemical properties},
journal = {Computational Toxicology},
volume = {9},
pages = {73-99},
year = {2019},
issn = {2468-1113},
doi = {https://doi.org/10.1016/j.comtox.2018.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S2468111318300276},
author = {Edwin John Matthews},
keywords = {Absorption, Bioavailability, Chemical disposition, Data-gaps, Distribution, Food ingredient, GRAS, Hazard identification, , OCS (optimal chemical space), Pharmacokinetics, Physicochemical property, Preservative, Prioritization, QSAR, QSPR, Read-across, Risk-ranking, Sequestration, Signal-detection, Toxicokinetics},
abstract = {This report describes a computational method developed to predict systemic exposure (s-exposure), chemical disposition {(CD) intestinal absorption, transport, membrane permeability, distribution, sequestration, phospholipidosis and toxicokinetics} of organic chemicals in humans. The method qualitatively and quantitatively estimates a chemical's CD activity profile based upon computed molecular descriptor properties (descriptors), and it facilitates in silico signal-detection of data-gaps, prioritization, risk-ranking, read-across, and re-assessments (if mandated) of large sets of chemicals in a safety evaluation setting. The investigation used a reference set of 2372 marketed human pharmaceuticals to define decision rules for an optimal chemical space (OCS) in which chemicals have high s-exposure, good CD, and a potential for chemical toxicity (CT); conversely, chemicals outside the OCS have low s-exposure, poor CD into the body, and low potential for CT. The method requires computation of 29 descriptors, identification of OCS molecular descriptor property violations (descriptor_violations), and alignment of descriptor_violations with specific decision rules for individual CD endpoint activities. The investigation predicted the CD activities of food and cosmetic preservatives, ingredients in GRAS (generally recognized as safe). Notices submitted to the FDA, reference pharmaceuticals, and it provides prioritization metrics and indices that facilitate prioritization of chemical in silico computed CD activities.}
}
@article{ERVIN201612,
title = {Technology in geodesign},
journal = {Landscape and Urban Planning},
volume = {156},
pages = {12-16},
year = {2016},
note = {Geodesign—Changing the world, changing design},
issn = {0169-2046},
doi = {https://doi.org/10.1016/j.landurbplan.2016.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S0169204616301888},
author = {Stephen M. Ervin},
keywords = {Geodesign, Algorithmic processes, Collaboration, Dynamic modeling, Simulation, Systems thinking},
abstract = {Based on an idealized model with six distinguishing criteria of geodesign projects -- large areas, complex issues, and multi-person teams; digital computing, algorithmic processes, and communications technologies; collaborative, information-based projects; timely feedback about impacts and implications of proposals; dynamic modeling and simulation; and systems thinking -- the technological supports required for each of these criteria are described.}
}
@article{SINGH2024483,
title = {How has the AI boom impacted algorithmic biology?},
journal = {Cell Systems},
volume = {15},
number = {6},
pages = {483-487},
year = {2024},
issn = {2405-4712},
doi = {https://doi.org/10.1016/j.cels.2024.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S2405471224001522},
author = {Mona Singh and Cenk Sahinalp and Jianyang Zeng and Wei Vivian Li and Carl Kingsford and Qiangfeng Zhang and Teresa Przytycka and Joshua Welch and Jian Ma and Bonnie Berger},
abstract = {This Voices piece will highlight the impact of artificial intelligence on algorithm development among computational biologists. How has worldwide focus on AI changed the path of research in computational biology? What is the impact on the algorithmic biology research community?}
}
@article{BOTTINI2020606,
title = {Knowledge Across Reference Frames: Cognitive Maps and Image Spaces},
journal = {Trends in Cognitive Sciences},
volume = {24},
number = {8},
pages = {606-619},
year = {2020},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2020.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S1364661320301327},
author = {Roberto Bottini and Christian F. Doeller},
keywords = {conceptual knowledge, space, hippocampus, parietal lobe, conceptual metaphors, analogy},
abstract = {In human and non-human animals, conceptual knowledge is partially organized according to low-dimensional geometries that rely on brain structures and computations involved in spatial representations. Recently, two separate lines of research have investigated cognitive maps, that are associated with the hippocampal formation and are similar to world-centered representations of the environment, and image spaces, that are associated with the parietal cortex and are similar to self-centered spatial relationships. We review evidence supporting cognitive maps and image spaces, and we propose a hippocampal–parietal network that can account for the organization and retrieval of knowledge across multiple reference frames. We also suggest that cognitive maps and image spaces may be two manifestations of a more general propensity of the mind to create low-dimensional internal models.}
}
@article{SINGH2012185,
title = {Towards an integrated generative design framework},
journal = {Design Studies},
volume = {33},
number = {2},
pages = {185-207},
year = {2012},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2011.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X11000391},
author = {Vishal Singh and Ning Gu},
keywords = {generative design, architectural design, digital design, design cognition, reflective practise},
abstract = {Design creativity techniques encourage divergent thinking. But how well do the existing generative design techniques support this requirement? How can these general techniques be augmented for supporting design exploration and creativity? This paper investigates these questions through a review of five different generative design techniques used in architectural design that includes cellular automata, genetic algorithms, L-systems, shape grammars, and swarm intelligence. Based on the literature on design cognition and the recent theoretical works on digital design thinking, this paper proposes the need for an integrated generative design framework to enhance design exploration support for human designers. Potential challenges and strategies towards developing such an integrated framework are discussed.}
}
@article{CRUJEIRAS2013208,
title = {Challenges in the implementation of a competency-based curriculum in Spain},
journal = {Thinking Skills and Creativity},
volume = {10},
pages = {208-220},
year = {2013},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2013.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S187118711300045X},
author = {Beatriz Crujeiras and María Pilar Jiménez-Aleixandre},
keywords = {Scientific competency, Epistemic practices, Higher-order thinking, Policy},
abstract = {This paper addresses some of the challenges involved in implementing the new approach established in the Spanish National Curriculum in 2006, which brought as a major change a focus on the development of key competencies. The paper focuses on scientific competency and the challenges involved in the itinerary from policy documents to classrooms are addressed in three sections: (i) an analysis is made of the changes in the science curriculum as a consequence of the emphasis on scientific competency, comparing the assessment criteria in the previous and current steering documents; (ii) trends in teacher education are discussed; (iii) the findings of the diagnostic evaluation are analyzed. The paper is framed in a theoretical approach, viewing students’ participation in scientific practices, and the development of higher-order thinking as necessary goals of science education. We argue that the focus on competencies, characterized as the ability to apply knowledge and skills in new contexts, involves a major change towards knowledge transfer and higher-order thinking skills. Some issues emerging from the analysis relate to the implications of assessment criteria and the challenges involved in its implementation, to the trends in teacher professional development and the difficulties related to the current economic crisis and to the results of the diagnostic evaluation and time frame needed for reforms to have an impact. It is argued that the development of both competencies and higher-order thinking requires students’ prolonged engagement.}
}
@article{DOWNES1993229,
title = {Modeling scientific practice: Paul Thagard's computational approach},
journal = {New Ideas in Psychology},
volume = {11},
number = {2},
pages = {229-243},
year = {1993},
issn = {0732-118X},
doi = {https://doi.org/10.1016/0732-118X(93)90036-D},
url = {https://www.sciencedirect.com/science/article/pii/0732118X9390036D},
author = {Stephen Downes},
abstract = {In this paper I examine Paul Thagard's computational approach to studying science, which is a contribution to the cognitive science of science. I present several criticisms of Thagard's approach and use them to motivate some suggestions for alternative approaches in cognitive science of science. I first argue that Thagard does not clearly establish the units of analysis of his study. Second, I argue that Thagard mistakenly applies the same model to both individual and group decision making. Finally, I argue that in attempting to account for psychological and social processes as well as providing a philosophical model of successful reasoning Thagard attempts to explain too much with one model, thus straining the plausibility of his model.}
}
@article{SONG2023100812,
title = {Robert Mare’s legacy: Multi-generational processes},
journal = {Research in Social Stratification and Mobility},
volume = {88},
pages = {100812},
year = {2023},
note = {Robert D. Mare’s Legacy},
issn = {0276-5624},
doi = {https://doi.org/10.1016/j.rssm.2023.100812},
url = {https://www.sciencedirect.com/science/article/pii/S0276562423000562},
author = {Xi Song},
abstract = {This paper summarizes some of Robert Mare’s major contributions as a sociologist, demographer, and social statistician; as a pioneer who advanced the multi-generational perspective in social science research; as a leader who introduced demographic thinking to social mobility studies; and as a trailblazer who developed new approaches to studying multi-generational processes}
}
@article{ZHONG2016423,
title = {The impact of social factors on pair programming in a primary school},
journal = {Computers in Human Behavior},
volume = {64},
pages = {423-431},
year = {2016},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2016.07.017},
url = {https://www.sciencedirect.com/science/article/pii/S0747563216305064},
author = {Baichang Zhong and Qiyun Wang and Jie Chen},
keywords = {Primary education, Pair programming, Social factors, Gender, Partnership},
abstract = {Pair programming (PP) is a usefulness approach to fostering computational thinking (CT) for young students. However, there are many factors to impact the effectiveness of PP. Among all factors, the social factors are often ignored by researchers. Therefore, this study aimed to explore the impact of two social factors (gender and partnership) on PP in a primary school setting. To that end, we conducted PP experiments in four classes from the sixth grade in a Chinese primary school. The research results indicated: (a) there was no significant difference on compatibility among the gender pairs, but a significant difference among partnership pairs; (b) there was no significant difference on programming achievement and confidence among different pairs, and girls became more productive and confidence in PP; and (c) PP tightened up the partnership within pairs. These findings suggest that teachers should take partnership into account as an important factor in PP or other collaborative learning, and adopt PP as an effective approach to decrease the gender gap in programming courses, and make students socialize.}
}
@article{LIU2025101664,
title = {Interdigitated microband electrode arrays in paired organic electrosyntheses: Sustainability and practicality},
journal = {Current Opinion in Electrochemistry},
volume = {50},
pages = {101664},
year = {2025},
issn = {2451-9103},
doi = {https://doi.org/10.1016/j.coelec.2025.101664},
url = {https://www.sciencedirect.com/science/article/pii/S2451910325000237},
author = {Tingran Liu and Taku Suzuki-Osborne and James E. Taylor and Frank Marken},
abstract = {Electrochemical synthesis is well established for production of bulk commodities such as copper, aluminium, or ethylene oxide, but electrosynthesis could play an increasingly important role also in a broader range of organic and pharmaceutical syntheses. Electrochemical transformations linked to renewable electricity offer a low-carbon low-waste alternative to traditional chemical reactions (sustainability), although more work is needed to establish processes and reactor technology for easy implementation (practicality). Here, the application of interdigitated microband array electrodes (in conjunction with computational methods) is discussed/contrasted as a tool to (i) avoid the use of added supporting electrolyte, (ii) achieve anode–cathode process pairing, and (iii) allow very simple reactor technology to be introduced compatible with existing chemical reactionware.}
}
@article{SHI2024e35268,
title = {3D dynamic landscape simulation of artificial intelligence in environmental landscape design},
journal = {Heliyon},
volume = {10},
number = {15},
pages = {e35268},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e35268},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024112996},
author = {Binbin Shi},
keywords = {Artificial intelligence, Environmental landscape design, Fuzzy analytical hierarchical process, Geographical information system, 3D dynamic landscape, Interactive design system},
abstract = {Three-dimensional (3D) simulations and precise landscape visualizations are crucial for various applications, like landscape management and planning, computer and connection of the landscape, evaluation, and tracking of land use. The consequences of several plans and a large scene cannot be communicated using older methods of comprehensive environmental planning and development in a timely, rational, and coordinated manner. Architects have trouble incorporating ideas into other comprehensive planning implementation processes. Architects did not thoroughly investigate the neighbourhood's demographics and matching behavioural needs and lacked critical thinking. The 3D dynamic landscape simulation is a detailed computerized three-dimensional simulation of the environment that can be dynamically presented. With the aid of Artificial Intelligence (AI) technology, the system possesses a strong sense of reality, a user-friendly interface, and interactive features that can be tailored to the requirements of the contemporary urban environmental landscape. Regarding exterior publicity, domestic assistance, environmental land use planning, and information systems. The novelty of the proposed Interactive Design System based on AI (IDS-AI) is to create a 3D dynamic landscape model based on a real-life environmental scene, utilizing a Geographic Information System (GIS) to optimize landscape vision. Secondly, 3D environmental landscape design simulation was implemented using GIS spatial analysis in conjunction with the Fuzzy Analytical Hierarchical Process (FAHP) to reduce the data overlap rate and help make an accurate decision. Finally, the design incorporates the development of the interactive interface system application of landscape design and environmental resources for viewing the landscape, the factors that affect them, and the area coverage ratio of various land cover types. The experimental outcomes show that the suggested IDS model increases the gradient sensitivity level of 98.3 % and area coverage ratio of 93.4 % compared to other existing models.}
}
@incollection{PENN2012143,
title = {Computational Linguistics},
editor = {Ruth Kempson and Tim Fernando and Nicholas Asher},
booktitle = {Philosophy of Linguistics},
publisher = {North-Holland},
address = {Amsterdam},
pages = {143-173},
year = {2012},
series = {Handbook of the Philosophy of Science},
issn = {18789846},
doi = {https://doi.org/10.1016/B978-0-444-51747-0.50005-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780444517470500056},
author = {Gerald Penn}
}
@article{PARK2025,
title = {Development and Validation of the Digital Sensitivity Scale for Adults: Cross-Sectional Observational Study},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/55828},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125000470},
author = {Hae In Park and Minjeong Jeon and Ji Seon Ahn and Kyungmi Chung and Jin Young Park},
keywords = {information literacy, health literacy, computer literacy, self-efficacy, attitude, digital divide},
abstract = {Background
The COVID-19 pandemic has accelerated the digitalization of modern society, extending digital transformation to daily life and psychological evaluation and treatment. However, the development of competencies and literacy in handling digital technology has not kept pace, resulting in a significant disparity among individuals. Existing measurements of digital literacy were developed before widespread information and communications technology device adoption, mainly focusing on one’s perceptions of their proficiency and the utility of device operation. In the contemporary landscape, digital transformation is evolving within specialized domains, necessitating a comprehensive evaluation of digital competencies, attitudes, and proficiency in technology application to bridge the digital divide and ensure digital compliance.
Objective
This study was designed to address the shortcomings of existing scales and formulate a digital sensitivity scale tailored to the requirements of today’s society.
Methods
Initial items of the Yongin Severance Digital Sensitivity Scale (YI-DSS) were collected through a literature review, and expert opinions were gathered to ensure content validity. An exploratory and confirmatory factor analysis included 986 adult participants evaluating 14 digital literacy items and 6 digital efficacy items. The Cronbach α confirmed internal consistency reliability, and 2-tailed t tests, ANOVAs, and post hoc tests analyzed demographic differences in digital literacy and efficacy.
Results
A robust 4-factor digital literacy solution was identified: digital application, digital communication, critical thinking, and digital ethics (Kaiser-Meyer-Olkin=0.891; Bartlett × 2=9829.713; P<.001; Cronbach α=0.782-0.947). A 2-factor solution defined digital efficacy: digital confidence and digital anxiety (Kaiser-Meyer-Olkin=0.735; Bartlett × 2=3282.217; P<.001; Cronbach α=0.787-0.912). Confirmatory factor analysis was conducted for each model (digital literacy model: χ271=676.0, comparative fit index=0.938, Tucker-Lewis index=0.921, standardized root mean square residual=0.73, and root mean square error of approximation=0.093; digital efficacy model: χ28=81.9, comparative fit index=0.977, Tucker-Lewis index=0.958, standardized root mean square residual=0.73, and root mean square error of approximation=0.097), which indicated a good fit. The YI-DSS also showed high correlation with the previously developed Digital Literacy Scale (r=0.809; P<.001).
Conclusions
The YI-DSS, as a self-assessment tool, has the potential to bridge the generational information gap by promoting acceptance, motivation, and adaptation to digital technology. Furthermore, given the remote nature of digital therapeutics, an individual’s familiarity with required technologies and digital communication strongly influences their acceptance of digital treatments and the efficacy thereof. This scale can play a pivotal role in enhancing compliance with digital therapeutics by preemptively assessing individuals’ technological literacy and competency.}
}
@article{CASH2023101219,
title = {Method in their madness: Explaining how designers think and act through the cognitive co-evolution model},
journal = {Design Studies},
volume = {88},
pages = {101219},
year = {2023},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2023.101219},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X23000601},
author = {Philip Cash and Milene Gonçalves and Kees Dorst},
keywords = {co-evolution, design process(es), design cognition, design thinking, creativity},
abstract = {Designers often face situations where the only way forward is through the exploration of possibilities. However, there is a critical disconnect between understanding of how designer’s think and act in such situations. We address this disconnect by proposing and testing (via protocol analysis) the cognitive co-evolution model. Our model comprises a new approach to co-evolutionary design theory by explaining both the progression of the process itself and the creation of design outputs via an interplay between metacognitive perceived uncertainty, cognition, and the external world. We thus connect explanations of how designers think with descriptions of how they act. We provide a foundation for connecting to other theories, models, and questions in design research via common links to cognition and metacognition.}
}
@article{KIM20141,
title = {Studying children's tactile problem-solving in a digital environment},
journal = {Thinking Skills and Creativity},
volume = {12},
pages = {1-13},
year = {2014},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2013.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S1871187113000734},
author = {Mi Jeong Kim and Myung Eun Cho},
keywords = {Children's problem solving, Tactile interaction, Cognitive perspectives, Empirical study, Protocol analysis},
abstract = {Given that modern children have grown up with numerous digital interactive devices it is essential to understand how the digital environment might affect children's cognitive development. As an extension of previous studies, this research investigates the cognitive effects of tactile interaction on children's problem solving. In order to explore the cognitive development of children with respect to tactile interaction, we compared furniture arrangements by elementary school students of 3D blocks and pencils. A protocol analysis was adopted for examining the ways in which children used the two different tools. The results of this study show that tactile interaction supports children's problem solving. This research implies that children in early education need to experience a wide range of digital devices utilizing rich sensorial dimensions as such devices stimulate divergent thinking, affecting cognitive developmental trajectories.}
}
@article{RAJAN2024R1221,
title = {Cellular cognition: How single cells learn using non-neural networks},
journal = {Current Biology},
volume = {34},
number = {24},
pages = {R1221-R1223},
year = {2024},
issn = {0960-9822},
doi = {https://doi.org/10.1016/j.cub.2024.11.016},
url = {https://www.sciencedirect.com/science/article/pii/S0960982224015239},
author = {Deepa H. Rajan and Wallace F. Marshall},
abstract = {Summary
Single cells can perform surprisingly complex behaviors and computations, including primitive forms of learning like habituation. New work highlighted here uses mathematical modeling to show that relatively simple biochemical networks can recapitulate many features of habituation in animals.}
}
@article{LASAPONARA202460,
title = {Temperament and probabilistic predictive coding in visual-spatial attention},
journal = {Cortex},
volume = {171},
pages = {60-74},
year = {2024},
issn = {0010-9452},
doi = {https://doi.org/10.1016/j.cortex.2023.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S0010945223002599},
author = {Stefano Lasaponara and Gabriele Scozia and Silvana Lozito and Mario Pinto and David Conversi and Marco Costanzi and Tim Vriens and Massimo Silvetti and Fabrizio Doricchi},
keywords = {Attention, Temperament, Personality, Posner task, Neurotransmitters},
abstract = {Cholinergic (Ach), Noradrenergic (NE), and Dopaminergic (DA) pathways play an important role in the regulation of spatial attention. The same neurotransmitters are also responsible for inter-individual differences in temperamental traits. Here we explored whether biologically defined temperamental traits determine differences in the ability to orient spatial attention as a function of the probabilistic association between cues and targets. To this aim, we administered the Structure of Temperament Questionnaire (STQ-77) to a sample of 151 participants who also performed a Posner task with central endogenous predictive (80 % valid/20 % invalid) or non-predictive cues (50 % valid/50 % invalid). We found that only participants with high scores in Plasticity and Intellectual Endurance showed a selective abatement of attentional costs with non-predictive cues. In addition, stepwise regression showed that costs in the non-predictive condition were negatively predicted by scores in Plasticity and positively predicted by scores in Probabilistic Thinking. These results show that stable temperamental characteristics play an important role in defining the inter-individual differences in attentional behaviour, especially in the presence of different probabilistic organisations of the sensory environment. These findings emphasize the importance of considering temperamental and personality traits in social and professional environments where the ability to control one's attention is a crucial functional skill.}
}
@article{WILLIAMS2009420,
title = {Analysis of externally loaded bolted joints: Analytical, computational and experimental study},
journal = {International Journal of Pressure Vessels and Piping},
volume = {86},
number = {7},
pages = {420-427},
year = {2009},
issn = {0308-0161},
doi = {https://doi.org/10.1016/j.ijpvp.2009.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0308016109000179},
author = {J.G. Williams and R.E. Anley and D.H. Nash and T.G.F. Gray},
keywords = {Bolted joints, Pre-loading, Bolt stiffness, Member stiffness, Member contact},
abstract = {The behaviour of a simple single-bolted-joint under tensile separating loads is analysed using conventional analytical methods, a finite element approach and experimental techniques. The variation in bolt force with external load predicted by the finite element analysis conforms well to the experimental results. It is demonstrated that certain detailed features such as thread interaction do not need to be modelled to ensure useful results. Behaviour during the pre-loading phase of use agrees with previous long-standing studies. However, the pre-loading analysis does not carry over to the stage when external loading is applied, as is normally assumed and it is shown that the current, conventional analytical methods substantially over-predict the proportion of the external load carried by the bolt. The basic reason for this is shown to be related to the non-linear variation in contact conditions between the clamped members during the external loading stage.}
}
@article{ZENASNI201149,
title = {Pleasantness of creative tasks and creative performance},
journal = {Thinking Skills and Creativity},
volume = {6},
number = {1},
pages = {49-56},
year = {2011},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2010.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S1871187110000404},
author = {Franck Zenasni and Todd Lubart},
keywords = {Creativity, Perceived pleasantness, Emotion, Story writing, Divergent thinking},
abstract = {To examine the impact of emotion on creative potential, experimental studies have typically focused on the impact of induced or spontaneous mood states on creative performance. In this report the relationship between the perceived pleasantness of tasks (using divergent thinking and story writing tasks) and creative performance was examined. Overall perceived pleasantness did not differ between tasks. However, results indicate that the perceived pleasantness of the story writing task increased during task completion whereas the perceived pleasantness of divergent thinking tasks remained stable during task performance. The number of generated ideas in a divergent thinking task (fluency) was significantly related to overall perceived pleasantness of the task.}
}
@article{DONG2022134394,
title = {Understanding robustness in multiscale nutrient abatement: Probabilistic simulation-optimization using Bayesian network emulators},
journal = {Journal of Cleaner Production},
volume = {378},
pages = {134394},
year = {2022},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2022.134394},
url = {https://www.sciencedirect.com/science/article/pii/S095965262203966X},
author = {Feifei Dong and Jincheng Li and Chao Dai and Jie Niu and Yan Chen and Jiacong Huang and Yong Liu},
keywords = {Diffuse nutrient, BMPs, Machine learning, Uncertainty, Simulation-optimization, Bayesian network},
abstract = {Ecosystem management in the face of uncertain disturbances has triggered increasing practices of resilience thinking. A multiscale probabilistic simulation-optimization framework is developed based on the nested nature of watersheds to inform decision robustness for Best Management Practices (BMPs). We presented a novel approach using hybrid Bayesian Networks (BNs) as interpretable and probabilistic emulators of process-based models. The hybrid BNs established at the scale of Hydrologic Response Units (HRUs) are embedded into simulation-optimization, whereby we analyze the cost-effectiveness-robustness of candidate BMP strategies at the subbasin scale. The optimal strategy is identified in compliance with water quality standards using watershed-scale integer programming. We apply the approaches in a typical intensively cultivated plateau watershed adjacent to Lake Dianchi, one of the three most eutrophic lakes in China. Our findings suggest that the hybrid BNs, incorporating both quantitative and qualitative information, are reliable emulators of the Soil and Water Assessment Tool (SWAT) in capturing critical pathways of diffuse phosphorus. Tradeoffs among cost, effectiveness, and robustness follow the law of diminishing marginal benefits. The optimum BMP strategies vary with policymakers’ preference toward robustness levels. Our findings indicate that robustness should be accounted for as an additional decision attribute besides costs and pollution mitigation. The benefits of the modeling framework are to (i) reduce over 99% computation complexity and support efficient decision-making under multifaceted uncertainties; (ii) improve interpretability and reliability of machine learning emulators; and (iii) inform policymakers of robustness with the probability of water quality restoration success.}
}
@article{STONE2004781,
title = {Intention, interpretation and the computational structure of language},
journal = {Cognitive Science},
volume = {28},
number = {5},
pages = {781-809},
year = {2004},
note = {2003 Rumelhart Prize Special Issue Honoring Aravind K. Joshi},
issn = {0364-0213},
doi = {https://doi.org/10.1016/j.cogsci.2004.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S036402130400062X},
author = {Matthew Stone},
keywords = {Dialogue, Pragmatics, Tree adjoining grammar},
abstract = {I show how a conversational process that takes simple, intuitively meaningful steps may be understood as a sophisticated computation that derives the richly detailed, complex representations implicit in our knowledge of language. To develop the account, I argue that natural language is structured in a way that lets us formalize grammatical knowledge precisely in terms of rich primitives of interpretation. Primitives of interpretation can be correctly viewed intentionally, as explanations of our choices of linguistic actions; the model therefore fits our intuitions about meaning in conversation. Nevertheless, interpretations for complex utterances can be built from these primitives by simple operations of grammatical derivation. In bridging analyses of meaning at semantic and symbol-processing levels, this account underscores the fundamental place for computation in the cognitive science of language use.}
}
@article{CEKIRGE199461,
title = {Oil spill modeling using parallel computations},
journal = {Spill Science & Technology Bulletin},
volume = {1},
number = {1},
pages = {61-68},
year = {1994},
issn = {1353-2561},
doi = {https://doi.org/10.1016/1353-2561(94)90008-6},
url = {https://www.sciencedirect.com/science/article/pii/1353256194900086},
author = {H.M. Cekirge and C.P. Giammona and J. Berlin and C. Long and M. Koch and R. Jamail},
abstract = {The current status of oil spill modeling is presented. The physical and chemical processes taking place in oil spills are explained for the design of an ideal oil spill model (IOSM). The requirements of an IOSM for forecasting are rapid response, contingency planning and training. The use of parallel computation techniques in oil spill modeling is introduced and delineated.}
}
@article{HSU2011380,
title = {The probabilistic analysis of language acquisition: Theoretical, computational, and experimental analysis},
journal = {Cognition},
volume = {120},
number = {3},
pages = {380-390},
year = {2011},
note = {Probabilistic models of cognitive development},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2011.02.013},
url = {https://www.sciencedirect.com/science/article/pii/S0010027711000734},
author = {Anne S. Hsu and Nick Chater and Paul M.B. Vitányi},
keywords = {Child language acquisition, Poverty of the stimulus, No negative evidence, Bayesian models, Minimum description length, Simplicity principle, Natural language, Probabilistic models, Identification in the limit},
abstract = {There is much debate over the degree to which language learning is governed by innate language-specific biases, or acquired through cognition-general principles. Here we examine the probabilistic language acquisition hypothesis on three levels: We outline a novel theoretical result showing that it is possible to learn the exact generative model underlying a wide class of languages, purely from observing samples of the language. We then describe a recently proposed practical framework, which quantifies natural language learnability, allowing specific learnability predictions to be made for the first time. In previous work, this framework was used to make learnability predictions for a wide variety of linguistic constructions, for which learnability has been much debated. Here, we present a new experiment which tests these learnability predictions. We find that our experimental results support the possibility that these linguistic constructions are acquired probabilistically from cognition-general principles.}
}
@article{HOWARD2006464,
title = {Cumulative semantic inhibition in picture naming: experimental and computational studies},
journal = {Cognition},
volume = {100},
number = {3},
pages = {464-482},
year = {2006},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2005.02.006},
url = {https://www.sciencedirect.com/science/article/pii/S0010027705001393},
author = {David Howard and Lyndsey Nickels and Max Coltheart and Jennifer Cole-Virtue},
keywords = {Semantic inhibition, Spoken word production, Picture naming, Competition, Word retrieval, Computational modelling, Priming},
abstract = {We report an experiment in which subjects named 120 pictures, consisting of series of five pictures drawn from each of 24 semantic categories (and intermixed with 45 fillers). The number of intervening trials (lag) between successive presentations of members of the same category varied from two to eight. Subjects' naming latencies were slowed by 30ms for each preceding member of the category. This effect was both cumulative and linear, and unrelated to the lag elapsing since the previous presentation of a category member. These results definitively demonstrate the occurrence of cumulative interference for word retrieval by prior retrieval of other exemplars of the same semantic category—cumulative semantic inhibition. We claim that this inhibition effect could only occur if the spoken word production system possesses three specific properties (competition, priming, and sharing of semantic activation). We provide computational-modelling evidence in support of this claim. We show that no current theory of spoken word production has all of these properties. In their current form, all these theories are falsified by these results. We briefly discuss the obstacles that may be encountered by current models were they modified to account for our findings.}
}
@article{POHL201654,
title = {Using lag-sequential analysis for understanding interaction sequences in visualizations},
journal = {International Journal of Human-Computer Studies},
volume = {96},
pages = {54-66},
year = {2016},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2016.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S1071581916300829},
author = {Margit Pohl and Günter Wallner and Simone Kriglstein},
keywords = {Interaction sequences, Lag-sequential analysis, Visualization, Log files, Thinking aloud},
abstract = {The investigation of how users make sense of the data provided by information systems is very important for human computer interaction. In this context, understanding the interaction processes of users plays an important role. The analysis of interaction sequences, for example, can provide a deeper understanding about how users solve problems. In this paper we present an analysis of sequences of interactions within a visualization system and compare the results to previous research. We used log file analysis and thinking aloud as methods. There is some indication based on log file analysis that there are interaction patterns which can be generalized. Thinking aloud indicates that some cognitive processes occur together with a higher probability than others.}
}
@article{GRETREGAMEY2024104978,
title = {Key factors to enhance efficacy of 3D digital environments for transformative landscape and urban planning},
journal = {Landscape and Urban Planning},
volume = {244},
pages = {104978},
year = {2024},
issn = {0169-2046},
doi = {https://doi.org/10.1016/j.landurbplan.2023.104978},
url = {https://www.sciencedirect.com/science/article/pii/S0169204623002979},
author = {Adrienne Grêt-Regamey and Nora Fagerholm},
abstract = {The unprecedented expansion of digital technologies has led to a rapid increase in the development and application of 3D digital environments for landscape and urban planning in the past two decades. Considering the significant challenges in guiding human societies towards sustainability, these technologies must not only assist decision-makers in adapting to changes but promote fast, transformative shifts in the relationship between human societies and nature. Based on a set of global exemplars, this Perspective Essay outlines six key factors that can enhance efficacy of 3D digital environments to guide knowledge-informed landscape and urban planning. We call for (1) explicitly representing dynamic interplay between the social, ecological, and technical systems, (2) exploring the integration of design with simulation models to address cross-scale dynamics, (3) developing features to foster imagination, (4) employing multisensory stimuli to encourage profound changes in environmentally and socially sustainable behavior, (5) tailoring the incorporation of active sensing by and with non-experts into 3D digital environments to better acknowledge indigenous and local knowledge systems, and finally, (6) carrying out a usability evaluation to facilitate participation and collaboration in an efficient co-creation process. We conclude by recommending the establishment of a collaborative knowledge platform that unites researchers, developers, and stakeholders for stimulating social-ecological-technological system thinking in the development of 3D digital environments and harnessing the technological advancements to accelerate and drive the needed transformative change within urban and landscape planning.}
}
@article{ARKOUDAS2008461,
title = {Computation, hypercomputation, and physical science},
journal = {Journal of Applied Logic},
volume = {6},
number = {4},
pages = {461-475},
year = {2008},
note = {The Philosophy of Computer Science},
issn = {1570-8683},
doi = {https://doi.org/10.1016/j.jal.2008.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S1570868308000414},
author = {Konstantine Arkoudas},
keywords = {Hypercomputation, Church–Turing thesis, Gandy's thesis, Mechanical computability, Algorithms, Turing limit, Physical science, Physical computability},
abstract = {Copeland and others have argued that the Church–Turing thesis (CTT) has been widely misunderstood by philosophers and cognitive scientists. In particular, they have claimed that CTT is in principle compatible with the existence of machines that compute functions above the “Turing limit,” and that empirical investigation is needed to determine the “exact membership” of the set of functions that are physically computable. I argue for the following points: (a) It is highly doubtful that philosophers and cognitive scientists have widely misunderstood CTT as alleged.1 In fact, by and large, computability theorists and mathematical logicians understand CTT in the exact same way. (b) That understanding most likely coincides with what Turing and Church had in mind. Even if it does not, an accurate exegesis of Turing and Church need not dictate how today's working scientists understand the thesis. (c) Even if we grant Copeland's reading of CTT, an orthodox stronger version of it which he rejects (Gandy's thesis) follows readily if we only accept a highly plausible necessary condition for what constitutes a deterministic digital computer. Finally, (d) regardless of whether we accept this condition, the prospects for a scientific theory of hypercomputation are exceedingly poor because physical science does not have the wherewithal to investigate computability or to discover its ultimate “limit.”}
}
@article{TAGHIKHAH2022101854,
title = {Machine-assisted agent-based modeling: Opening the black box},
journal = {Journal of Computational Science},
volume = {64},
pages = {101854},
year = {2022},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2022.101854},
url = {https://www.sciencedirect.com/science/article/pii/S1877750322002137},
author = {Firouzeh Taghikhah and Alexey Voinov and Tatiana Filatova and J. Gareth Polhill},
keywords = {Behavioral analytics, Social communications, Interpretable artificial intelligence, Conceptual modeling, Systems thinking},
abstract = {While agent-based modeling (ABM) has become one of the most powerful tools in quantitative social sciences, it remains difficult to explain their structure and performance. We propose to use artificial intelligence both to build the models from data, and to improve the way we communicate models to stakeholders. Although machine learning is actively employed for pre-processing data, here for the first time, we used it to facilitate model development of a simulation model directly from data. Our suggested framework, ML-ABM accounts for causality and feedback loops in a complex nonlinear system and at the same time keeps it transparent for stakeholders. As a result, beside the development of a behavioral ABM, we open the ‘blackbox’ of purely empirical models. With our approach, artificial intelligence in the simulation field can open a new stream in modeling practices and provide insights for future applications.}
}
@article{BYTYQIDAMONI2024137516,
title = {Synthesis, characterization, and computational study of novel carvacrol-based 2-aminothiol and sulfonic acid derivatives as metabolic enzyme inhibitors},
journal = {Journal of Molecular Structure},
volume = {1303},
pages = {137516},
year = {2024},
issn = {0022-2860},
doi = {https://doi.org/10.1016/j.molstruc.2024.137516},
url = {https://www.sciencedirect.com/science/article/pii/S0022286024000395},
author = {Arlinda Bytyqi-Damoni and Eda Mehtap Uc and Rıfat Emin Bora and Hayriye Genc Bilgicli and Mehmet Abdullah Alagöz and Mustafa Zengin and İlhami Gülçin},
keywords = {Carvacrol, Carbonic anhydrase, α-glucosidase, Acetylcholinesterase, Butyrylcholinesterase},
abstract = {Eight new 2-aminothiols (69–96%) and three new sulfonic acids (51–76%) were synthesized and characterized by NMR and HRMS spectra. This study presents the inhibitory effects of a series of novel carvacrol-based 2-aminothiol and sulfonic acid derivatives (3a-f,4a-c) against human carbonic anhydrase I and II isozymes (hCA I and II) acetylcholinesterase (AChE), butyrylcholinesterase (BChE) and α-glycosidase. Ki values were calculated as 12.52±3.61–335.65±60.56 nM for hCA I, 12.20±3.59–389.69±119.41 nM for hCA II, 1.79±0.56–84.86±23.34 nM for AChE, 6.57±2.54–88.05±21.05 nM for BChE and 14.63±4.76–116.39±33.70 nM α-glucosidase enzymes. Also, the inhibition effects of novel carvacrol-based 2-aminothiol (3a-h) and sulfonic acid derivatives (4a-c) were compared to standard and clinically used inhibitors of acetazolamide, Tacrine and acarbose, respectively. Molecular modeling studies of novel compounds, docking scores, and free binding energies were calculated. The activity results of the compounds were found to be compatible with the docking scores. Molecular dynamics studies were conducted with the best activity against CA I and CA II compounds, 4b (IC50: 4.76 nM) and 4a (IC50: 4.36 nM), respectively. In Dynamic Simulation studies, it was observed that the compounds remained stable at the active sites of the proteins.}
}
@incollection{FEIGENSON201113,
title = {Chapter 2 - Objects, Sets, and Ensembles},
editor = {Stanislas Dehaene and Elizabeth M. Brannon},
booktitle = {Space, Time and Number in the Brain},
publisher = {Academic Press},
address = {San Diego},
pages = {13-22},
year = {2011},
isbn = {978-0-12-385948-8},
doi = {https://doi.org/10.1016/B978-0-12-385948-8.00002-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780123859488000025},
author = {Lisa Feigenson},
abstract = {Publisher Summary
This chapter discusses how different types of entities such as individual objects, sets of objects, and ensembles can function as items to be maintained in working memory (WM). All of these types of representations can be relevant to thinking about quantities, and each supports different kinds of quantity-relevant computations. One way to overcome the three- to four-item limit of WM is to bind together representations of individual objects into representations of sets of objects. Binding multiple individuals into a single higher-order group can increase the number of individual items that can be remembered, as in the well-known demonstrations of chunking by adults. Set representations play a critical role in many numerical processes, including representing the nested relationships between as well as representing the cardinality of an array. Many real-world scenes contain stimuli that do not lend themselves to representation qua individual objects or sets of objects. One can imagine enumerating a flock containing dozens of individual birds.}
}
@article{GOLDBACH2016249,
title = {Computational Cutting Pattern Generation Using Isogeometric B-Rep Analysis},
journal = {Procedia Engineering},
volume = {155},
pages = {249-255},
year = {2016},
note = {TENSINET – COST TU1303 International Symposium 2016 "Novel structural skins - Improving sustainability and efficiency through new structural textile materials and designs"},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2016.08.026},
url = {https://www.sciencedirect.com/science/article/pii/S1877705816321671},
author = {Ann-Kathrin Goldbach and Michael Breitenberger and Armin Widhammer and Kai-Uwe Bletzinger},
keywords = {Cutting pattern generation, Variation of Reference Strategy, Isogeometric Analysis, Isogeometric B-Rep Analysis, Design cycle of structural membranes},
abstract = {The cutting pattern plays a major role for the design of structural membranes, since it influences both their aesthetical appearance and structural behavior. A novel approach towards cutting pattern generation is the so-called Variation of Reference Strategy (VaReS) [1], which minimizes the total potential energy arising from the motion of a planar cutting pattern to its corresponding three-dimensional shape. With non-uniform rational B-Splines (NURBS) being the standard tool for geometry description in CAD, it is only consequent to use these for analysis as well. Isogeometric B-Rep Analysis (IBRA) [2] follows up on this idea and enriches the original Isogeometric Analysis (IGA), which was introduced by Hughes et al. [3], by the possibility of analysing trimmed NURBS geometries. This paper presents cutting pattern generation with the Variation of Reference Strategy in the context of IGA/IBRA. With this approach, the whole design of a membrane structure can be represented by NURBS geometries – including blueprint plans. To use the benefits of IBRA for cutting pattern generation, a NURBS-based membrane-element was developed for the VaReS routine. A developable surface serves as a benchmark example, since its analytical cutting pattern is known. Examples of double-curved geometries show the applicability and benefits of the proposed procedure for real structures.}
}
@article{KADUWELA2024105337,
title = {Application of a human-centered design for embedded machine learning model to develop data labeling software with nurses: Human-to-Artificial Intelligence (H2AI)},
journal = {International Journal of Medical Informatics},
volume = {183},
pages = {105337},
year = {2024},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2023.105337},
url = {https://www.sciencedirect.com/science/article/pii/S1386505623003556},
author = {Naomi A. Kaduwela and Susan Horner and Priyansh Dadar and Renee C.B. Manworren},
keywords = {Clinical decision support software, Data labeling, Human-centered Design for Embedded Machine Learning Solutions Machine Learning, Machine learning models},
abstract = {Background
Nurses are essential for assessing and managing acute pain in hospitalized patients, especially those who are unable to self-report pain. Given their role and subject matter expertise (SME), nurses are also essential for the design and development of a supervised machine learning (ML) model for pain detection and clinical decision support software (CDSS) in a pain recognition automated monitoring system (PRAMS). Our first step for developing PRAMS with nurses was to create SME-friendly data labeling software.
Purpose
To develop an intuitive and efficient data labeling software solution, Human-to-Artificial Intelligence (H2AI).
Method
The Human-centered Design for Embedded Machine Learning Solutions (HCDe-MLS) model was used to engage nurses. In this paper, HCDe-MLS will be explained using H2AI and PRAMS as illustrative cases.
Findings
Using HCDe-MLS, H2AI was developed and facilitated labeling of 139 videos (mean = 29.83 min) with 3189 images labeled (mean = 75 s) by 6 nurses. OpenCV was used for video-to-image pre-processing; and MobileFaceNet was used for default landmark placement on images. H2AI randomly assigned videos to nurses for data labeling, tracked labelers’ inter-rater reliability, and stored labeled data to train ML models.
Conclusions
Nurses’ engagement in CDSS development was critical for ensuring the end-product addressed nurses’ priorities, reflected nurses’ cognitive and decision-making processes, and garnered nurses’ trust for technology adoption.}
}
@article{DEBARROS2012171,
title = {Quantum-like model of behavioral response computation using neural oscillators},
journal = {Biosystems},
volume = {110},
number = {3},
pages = {171-182},
year = {2012},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2012.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S0303264712001736},
author = {J. Acacio {de Barros}},
keywords = {Disjunction effect, Quantum cognition, Quantum-like model, Neural oscillators, Stimulus-response theory},
abstract = {In this paper we propose the use of neural interference as the origin of quantum-like effects in the brain. We do so by using a neural oscillator model consistent with neurophysiological data. The model used was shown elsewhere to reproduce well the predictions of behavioral stimulus-response theory. The quantum-like effects are brought about by the spreading activation of incompatible oscillators, leading to an interference-like effect mediated by inhibitory and excitatory synapses.}
}
@article{PILA201952,
title = {Learning to code via tablet applications: An evaluation of Daisy the Dinosaur and Kodable as learning tools for young children},
journal = {Computers & Education},
volume = {128},
pages = {52-62},
year = {2019},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2018.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S0360131518302422},
author = {Sarah Pila and Fashina Aladé and Kelly J. Sheehan and Alexis R. Lauricella and Ellen A. Wartella},
keywords = {Apps, Coding, Computational thinking, Digital games, Educational technology, STEM},
abstract = {Despite the growing number of digital apps designed to teach coding skills to young children, we know little about their effectiveness. To formally explore this question, we conducted a naturalistic observation of a one-week program designed to teach foundational coding skills (i.e., sequencing, conditions, loops) to young children (N = 28, Mage = 5.15 years) using two tablet applications: Daisy the Dinosaur and Kodable. Pre- and post-assessments measured familiarity with technology, appeal of coding apps, knowledge of Daisy commands, ability to play Kodable, and conceptual understanding of coding. Participants improved in their knowledge of Daisy commands (i.e., move, grow, jump) and Kodable gameplay (i.e., placing arrows in the correct sequence to move a character through a maze), but did not improve in their ability to verbally explain what coding is. Appeal of the games was significantly related to children's learning of Daisy commands, but child gender was not related to either Daisy or Kodable learning outcomes. Results suggest that young children can learn foundational coding skills via apps, especially when the apps are appealing to children.}
}
@article{REICHLE20062,
title = {Computational models of eye-movement control during reading: Theories of the “eye–mind” link},
journal = {Cognitive Systems Research},
volume = {7},
number = {1},
pages = {2-3},
year = {2006},
note = {Models of Eye-Movement Control in Reading},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2005.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041705000227},
author = {Erik D. Reichle}
}
@article{ZOMAYA2004551,
title = {Parallel and nature-inspired computational paradigms and applications},
journal = {Parallel Computing},
volume = {30},
number = {5},
pages = {551-552},
year = {2004},
note = {Parallel and nature-inspired computational paradigms and applications},
issn = {0167-8191},
doi = {https://doi.org/10.1016/j.parco.2004.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0167819104000304},
author = {Albert Y Zomaya and Fikret Ercal and El-ghazali Talbi}
}
@article{KOOLSCHIJN2024101453,
title = {Resources, costs and long-term value: an integrative perspective on serotonin and meta-decision making},
journal = {Current Opinion in Behavioral Sciences},
volume = {60},
pages = {101453},
year = {2024},
issn = {2352-1546},
doi = {https://doi.org/10.1016/j.cobeha.2024.101453},
url = {https://www.sciencedirect.com/science/article/pii/S2352154624001049},
author = {Renée S Koolschijn and Bertalan Polner and Julie M Hoomans and Roshan Cools and Eliana Vassena and Hanneke EM {den Ouden}},
abstract = {Serotonin has been associated with a wide range of neural computations and behaviours, yet an overarching function of this neurotransmitter has been hard to pinpoint. Here, we combine recent theories and findings on serotonin and propose a framework where serotonin integrates information on resource availability and state value to represent a cost–benefit trade-off at the neural level. Critically, this framework supports meta-decision making, that is, the flexible allocation of resources to decision-making. We highlight a computational and neural implementation of this framework, and through this novel, lens interpret empirical findings in the domains of controllability and persistence.}
}
@article{HU2015287,
title = {A new face recognition method based on image decomposition for single sample per person problem},
journal = {Neurocomputing},
volume = {160},
pages = {287-299},
year = {2015},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2015.02.032},
url = {https://www.sciencedirect.com/science/article/pii/S0925231215001812},
author = {Changhui Hu and Mengjun Ye and Saiping Ji and Weili Zeng and Xiaobo Lu},
keywords = {Face recognition, Single sample per person problem, Lower-upper decomposition algorithm, Reverse thinking approach based on experimental analysis},
abstract = {The image decomposition based method is one of the efficient and important face recognition solutions for the single sample per person problem. The low image decomposition performance and the unconvincing reconstruction of the approximation image are the two main limitations of the previous methods. In this paper, a new single sample face recognition method based on lower-upper (LU) decomposition algorithm is proposed. The procedure of the proposed method is as following. First, the single sample and its transpose are decomposed to two sets of basis images by using the LU decomposition algorithm, which is more efficient than the image decomposition algorithms of the previous works. Two approximation images are reconstructed from the two basis image sets by the reverse thinking approach based on experimental analysis. Then, the fisher linear discriminant analysis (FLDA) algorithm is used to evaluate the optimal projection space by using the new training set consisting of the single sample and its two approximation images for each person. Finally, the nearest neighbor classifier based on Euclidean distance is adopted as the final classification. We make two main contributions: one is that we propose to decompose the single sample and its transpose using the efficient LU decomposition algorithm, and reorder each basis image set according to the basis image energy; the other is that we present a reverse thinking approach based on experimental analysis to reconstruct the approximation image. The performance of the proposed method is verified using four public face databases, namely FERET, AR, ORL and Yale B. The experimental results indicate that the proposed method is efficient and outperforms several state-of-the-art approaches which are proposed to address the single sample per person problem.}
}
@article{ANANTHASWAMY201742,
title = {That's a termite colony between your ears},
journal = {New Scientist},
volume = {233},
number = {3112},
pages = {42-43},
year = {2017},
issn = {0262-4079},
doi = {https://doi.org/10.1016/S0262-4079(17)30275-0},
url = {https://www.sciencedirect.com/science/article/pii/S0262407917302750},
author = {Anil Ananthaswamy},
abstract = {After wrestling with the nature of the mind for over half a century, Daniel Dennett uploads his latest thinking on consciousness, word-based “mind viruses” and why we must doubt the power of artificial intelligence}
}
@article{RIETMAN2003249,
title = {Analog computation with rings of quasiperiodic oscillators: the microdynamics of cognition in living machines},
journal = {Robotics and Autonomous Systems},
volume = {45},
number = {3},
pages = {249-263},
year = {2003},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2003.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S0921889003001520},
author = {Edward A. Rietman and Mark W. Tilden and Manor Askenazi},
keywords = {Quasiperiodic oscillators, Microdynamics, Schmitt trigger},
abstract = {We describe experimental results to demonstrate the wide-ranging computational ability of quasiperiodic oscillators built from rings of differentiating Schmitt triggers. We describe a theoretical model based on necklace functions to compute the number of states supportable by a ring circuit of a given size. Experimental results are presented to demonstrate that probabilistic state machines can be built from these ring circuits. Other experimental results are given to demonstrate that the rings can model spiking neural network circuits.}
}
@article{TRINDADE2025101104,
title = {Teaching mathematical concepts in management with generative artificial intelligence: The power of human oversight in AI-driven learning},
journal = {The International Journal of Management Education},
volume = {23},
number = {2},
pages = {101104},
year = {2025},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2024.101104},
url = {https://www.sciencedirect.com/science/article/pii/S1472811724001757},
author = {Maria A.M. Trindade and Gihan S. Edirisinghe and Lan Luo},
keywords = {Generative artificial intelligence in education, Generative AI-Driven learning, Mathematics in management education, Operations management, Economic order quantity, Generative AI in management education},
abstract = {This study demonstrates a successful use of Generative Artificial Intelligence (AI) in teaching mathematical material to management students. We herein introduce the EOQ World Tour game, which substantially improves understanding of inventory-related concepts and long-term knowledge retention compared with traditional methods. Generative AI is revolutionizing management education, by offering innovative methods for teaching and learning. The integration of AI into quantitative business disciplines through novel learning mechanisms provides significant benefits, including enhanced data analysis, improved decision-making models, and sophisticated simulations for hands-on experience. This study introduces the EOQ World Tour game, specifically designed to teach the Economic Order Quantity concept in Operations Management. The game addresses challenges in integrating Generative AI into mathematics in management education by combining human oversight and instructor control through three innovative features: (1) a Generative AI-based simulation, (2) a macropowered Excel worksheet for validating the calculations of an AI chatbot, and (3) a Google Sheets dashboard for centralizing team-generated AI data for postgame analysis. Our study included 41 students divided into experimental and control groups. Pretest results indicated no significant differences in baseline knowledge. However, the post-test results showed that the experimental group achieved a better understanding of inventory-related concepts and practical applications, along with higher engagement, excitement, confidence, and long-term knowledge retention.}
}
@article{JIANG2023119343,
title = {Film cooling comparison of shaped holes among the pressure surface, the suction surface and the leading edge of turbine vane},
journal = {Applied Thermal Engineering},
volume = {219},
pages = {119343},
year = {2023},
issn = {1359-4311},
doi = {https://doi.org/10.1016/j.applthermaleng.2022.119343},
url = {https://www.sciencedirect.com/science/article/pii/S135943112201273X},
author = {Yan Jiang and Haiwang Li and Runzhou Liu and Zhi Tao and Zhiyu Zhou},
keywords = {Film cooling, NHFR, Shaped holes, Turbine guide vane},
abstract = {The present study employed commercial computational fluid dynamics software ANSYS 2019R3 to explore the adiabatic film cooling effectiveness and the net heat flux reduction (NHFR) for the comparison of the five selected shaped holes and conventional cylindrical holes between the pressure surface, the suction surface and the leading edge. Amo4ng the shape parameters of shaped holes, the lateral divergence angle (β) and the forward divergence angle (δ) were fixed as 12° and 7° in all shaped holes structures, respectively. The others varied with different regions of the turbine vane. Results showed that different holes fit different positions of vanes. On the suction surface, laidback holes performed the worst net heat flux reduction in most blowing ratios conditions, which indicated the forward divergence angle was not conducive to the flow field and heat transfer characteristics on the suction surface. Whereas, the lateral divergence angle was beneficial to the film cooling and heat transfer characteristics. Laidback fan-shaped holes performed the best adiabatic film cooling effectiveness, but once simultaneously thinking about the heat transfer, fan-shaped holes performed better in net heat flux reduction due to less vortices at holes exit. On the leading edge, the divergence angle towards the upper wall (the lateral divergence angle of spanwise expansion holes) of vanes was not conducive to steady flow. And conical holes performed best, which indicated that coolant from holes with axial divergence angles (the lateral divergence angle in axial direction of conical holes) under the influence of mainstream impact could perform higher film cooling effectiveness and more stable flow fields. On the pressure surface, holes had a lateral divergence angle in the direction of vane height, which was conducive to increasing the coolant coverage area and improving the ability to attach to the pressure surface. Additionally, the laidback hole case was observed the lowest net heat flux reduction when the blowing ratio was less than 2, which revealed that holes that expanded only in flow direction was not conducive to film cooling and heat transfer characteristics.}
}
@incollection{RUFFONI201191,
title = {3.307 - Finite Element Analysis in Bone Research: A Computational Method Relating Structure to Mechanical Function},
editor = {Paul Ducheyne},
booktitle = {Comprehensive Biomaterials},
publisher = {Elsevier},
address = {Oxford},
pages = {91-111},
year = {2011},
isbn = {978-0-08-055294-1},
doi = {https://doi.org/10.1016/B978-0-08-055294-1.00093-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780080552941000933},
author = {D. Ruffoni and G.H. {van Lenthe}},
keywords = {Bone imaging, Bone research, Computational modeling, Femur, Finite element analysis, Fracture, Hierarchical structure, Microcomputed tomography, Osteoporosis, Radius, Strength, Vertebra},
abstract = {Bone is probably the most frequently investigated biological material and finite element analysis (FEA) is the computational tool most commonly used for the analysis of bone biomechanical function. FEA has been used in bone research for more than 30years and has had a substantial impact on our understanding of the complex behavior of bone. Bone is structured in a hierarchical way covering many length scales and this chapter reflects this hierarchical organization. In particular, the focus is on the applications of FEA for understanding the relationship between bone structure and its mechanical function at specific hierarchical levels. Depending on the hierarchical level, different issues have been investigated with FEA ranging from more clinically oriented topics related to bone quality (e.g., predicting bone strength and fracture risk) to more fundamental problems dealing with the mechanical aspects of biological processes (e.g., stress and strain around osteocyte lacunae) as well as with the micromechanical behavior of bone at its ultrastructure. A better understanding of the relationship between structure and mechanical function is expected to be important for the current trends in (bio)materials design, where the structure of biological materials is considered as a possible source of inspiration, as well as for more successful approaches in the prevention and treatment of age- and disease-related fractures.}
}