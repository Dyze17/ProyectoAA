@article{HAMZI2023133853,
title = {Learning dynamical systems from data: A simple cross-validation perspective, part IV: Case with partial observations},
journal = {Physica D: Nonlinear Phenomena},
volume = {454},
pages = {133853},
year = {2023},
issn = {0167-2789},
doi = {https://doi.org/10.1016/j.physd.2023.133853},
url = {https://www.sciencedirect.com/science/article/pii/S0167278923002075},
author = {Boumediene Hamzi and Houman Owhadi and Yannis Kevrekidis},
keywords = {Learning dynamical systems, Kernel flows, Partial observations, Computational graph completion},
abstract = {A simple and interpretable way to learn a dynamical system from data is to interpolate its governing equations with a kernel. In particular, this strategy is highly efficient (both in terms of accuracy and complexity) when the kernel is data-adapted using Kernel Flows (KF) (Owhadi and Yoo, 2019), (which uses gradient-based optimization to learn a kernel based on the premise that a kernel is good if there is no significant loss in accuracy if half of the data is used for interpolation). In this work, we extend previous work on learning dynamical systems using Kernel Flows (Hamzi and Owhadi, 2021; Darcy et al. 2021; Lee et al. 2023; Darcy et al. 2023; Owhadi and Romit Maulik, 2021) to the case of learning vector-valued dynamical systems from time-series observations that are partial/incomplete in the state space. The method combines Kernel Flows with Computational Graph Completion.}
}
@incollection{JACOBLOPES202177,
title = {Chapter 5 - Assistant’s tools toward life cycle assessment},
editor = {Eduardo Jacob-Lopes and Leila Queiroz Zepka and Mariany Costa Deprá},
booktitle = {Sustainability Metrics and Indicators of Environmental Impact},
publisher = {Elsevier},
pages = {77-90},
year = {2021},
isbn = {978-0-12-823411-2},
doi = {https://doi.org/10.1016/B978-0-12-823411-2.00006-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128234112000062},
author = {Eduardo Jacob-Lopes and Leila Queiroz Zepka and Mariany Costa Deprá},
keywords = {Theoretical approach, Sustainability metrics, Life cycle thinking, Social life cycle assessment, Life cycle costing, Life cycle sustainability assessment},
abstract = {This chapter aims to elucidate the main assistant’s tools created to assist in a global assessment of sustainability metrics and indicators. To this end, the chapter will provide a general review of the main assistant’s tools, considering the Life cycle thinking, social life cycle assessment, life cycle cost, and life cycle sustainability assessment tool. In addition, it guides some necessary criteria to be followed to apply each of these tools. Finally, this compilation of information strongly suggests, at the end of the chapter, the application of sensitivity analyses at the end of the process evaluations.}
}
@article{LI2023110701,
title = {Graph neural network architecture search for rotating machinery fault diagnosis based on reinforcement learning},
journal = {Mechanical Systems and Signal Processing},
volume = {202},
pages = {110701},
year = {2023},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2023.110701},
url = {https://www.sciencedirect.com/science/article/pii/S088832702300609X},
author = {Jialin Li and Xuan Cao and Renxiang Chen and Xia Zhang and Xianzhen Huang and Yongzhi Qu},
keywords = {Rotating machinery, Fault diagnosis, Graph neural network, Neural architecture search, Reinforcement learning},
abstract = {In order to improve the accuracy of fault diagnosis, researchers are constantly trying to develop new diagnostic models. However, limited by the inherent thinking of human beings, it has always been difficult to build a pioneering architecture for rotating machinery fault diagnosis. In order to solve this problem, this paper uses reinforcement learning algorithm based on adjacency matrix to carry out network architecture search (NAS) of rotating machinery fault diagnosis model. A reinforcement learning agent for deep deterministic policy gradient (DDPG) is developed based on actor–critic neural networks. The observation state of reinforcement learning is used to develop the graph neural network (GNN) diagnosis model, and the diagnosis accuracy is fed back to the agent as a reward for updating the reinforcement learning parameters. The MFPT bearing fault datasets and the developed gear pitting fault experimental data are used to validate the proposed network architecture search method based on reinforcement learning (RL-NAS). The proposed method is proved to be practical and effective in various aspects such as fault diagnosis ability, search space, search efficiency and multi-working condition performance.}
}
@article{HIPOLITO2023103510,
title = {Breaking boundaries: The Bayesian Brain Hypothesis for perception and prediction},
journal = {Consciousness and Cognition},
volume = {111},
pages = {103510},
year = {2023},
issn = {1053-8100},
doi = {https://doi.org/10.1016/j.concog.2023.103510},
url = {https://www.sciencedirect.com/science/article/pii/S1053810023000478},
author = {Inês Hipólito and Michael Kirchhoff},
keywords = {Bayesian Brain Hypothesis, Modularity of the Mind, Cognitive processes, Informational boundaries},
abstract = {This special issue aims to provide a comprehensive overview of the current state of the Bayesian Brain Hypothesis and its standing across neuroscience, cognitive science and the philosophy of cognitive science. By gathering cutting-edge research from leading experts, this issue seeks to showcase the latest advancements in our understanding of the Bayesian brain, as well as its potential implications for future research in perception, cognition, and motor control. A special focus to achieve this aim is adopted in this special issue, as it seeks to explore the relation between two seemingly incompatible frameworks for the understanding of cognitive structure and function: the Bayesian Brain Hypothesis and the Modularity Theory of the Mind. In assessing the compatibility between these theories, the contributors to this special issue open up new pathways of thinking and advance our understanding of cognitive processes.}
}
@article{STROMMER2022134322,
title = {Forward-looking impact assessment – An interdisciplinary systematic review and research agenda},
journal = {Journal of Cleaner Production},
volume = {377},
pages = {134322},
year = {2022},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2022.134322},
url = {https://www.sciencedirect.com/science/article/pii/S095965262203894X},
author = {Kiia Strömmer and Jarrod Ormiston},
keywords = {Impact assessment, Forward-looking, Temporality, Futures thinking},
abstract = {New and established ventures are under increasing pressure to consider how their current actions impact our future world. Whilst many practitioners are paying greater attention to their future impact, most impact assessment research focuses on the retrospective measurement of impact. Limited studies have explored how impact assessment is used as a tool to forecast or predict the intended impact of organisational action. This study aims to overcome this gap by exploring forward-looking approaches to impact assessment. An interdisciplinary systematic review of the impact assessment literature was conducted to answer the question: “How and why do organisations utilise forward-looking, future-oriented approaches to impact assessment?“. The findings elaborate on the common research themes, challenges, and gaps in understanding forward-looking impact assessment. An integrated process model is developed to show the relationships between various antecedents, methods, and effects of forward-looking impact assessment. Based on the review, the paper puts forward a research agenda to provoke further inquiry on forward-looking, future-oriented approaches to impact assessments related to four research themes: uncertainty, values and assumptions, stakeholder cooperation, and learning. The study contributes to the impact assessment literature by providing an overview of how the current literature comprehends forward-looking approaches and insights into how a more holistic view of temporality in impact assessment can be developed.}
}
@article{DIMAKOU20251310,
title = {The predictive nature of spontaneous brain activity across scales and species},
journal = {Neuron},
volume = {113},
number = {9},
pages = {1310-1332},
year = {2025},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2025.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S0896627325001278},
author = {Anastasia Dimakou and Giovanni Pezzulo and Andrea Zangrossi and Maurizio Corbetta},
keywords = {spontaneous brain activity, predictive brains, behavioral priors, task-rest similarity, metabolic priors},
abstract = {Summary
Emerging research suggests the brain operates as a “prediction machine,” continuously anticipating sensory, motor, and cognitive outcomes. Central to this capability is the brain's spontaneous activity—ongoing internal processes independent of external stimuli. Neuroimaging and computational studies support that this activity is integral to maintaining and refining mental models of our environment, body, and behaviors, akin to generative models in computation. During rest, spontaneous activity expands the variability of potential representations, enhancing the accuracy and adaptability of these models. When performing tasks, internal models direct brain regions to anticipate sensory and motor states, optimizing performance. This review synthesizes evidence from various species, from C. elegans to humans, highlighting three key aspects of spontaneous brain activity’s role in prediction: the similarity between spontaneous and task-related activity, the encoding of behavioral and interoceptive priors, and the high metabolic cost of this activity, underscoring prediction as a fundamental function of brains across species.}
}
@article{GABRIEL2008330,
title = {A friend is a present you give to your “Self”: Avoidance of intimacy moderates the effects of friends on self-liking},
journal = {Journal of Experimental Social Psychology},
volume = {44},
number = {2},
pages = {330-343},
year = {2008},
issn = {0022-1031},
doi = {https://doi.org/10.1016/j.jesp.2007.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S0022103107001126},
author = {Shira Gabriel and Mauricio Carvallo and Lisa M. Jaremka and Brooke Tippin},
keywords = {The self, Social comparison, Friendship, Avoidance of intimacy, Attachment style},
abstract = {The current research proposes that thinking about friends improves feelings about the self and does so differentially depending on avoidance of intimacy. Based on previous findings that individuals who avoid intimacy in relationships (avoidant individuals) contrast their self-concepts with primed friends whereas those who pursue intimacy in relationships (non-avoidant individuals) assimilate their self-concepts to primed friends [Gabriel, S., Carvallo, M., Dean, K., Tippin, B. D., & Renaud, J. (2005). How I see “Me” depends on how I see “We”: The role of avoidance of intimacy in social comparison. Personality and Social Psychology Bulletin, 31, 156–157], we predicted that friends who embody negative aspects of self would lead avoidant individuals to like themselves more, whereas friends who embody positive aspects of self would lead non-avoidant individuals to like themselves more. A pretest determined that good friends were seen as more similar to positive and ideal aspects of the self, whereas friends about whom participants had more mixed feelings (ambivalent friends) were seen as more similar to disliked and feared aspects of the self. Four experiments supported the main hypotheses. In Experiment 1, non-avoidant individuals like themselves more when good friends were primed. In Experiment 2, avoidant individuals like themselves more when ambivalent friends were primed. In Experiment 3, non-avoidant individuals liked themselves better after thinking about a friend’s positive traits, whereas avoidant individuals liked themselves better after thinking about a friend’s negative traits. In Experiment 4, all individuals under self-esteem threat strategically brought friends to mind who would help them like themselves more.}
}
@article{201119,
title = {Evolution of cognition might be down to brain chemistry},
journal = {New Scientist},
volume = {210},
number = {2806},
pages = {19},
year = {2011},
issn = {0262-4079},
doi = {https://doi.org/10.1016/S0262-4079(11)60726-4},
url = {https://www.sciencedirect.com/science/article/pii/S0262407911607264},
abstract = {The prefrontal cortex, the “thinking” part of our brain, has a radically different chemical balance to that of chimps and macaques}
}
@article{LIN2025122926,
title = {Assessment of power loss caused by soiling PV modules using a dual branch multi-modality deep learning network framework},
journal = {Renewable Energy},
volume = {248},
pages = {122926},
year = {2025},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2025.122926},
url = {https://www.sciencedirect.com/science/article/pii/S0960148125005889},
author = {Peijie Lin and Hang Chen and Shuying Cheng and Xiaoyang Lu and Yaohai Lin and Lei Sun},
keywords = {PV power generation, Soiling loss, Multi-modality feature fusion, CA-CMDAF, Deep learning},
abstract = {Soiling can reduce the output power and work efficiency of photovoltaic (PV) modules, causing serious economic losses to PV systems. The cleaning schedules can be optimized to save economic expenses through the methods capable of estimating the power loss of PV modules resulting from soiling. This paper proposes a deep learning framework that combines visible light and infrared image information with dual branch cross-modality feature fusion. Initially, the MobileNetV2 is applied as the backbone of the dual branch framework to enhance the training efficiency and reduce the computational complexity. Subsequently, a cross-modality differential aware fusion module based on the channel attention mechanism (CA-CMDAF) is introduced to improve the cross-modality feature fusion capability of the model. Moreover, a multi-cascade and cross-modality fusion network and a multi-scale fusion network are integrated to further facilitate the effectiveness of feature fusion and reduce the loss of visual details during the feature extraction. Lastly, extensive experiments are carried out on the multi-modality dataset. The comparison results demonstrate the superior performance of the proposed dual branch network framework with the average accuracy of 88.27 %, which is higher than that of the single-modality models trained on either visible light or infrared images alone.}
}
@article{ZHAO2023106750,
title = {A cooperative population-based iterated greedy algorithm for distributed permutation flowshop group scheduling problem},
journal = {Engineering Applications of Artificial Intelligence},
volume = {125},
pages = {106750},
year = {2023},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2023.106750},
url = {https://www.sciencedirect.com/science/article/pii/S095219762300934X},
author = {Hui Zhao and Quan-Ke Pan and Kai-Zhou Gao},
keywords = {Distributed permutation flowshop, Group scheduling, Total flowtime, Iterated greedy algorithm, Co-evolutionary},
abstract = {This paper studies the distributed permutation flowshop group scheduling problem (DPFGSP) with the consideration of minimizing total flowtime (TF), which has important applications in the modern manufacturing process. Based on the characteristics of the problem, a cooperative population-based iterated greedy (CPIG) algorithm is proposed by combining the advantages of the divide-and-rule policy, population-based evolution and iterated greedy algorithm. The CPIG divides the DPFGSP into two coupled sub-problems of group scheduling sub-problem and job scheduling sub-problem, and starts with a single population for simplicity. Unlike in the traditional cooperative co-evolutionary algorithms, the two-coupled sub-problems are addressed with a certain probability that can be determined in favor of solving the whole scheduling problem. Some advanced technologies are used, including the constructive heuristics based initialization, the critical factories based destruction and construction, the new best solution based population updating mechanism. The comprehensive experimental evaluation of 810 instances shows that the CPIG algorithm performs much better than the five state-of-the-art metaheuristics in the literature which are closely related to the considered scheduling problem.}
}
@article{CEGIELSKI2016283,
title = {Rethinking the role of Agent-Based Modeling in archaeology},
journal = {Journal of Anthropological Archaeology},
volume = {41},
pages = {283-298},
year = {2016},
issn = {0278-4165},
doi = {https://doi.org/10.1016/j.jaa.2016.01.009},
url = {https://www.sciencedirect.com/science/article/pii/S0278416516000118},
author = {Wendy H. Cegielski and J. Daniel Rogers},
keywords = {ABM, Agent-Based Modeling, Archaeological methods, Simulation, Computational modeling},
abstract = {Agent-Based Modeling (ABM) represents a methodology with significant potential for altering archaeological analytical practice. The continued growth in the number of publications that use ABM provides evidence for the significance of this emerging approach. However, the scope of the research topics investigated has not increased accordingly. A consensus exists among ABM practitioners, that once generally accepted by the field, ABM can make revolutionary advances within the overall archaeological research paradigm. Unresolved concerns within the archaeological community center on whether ABMs are sufficiently grounded in empirical data, are aligned with theoretical trajectories, and on the difficult task of mastering the computational systems. It is worth exploring these aspects of the disjuncture between the mainstream and ABM practitioners for two reasons – to frame a discussion of qualities of ABM that make it transformative and to provide guidelines for broadening ABM’s applicability. With capacity-building in mind, offered here is a practical reference for the non-practitioner archaeologist considering ABM. A glossary is included of key terms used in the text to describe ABM methods and theory.}
}
@article{NKONGOLO2022182,
title = {Using Deep Packet Inspection Data to Examine Subscribers on the Network},
journal = {Procedia Computer Science},
volume = {215},
pages = {182-191},
year = {2022},
note = {4th International Conference on Innovative Data Communication Technology and Application},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.12.021},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922020920},
author = {Mike Nkongolo and Jacobus Phillipus {van Deventer} and Sydney Mambwe Kasongo},
keywords = {Deep packet inspection, machine learning, UGRansome, telecommunication, data science},
abstract = {This article proposes the creation of the deep packet inspection (DPI) dataset to study subscribers’ behavior on the network, applying ensemble learning to this dataset, and comparing it with the UGRansome dataset. The subscriber can be thought of as a person or a group of users using a network service or connectivity. The DPI features represent the subscriber network usage, and the ensemble learning approach is implemented on the DPI dataset to predict the subscriber's service category on the network. The classification and prediction problem addressed on the DPI dataset reached a precision of 100%. The paper predicts that the web and streaming categories with Netflix, Facebook, and YouTube services will be the most utilized in the next few years. This study will lead to a better understanding of the idiosyncratic behavior of active subscribers on the network, exposing novel network anomalies and facilitating the development of novel DPI systems.}
}
@article{BRYANSMITH2023105405,
title = {Real-time social media sentiment analysis for rapid impact assessment of floods},
journal = {Computers & Geosciences},
volume = {178},
pages = {105405},
year = {2023},
issn = {0098-3004},
doi = {https://doi.org/10.1016/j.cageo.2023.105405},
url = {https://www.sciencedirect.com/science/article/pii/S0098300423001097},
author = {Lydia Bryan-Smith and Jake Godsall and Franky George and Kelly Egode and Nina Dethlefs and Dan Parsons},
keywords = {Social media, Sentiment analysis, Flooding, Artificial Intelligence},
abstract = {Traditional approaches to flood modelling mostly rely on hydrodynamic physical simulations. While these simulations can be accurate, they are computationally expensive and prohibitively so when thinking about real-time prediction based on dynamic environmental conditions. Alternatively, social media platforms such as Twitter are often used by people to communicate during a flooding event, but discovering which tweets hold useful information is the key challenge in extracting information from posts in real time. In this article, we present a novel model for flood forecasting and monitoring that makes use of a transformer network that assesses the severity of a flooding situation based on sentiment analysis of the multimodal inputs (text and images). We also present an experimental comparison of a range of state-of-the-art deep learning methods for image processing and natural language processing. Finally, we demonstrate that information induced from tweets can be used effectively to visualise fine-grained geographical flood-related information dynamically and in real-time.}
}
@incollection{KUMAR2024147,
title = {Chapter Eight - Machine learning model for teaching and emotional intelligence},
editor = {Muskan Garg and Deepika Koundal},
booktitle = {Emotional AI and Human-AI Interactions in Social Networking},
publisher = {Academic Press},
pages = {147-168},
year = {2024},
isbn = {978-0-443-19096-4},
doi = {https://doi.org/10.1016/B978-0-443-19096-4.00014-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780443190964000146},
author = {Mohit Kumar and Syam Machinathu Parambil Gangadharan and Nabanita Choudhury},
keywords = {Cognitive thinking, Design thinking, E-Learning, Emotional intelligence, Intelligent quotient, Social neuroscience},
abstract = {Education that is ongoing and permanent for the purpose of adaptable up-skilling and retraining has been identified as a contributory factor, along with a relentless race against time, fast scientific progress, and unanticipated challenges. Students in postsecondary learning require mechanisms that can enable long-term, dependable knowledge production and storage, and this is particularly true in the age after a pandemic that occurred during the development of new technologies. There has been an explosion of e-learning platforms and methodologies that have been developed to remedy this issue; however, not all of them have been as successful as would be ideal. This type of new knowledge is very difficult to execute properly; it needs complex, careful educational and interface design to perform as well as it does and keep learners interested. This framework was designed and developed in this study. This technology was employed to support a cutting-edge pedagogic study based on neuroscience that was offered to faculty at universities of higher education. This framework was designed and developed in this study. This technology was employed to support a cutting-edge pedagogic study based on neuroscience that was offered to faculty at universities of higher education. Having a high intelligence quotient does not guarantee a successful and happy life. Success also necessitates self-awareness and emotional control. Our idea was to create a computational paradigm that would educate students in both programming and emotional intelligence. This experiment was successful in addressing the problem of excessive screen use by providing a student interface without displays.}
}
@article{FU2022107,
title = {Everyday Creativity is Associated with Increased Frontal Electroencephalography Alpha Activity During Creative Ideation},
journal = {Neuroscience},
volume = {503},
pages = {107-117},
year = {2022},
issn = {0306-4522},
doi = {https://doi.org/10.1016/j.neuroscience.2022.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S0306452222004596},
author = {Lei Fu and Jia Zhao and Jiangzhou Sun and Yuchi Yan and Mujie Ma and Qunlin Chen and Jiang Qiu and Wenjing Yang},
keywords = {Everyday creativity, Alpha power, Alpha coherence, Creative ideation, Frontal cortex},
abstract = {Everyday creativity is the basic ability of human survival and penetrates every aspect of life. Nevertheless, the neural mechanisms underlying everyday creativity was largely unexplored. In this study, seventy-five participants completed the creative behaviour inventory, a tool for assessing creative behaviour in daily life. The participants also completed the alternate uses task (AUT) during an electroencephalography (EEG) assessment to evaluate creative thinking. Alpha power was used to quantify neural oscillations during the creative process, while alpha coherence was used to quantify information communication between frontal regions and other sites during creative ideation. Moreover, these two task-related quantitative measures were combined to investigate the relationship between individual differences in everyday creativity and EEG alpha activity during creative idea generation. Compared with the reference period, increased alpha power was observed in the frontal cortex of the right hemisphere and increased functional coupling was observed between frontal and parietal/temporal regions during the activation period. Interestingly, individual differences in everyday creativity were associated with distinct patterns of EEG alpha activity. Specifically, individuals with higher everyday creativity had increased alpha power in the frontal cortex, and increased changes in coherence in frontal-temporal regions of the right hemisphere while performing the AUT. It might indicate that individuals with higher everyday creativity had an enhanced ability to focus on internal information processing and control bottom-up stimuli, as well as better selection of novel semantic information when performing creative ideation tasks.}
}
@article{SUN2025e01027,
title = {First-principles calculations of electronic and mechanical properties of magnesium indium intermetallic compounds},
journal = {Computational Condensed Matter},
volume = {43},
pages = {e01027},
year = {2025},
issn = {2352-2143},
doi = {https://doi.org/10.1016/j.cocom.2025.e01027},
url = {https://www.sciencedirect.com/science/article/pii/S2352214325000267},
author = {Liang Sun and Yidan Huang and Kaifeng Zhao and Zuoming Chen and Xiongtao Shang and Wenzhen Xu and wenyan Zhai and Pengyue Han and Jin Jia and Jianhong Peng},
keywords = {Mg-In intermetallic compounds, First-principles calculations, Phonon spectra, Anisotropy, Mechanical properties, Electronic properties},
abstract = {In the search for innovative alternatives to aluminum-magnesium alloys, this study takes a unique approach by focusing on magnesium-indium binary alloys, with an emphasis on the intermetallic compounds Mg2In, MgIn3, Mg5In2, and Mg3In. With the help of cutting-edge first-principles computational techniques, the four compounds are comprehensively and thoroughly analyzed in terms of crystal structure, anisotropy, phonon spectra, electronic properties, and mechanical properties. The charge transfer phenomenon from magnesium to indium is found for the first time, and the s-orbital density of indium is at its peak in the Mg-In phase. In terms of mechanical properties, Mg2In, Mg5In2, and MgIn3 exhibit similar bulk moduli, while the shear modulus, Young's modulus, and hardness of MgIn3 are significantly lower than those of the other phases, emphasizing its unique deformability. Taking the results together, MgIn3 shows great potential for application in cutting-edge fields such as biomedical materials due to its compact size, corrosion resistance, low hardness, and high plasticity, which opens up a new way of thinking for the development of Mg-In alloy-based advanced materials.}
}
@article{KARI2022102843,
title = {The Sabatier principle as a tool for discovery and engineering of industrial enzymes},
journal = {Current Opinion in Biotechnology},
volume = {78},
pages = {102843},
year = {2022},
issn = {0958-1669},
doi = {https://doi.org/10.1016/j.copbio.2022.102843},
url = {https://www.sciencedirect.com/science/article/pii/S095816692200177X},
author = {Jeppe Kari and Kay Schaller and Gustavo A Molina and Kim Borch and Peter Westh},
abstract = {The recent breakthrough in all-atom, protein structure prediction opens new avenues for a range of computational approaches in enzyme design. These new approaches could become instrumental for the development of technical biocatalysts, and hence our transition toward more sustainable industries. Here, we discuss one approach, which is well-known within inorganic catalysis, but essentially unexploited in biotechnology. Specifically, we review examples of linear free-energy relationships (LFERs) for enzyme reactions and discuss how LFERs and the associated Sabatier Principle may be implemented in algorithms that estimate kinetic parameters and enzyme performance based on model structures.}
}
@article{BIDERMAN2020542,
title = {What Are Memories For? The Hippocampus Bridges Past Experience with Future Decisions},
journal = {Trends in Cognitive Sciences},
volume = {24},
number = {7},
pages = {542-556},
year = {2020},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2020.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S1364661320301066},
author = {Natalie Biderman and Akram Bakkour and Daphna Shohamy},
keywords = {memory, decision-making, amnesia, hippocampus, value},
abstract = {Many decisions require flexible reasoning that depends on inference, generalization, and deliberation. Here, we review emerging findings indicating that the hippocampus, known for its role in long-term memory, contributes to these flexible aspects of value-based decision-making. This work offers new insights into the role of memory in decision-making and suggests that memory may shape decisions even in situations that do not appear, at first glance, to depend on memory at all. Uncovering the pervasive role of memory in decision-making challenges the way we define what memory is and what it does, suggesting that memory’s primary purpose may be to guide future behavior and that storing a record of the past is just one way to do so.}
}
@article{BANERJEE2015143,
title = {Z*-numbers: Augmented Z-numbers for machine-subjectivity representation},
journal = {Information Sciences},
volume = {323},
pages = {143-178},
year = {2015},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2015.06.026},
url = {https://www.sciencedirect.com/science/article/pii/S0020025515004582},
author = {Romi Banerjee and Sankar K. Pal},
keywords = {Artificial-mindfulness, Machine-consciousness, Machine-qualia, Machine-self, Perception-operators, Thinking machine},
abstract = {Envisaging a futuristic environment of man–machine and machine–machine synergy, this article documents our research on the augmented Z-numbers, the Z*-numbers, for machine-perception encapsulation. The Z*-numbers have been envisioned as operands of endogenous machine-mind processes underlying bespoke comprehension of the real world. Besides information-certainty, as in a Z-number, a Z*-number incorporates context, time and affects as essential factors of subjectivity representation. We have proposed: (a) definitions for certainty and affect parameters—arising out of socio-cultural influences on machine-knowledge, (b) a Z*-number based rudimentary procedure for natural-language comprehension emulation, and (c) primitive perception-operators for ‘machine-mentalese’ simulation using Z*-number information-equivalents. Our work draws from non-symbolic theories of cognition and ‘mindfulness’, human-mind processes—studied through behavioral experiments, and theories of the ‘self’ and ‘qualia’. The article includes detailed discussions of these experiments and consequent insights, analysis of a theoretical run-through of the defined procedure, and correspondence-studies between the Z*-number paradigm and philosophies of the self. Our research raises questions on cognitive biases and autogenous mind-processes that highlight crucial practical challenges in the current realization of a synthetic-mind. All ideas herein aim to contribute to studies on the ‘self’ and its machine-embodiment for the synthesis of an empathetic machine-mind.}
}
@article{GARCIACAIRASCO2021107930,
title = {Searching for a paradigm shift in the research on the epilepsies and associated neuropsychiatric comorbidities. From ancient historical knowledge to the challenge of contemporary systems complexity and emergent functions},
journal = {Epilepsy & Behavior},
volume = {121},
pages = {107930},
year = {2021},
note = {NEWroscience 2018},
issn = {1525-5050},
doi = {https://doi.org/10.1016/j.yebeh.2021.107930},
url = {https://www.sciencedirect.com/science/article/pii/S1525505021001645},
author = {Norberto Garcia-Cairasco and Guilherme Podolsky-Gondim and Julian Tejada},
keywords = {Ancestral knowledge, Superstitious versus scientific knowledge, Epilepsies and neuropsychiatric comorbidities, Clinical semiology and neurosurgery methods, experimental and computational modeling, Complexity and emergent properties},
abstract = {In this review, we will discuss in four scenarios our challenges to offer possible solutions for the puzzle associated with the epilepsies and neuropsychiatric comorbidities. We need to recognize that (1) since quite old times, human wisdom was linked to the plural (distinct global places/cultures) perception of the Universe we are in, with deep respect for earth and nature. Plural ancestral knowledge was added with the scientific methods; however, their joint efforts are the ideal scenario; (2) human behavior is not different than animal behavior, in essence the product of Darwinian natural selection; knowledge of animal and human behavior are complementary; (3) the expression of human behavior follows the same rules that complex systems with emergent properties, therefore, we can measure events in human, clinical, neurobiological situations with complexity systems’ tools; (4) we can use the semiology of epilepsies and comorbidities, their neural substrates, and potential treatments (including experimental/computational modeling, neurosurgical interventions), as a source and collection of integrated big data to predict with them (e.g.: machine/deep learning) diagnosis/prognosis, individualized solutions (precision medicine), basic underlying mechanisms and molecular targets. Once the group of symptoms/signals (with a myriad of changing definitions and interpretations over time) and their specific sequences are determined, in epileptology research and clinical settings, the use of modern and contemporary techniques such as neuroanatomical maps, surface electroencephalogram and stereoelectroencephalography (SEEG) and imaging (MRI, BOLD, DTI, SPECT/PET), neuropsychological testing, among others, are auxiliary in the determination of the best electroclinical hypothesis, and help design a specific treatment, usually as the first attempt, with available pharmacological resources. On top of ancient knowledge, currently known and potentially new antiepileptic drugs, alternative treatments and mechanisms are usually produced as a consequence of the hard, multidisciplinary, and integrated studies of clinicians, surgeons, and basic scientists, all over the world. The existence of pharmacoresistant patients, calls for search of other solutions, being along the decades the surgeries the most common interventions, such as resective procedures (i.e., selective or standard lobectomy, lesionectomy), callosotomy, hemispherectomy and hemispherotomy, added by vagus nerve stimulation (VNS), deep brain stimulation (DBS), neuromodulation, and more recently focal minimal or noninvasive ablation. What is critical when we consider the pharmacoresistance aspect with the potential solution through surgery, is still the pursuit of localization-dependent regions (e.g.: epileptogenic zone (EZ)), in order to decide, no matter how sophisticated are the brain mapping tools (EEG and MRI), the size and location of the tissue to be removed. Mimicking the semiology and studying potential neural mechanisms and molecular targets – by means of experimental and computational modeling – are fundamental steps of the whole process. Concluding, with the conjunction of ancient knowledge, coupled to critical and creative contemporary, scientific (not dogmatic) clinical/surgical, and experimental/computational contributions, a better world and of improved quality of life can be offered to the people with epilepsy and neuropsychiatric comorbidities, who are still waiting (as well as the scientists) for a paradigm shift in epileptology, both in the Basic Science, Computational, Clinical, and Neurosurgical Arenas. This article is part of the Special Issue “NEWroscience 2018”.}
}
@article{GENTILI2024150060,
title = {Living cells and biological mechanisms as prototypes for developing chemical artificial intelligence},
journal = {Biochemical and Biophysical Research Communications},
volume = {720},
pages = {150060},
year = {2024},
issn = {0006-291X},
doi = {https://doi.org/10.1016/j.bbrc.2024.150060},
url = {https://www.sciencedirect.com/science/article/pii/S0006291X24005965},
author = {Pier Luigi Gentili and Pasquale Stano},
keywords = {Chemical AI, Synthetic cell, Chemical neural networks, Neuromorphic engineering, Molecular fuzzy sets, Molecular computing},
abstract = {Artificial Intelligence (AI) is having a revolutionary impact on our societies. It is helping humans in facing the global challenges of this century. Traditionally, AI is developed in software or through neuromorphic engineering in hardware. More recently, a brand-new strategy has been proposed. It is the so-called Chemical AI (CAI), which exploits molecular, supramolecular, and systems chemistry in wetware to mimic human intelligence. In this work, two promising approaches for boosting CAI are described. One regards designing and implementing neural surrogates that can communicate through optical or chemical signals and give rise to networks for computational purposes and to develop micro/nanorobotics. The other approach concerns “bottom-up synthetic cells” that can be exploited for applications in various scenarios, including future nano-medicine. Both topics are presented at a basic level, mainly to inform the broader audience of non-specialists, and so favour the rise of interest in these frontier subjects.}
}
@incollection{AMJAD202559,
title = {Chapter 6 - Kinetics and dynamics of biological systems},
editor = {Babak Sokouti},
booktitle = {Systems Biology and In-Depth Applications for Unlocking Diseases},
publisher = {Academic Press},
pages = {59-67},
year = {2025},
isbn = {978-0-443-22326-6},
doi = {https://doi.org/10.1016/B978-0-443-22326-6.00006-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780443223266000067},
author = {Elham Amjad and Babak Sokouti},
keywords = {Biological systems, Computational methods, Dynamics, Enzyme kinetics, Simulations},
abstract = {Understanding the kinetics and dynamics of biological systems is crucial for elucidating the mechanisms that govern their behavior and function. This chapter discusses the fundamentals of kinetics, which deals with the rates of chemical reactions, and dynamics, which studies how biological systems change over time. Mathematical modeling approaches for analyzing kinetics and dynamics, including deterministic, stochastic, and hybrid models, are presented. Experimental techniques like transport measurements, calorimetry, fluorescence correlation spectroscopy, and neutron scattering are highlighted for investigating kinetics and dynamics. Computational methods such as molecular dynamics simulations and deep learning are also explored for studying biomolecular processes. Applications of kinetics and dynamics are illustrated through examples in areas like fuel-driven dynamic combinatorial libraries, self-assembly, and gene regulatory networks. Key discoveries enabled by kinetics and dynamics research are summarized, including dynamic heterogeneity, kinetic proofreading, biological switches, and single-molecule insights. The chapter emphasizes on the importance of integrating experimental data with computational modeling to deepen the understanding of biological systems across multiple scales. Future directions are outlined, such as studying interactomes, DNA mechanics, metabolic regulation, and developing advanced microtechnologies to further unravel the complex kinetic and dynamic behavior underlying diverse biological phenomena.}
}
@article{HANNA2025100705,
title = {Future of Artificial Intelligence—Machine Learning Trends in Pathology and Medicine},
journal = {Modern Pathology},
volume = {38},
number = {4},
pages = {100705},
year = {2025},
issn = {0893-3952},
doi = {https://doi.org/10.1016/j.modpat.2025.100705},
url = {https://www.sciencedirect.com/science/article/pii/S0893395225000018},
author = {Matthew G. Hanna and Liron Pantanowitz and Rajesh Dash and James H. Harrison and Mustafa Deebajah and Joshua Pantanowitz and Hooman H. Rashidi},
keywords = {artificial intelligence, computational pathology, machine learning, operations},
abstract = {Artificial intelligence (AI) and machine learning (ML) are transforming the field of medicine. Health care organizations are now starting to establish management strategies for integrating such platforms (AI-ML toolsets) that leverage the computational power of advanced algorithms to analyze data and to provide better insights that ultimately translate to enhanced clinical decision-making and improved patient outcomes. Emerging AI-ML platforms and trends in pathology and medicine are reshaping the field by offering innovative solutions to enhance diagnostic accuracy, operational workflows, clinical decision support, and clinical outcomes. These tools are also increasingly valuable in pathology research in which they contribute to automated image analysis, biomarker discovery, drug development, clinical trials, and productive analytics. Other related trends include the adoption of ML operations for managing models in clinical settings, the application of multimodal and multiagent AI to utilize diverse data sources, expedited translational research, and virtualized education for training and simulation. As the final chapter of our AI educational series, this review article delves into the current adoption, future directions, and transformative potential of AI-ML platforms in pathology and medicine, discussing their applications, benefits, challenges, and future perspectives.}
}
@incollection{MUBAYI2017249,
title = {Chapter 10 - Computational Modeling Approaches Linking Health and Social Sciences: Sensitivity of Social Determinants on the Patterns of Health Risk Behaviors and Diseases},
editor = {Arni S.R. {Srinivasa Rao} and Saumyadipta Pyne and C.R. Rao},
series = {Handbook of Statistics},
publisher = {Elsevier},
volume = {36},
pages = {249-304},
year = {2017},
booktitle = {Disease Modelling and Public Health, Part A},
issn = {0169-7161},
doi = {https://doi.org/10.1016/bs.host.2017.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0169716117300172},
author = {Anuj Mubayi},
keywords = {Health risk behaviors, Dynamic models, Data mining, Sensitivity and uncertainty analysis, Ecological models, Social influences},
abstract = {Developing health promotion programs that support healthy lifestyle behaviors require comprehensive understanding of mechanisms that drive such complex social systems. Policy makers can use models and theories to guide this process at the individuals, groups, and communities levels. Individuals can have multiple risky health behaviors including physical inactivity, unhealthy diets, smoking, and alcohol drinking that are often shaped by social and ecological factors. Collective understanding of these factors can provide ability to design and evaluate intervention programs that can change unhealthy or risky behaviors over long period of time. However, it is overwhelming task to optimize intervention based on only empirical and/or cross-sectional studies. Effective long lasting intervention needs a thorough understanding of the role of social and environmental mechanisms at multiple scales on the dynamics of health behaviors. Recent mathematical and computational methods developed in other fields, such as epidemiology and finance, can provide systematic and in-depth understanding of mechanisms. However, the use of such methods in social and behaviors sciences have been limited. In this chapter, some real life working examples of social health behaviors problems are provided which uses some cutting edge methods from dynamical systems and data mining to uncertainty quantification.}
}
@article{GOBERT201581,
title = {Using educational data mining to assess students’ skills at designing and conducting experiments within a complex systems microworld},
journal = {Thinking Skills and Creativity},
volume = {18},
pages = {81-90},
year = {2015},
note = {21st Century Skills: International Advancements and Recent Developments},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2015.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S1871187115300067},
author = {Janice D. Gobert and Yoon Jeon Kim and Michael A. {Sao Pedro} and Michael Kennedy and Cameron G. Betts},
keywords = {Complex systems, Inquiry assessment, Performance assessment, Educational data mining, 21st century skills},
abstract = {Many national policy documents underscore the importance of 21st century skills, including critical thinking. In parallel, recent American frameworks for K-12 science education call for the development of critical thinking skills in science, also referred to as science inquiry skills/practices. Assessment of these skills is necessary, as indicated in policy documents; however, this has posed a great challenge for assessment researchers. Recently, some science learning environments seek to assess these science skills. These systems log all students’ interactions within the given system, and if fully leveraged, these logs provide rich assessments of inquiry skills. Here, we describe our environment Inq-ITS (inquiry intelligent tutoring system), that uses educational data mining to assess science inquiry skills, as described as 21st century skills. Additionally, here, we describe how we measure students’ skills at designing controlled experiments, a lynchpin skill of inquiry, in the context of complex systems. In doing so, our work addresses 21st century skill assessment in two ways, namely of inquiry (designing and conducting experiments), and in the context of complex systems, a key topic area of 21st century skills. We use educational data mining to develop our assessment of this skill for complex systems.}
}
@article{CRUTCHFIELD199411,
title = {The calculi of emergence: computation, dynamics and induction},
journal = {Physica D: Nonlinear Phenomena},
volume = {75},
number = {1},
pages = {11-54},
year = {1994},
issn = {0167-2789},
doi = {https://doi.org/10.1016/0167-2789(94)90273-9},
url = {https://www.sciencedirect.com/science/article/pii/0167278994902739},
author = {James P. Crutchfield},
abstract = {Defining structure and detecting the emergence of complexity in nature are inherently subjective, though essential, scientific activities. Despite the difficulties, these problems can be analyzed in terms of how model-building observers infer from measurements the computational capabilities embedded in nonlinear processes. An observer's notion of what is ordered, what is random, and what is complex in its environment depends directly on its computational resources: the amount of raw measurement data, of memory, and of time available for estimation and inference. The discovery of structure in an environment depends more critically and subtlely though on how those resources are organized. The descriptive power of the observer's chosen (or implicit) computational model class, for example, can be an overwhelming determinant in finding regularity in data. This paper presents an overview of an inductive framework-hierarchical ϵ-machine reconstruction—in which the emergence of complexity is associated with the innovation of new computational model classes. Complexity metrics for detecting structure and quantifying emergence, along with an analysis of the constraints on the dynamics of innovation, are outlined. Illustrative examples are drawn from the onset of unpredictability in nonlinear systems, finitary nondeterministic processes, and cellular automata pattern recognition. They demonstrate how finite inference resources drive the innovation of new structures and so lead to the emergence of complexity.}
}
@article{MANCINI2022102697,
title = {Out of sight, out of mind? The importance of local context and trust in understanding the social acceptance of biogas projects: A global scale review},
journal = {Energy Research & Social Science},
volume = {91},
pages = {102697},
year = {2022},
issn = {2214-6296},
doi = {https://doi.org/10.1016/j.erss.2022.102697},
url = {https://www.sciencedirect.com/science/article/pii/S2214629622002018},
author = {Eliana Mancini and Andrea Raggi},
keywords = {Social acceptance, Bioenergy, Non-technical barriers, Biogas, Socio-cultural factors, Life Cycle Thinking},
abstract = {Social acceptance is considered the main non-technical barrier to the development of bioenergy projects. This paper presents the results of a systematic literature review aimed to cover a lack in state-of-the-art literature about socio-cultural factors affecting the acceptance of biogas projects at a global scale. Moreover, this study is aimed at identifying which methods are used for studying this phenomenon, with a focus on the Life Cycle Thinking-oriented ones. Journal articles and conference proceedings were considered. At the end of the screening phases, 54 documents were selected and reviewed. The results showed that acceptance concerns two main issues: biogas plants and its presence in a given location and digestate application on fields. This review showed different results between high-income and low-middle-income countries. As regards the former, trust was the most mentioned socio-cultural factor. Education, as well as women's living conditions were considered important in the latter. However, a contextualisation of every outcome based on local peculiarities is needed in order to understand in a better way the accepting/refuting phenomena of the projects. As regards the second objective of this study, Life Cycle Analysis resulted the most widespread Life Cycle Thinking methodology. In conclusion, the outcomes of this work may be useful to identify the non-technical factors and the most suitable approach that should be considered for a successful implementation of site-specific biogas projects.}
}
@article{JIANG2021106740,
title = {Accelerator for crosswise computing reduct},
journal = {Applied Soft Computing},
volume = {98},
pages = {106740},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.106740},
url = {https://www.sciencedirect.com/science/article/pii/S1568494620306785},
author = {Zehua Jiang and Keyu Liu and Jingjing Song and Xibei Yang and Jinhai Li and Yuhua Qian},
keywords = {Accelerator, Attribute reduction, Cross computation, Rough set},
abstract = {Attribute reduction, as a technique for selecting qualified attributes which can satisfy the intended constraint related to considered measure, has been widely explored. Notably, one and only one reduct is derived through using one searching strategy in most cases. Nevertheless, only one reduct may be not enough for us to evaluate its effectiveness. To fill such gap, an approach of crosswise computing reduct is proposed for obtaining multiple reducts. The computation of reduct is realized through partitioning the whole data into several groups, and crosswise selecting some groups to form different subsets of data, then computing reducts over these different subsets of data. Moreover, to speed up the process of crosswise computing reduct, an acceleration strategy is designed. The main thinking of our acceleration strategy is to compute the reduct over different subsets of data on the basis of reduct over the whole data. The experimental results over 16 data sets show the following superiorities of our strategy: (1) our approach can decrease the elapsed time of crosswise computing reducts significantly; (2) our approach can not only provide reduct with higher stability, but also maintain the classification performance; (3) the attributes in reduct can provide more stable classification results.}
}
@article{KATTERFELDT201872,
title = {Physical computing with plug-and-play toolkits:Key recommendations for collaborative learning implementations},
journal = {International Journal of Child-Computer Interaction},
volume = {17},
pages = {72-82},
year = {2018},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2018.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S2212868917300351},
author = {Eva-Sophie Katterfeldt and Mutlu Cukurova and Daniel Spikol and David Cuartielles},
keywords = {Collaborative learning, Education, Motivation, Physical computing, Programming, Toolkit},
abstract = {Physical computing toolkits have long been used in educational contexts to learn about computational concepts by engaging in the making of interactive projects. This paper presents a comprehensive toolkit that can help educators teach programming with an emphasis on collaboration, and provides suggestions for its effective pedagogical implementation. The toolkit comprises the Talkoo kit with physical computing plug-and-play modules and a visual programming environment. The key suggestions are inspired by the results of the evaluation studies which show that children (aged 14–18 in a sample group of 34 students) are well motivated when working with the toolkit but lack confidence in the kit’s support for collaborative learning. If the intention is to move beyond tools and code in computer education to community and context, thus encouraging computational participation, collaboration should be considered as a key aspect of physical computing activities. Our approach expands the field of programming with physical computing for teenage children with a focus on empowering teachers and students with not only a kit but also its appropriate classroom implementation for collaborative learning.}
}
@article{SHAFFER199795,
title = {Learning mathematics through design: The anatomy of Escher's world},
journal = {The Journal of Mathematical Behavior},
volume = {16},
number = {2},
pages = {95-112},
year = {1997},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(97)90019-5},
url = {https://www.sciencedirect.com/science/article/pii/S0732312397900195},
author = {David Williamson Shaffer},
abstract = {This article explores one example of an open learning environment created by combining mathematics and design activities in a “mathematics studio”. Two iterations of the mathematics studio experiment in a project at the MIT Media Laboratory known as Escher's World suggest that: (a) students can learn about the mathematical concept of symmetry in a studio learning environment, (b) students learn to use visual thinking to solve mathematical problems in a studio learning environment, and (c) students develop a more positive attitude towards mathematics as a result of working in a studio learning environment. This article uses a qualitative research model to explore the specific characteristics of the mathematics studio that were influential in creating a successful learning environment—in particular, how expressive mathematics activities and expressive computational media give students a sense of control over their learning.}
}
@article{KASNECI2023102274,
title = {ChatGPT for good? On opportunities and challenges of large language models for education},
journal = {Learning and Individual Differences},
volume = {103},
pages = {102274},
year = {2023},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2023.102274},
url = {https://www.sciencedirect.com/science/article/pii/S1041608023000195},
author = {Enkelejda Kasneci and Kathrin Sessler and Stefan Küchemann and Maria Bannert and Daryna Dementieva and Frank Fischer and Urs Gasser and Georg Groh and Stephan Günnemann and Eyke Hüllermeier and Stephan Krusche and Gitta Kutyniok and Tilman Michaeli and Claudia Nerdel and Jürgen Pfeffer and Oleksandra Poquet and Michael Sailer and Albrecht Schmidt and Tina Seidel and Matthias Stadler and Jochen Weller and Jochen Kuhn and Gjergji Kasneci},
keywords = {Large language models, Artificial intelligence, Education, Educational technologies},
abstract = {Large language models represent a significant advancement in the field of AI. The underlying technology is key to further innovations and, despite critical views and even bans within communities and regions, large language models are here to stay. This commentary presents the potential benefits and challenges of educational applications of large language models, from student and teacher perspectives. We briefly discuss the current state of large language models and their applications. We then highlight how these models can be used to create educational content, improve student engagement and interaction, and personalize learning experiences. With regard to challenges, we argue that large language models in education require teachers and learners to develop sets of competencies and literacies necessary to both understand the technology as well as their limitations and unexpected brittleness of such systems. In addition, a clear strategy within educational systems and a clear pedagogical approach with a strong focus on critical thinking and strategies for fact checking are required to integrate and take full advantage of large language models in learning settings and teaching curricula. Other challenges such as the potential bias in the output, the need for continuous human oversight, and the potential for misuse are not unique to the application of AI in education. But we believe that, if handled sensibly, these challenges can offer insights and opportunities in education scenarios to acquaint students early on with potential societal biases, criticalities, and risks of AI applications. We conclude with recommendations for how to address these challenges and ensure that such models are used in a responsible and ethical manner in education.}
}
@article{HUANG202233634,
title = {Transition from synaptic simulation to nonvolatile resistive switching behavior based on an Ag/Ag:ZnO/Pt memristor},
journal = {RSC Advances},
volume = {12},
number = {52},
pages = {33634-33640},
year = {2022},
issn = {2046-2069},
doi = {https://doi.org/10.1039/d2ra05483c},
url = {https://www.sciencedirect.com/science/article/pii/S2046206922032296},
author = {Yong Huang and Jiahao Yu and Yu Kong and Xiaoqiu Wang},
abstract = {ABSTRACT
The advent of memristors and the continuing research and development in the field of brain-inspired computing could allow realization of a veritable “thinking machine”. In this study, ZnO-based memristors were fabricated using a radio frequency magnetron sputtering method. The ZnO oxide layer was prepared by incorporating silver nanocrystals (NCs). Several synaptic functions, i.e. nonlinear transmission characteristics, short-term potentiation, long-term potentiation/depression, and pair-pulse facilitation, were imitated in the memristor successfully. Furthermore, the transition from synaptic behaviors to bipolar resistive switching behaviors of the device was also observed under repeated stimulus. It is speculated that the switching mechanism is due to the formation and rupture of the conductive Ag filaments and the corresponding electrochemical metallization. The experimental results demonstrate that the Ag/Ag:ZnO/Pt memristor with resistive switching and several synaptic behaviors has a potential application in neuromorphic computing and data storage systems.}
}
@article{BINA2020102475,
title = {Beyond techno-utopia and its discontents: On the role of utopianism and speculative fiction in shaping alternatives to the smart city imaginary},
journal = {Futures},
volume = {115},
pages = {102475},
year = {2020},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2019.102475},
url = {https://www.sciencedirect.com/science/article/pii/S0016328719303374},
author = {Olivia Bina and Andy Inch and Lavínia Pereira},
keywords = {Smart cities, Ways of knowing, Urban imaginaries, Utopianism, Fiction},
abstract = {In recent years, the ösmart city’ has become established in policy and planning discourse, embedding visions of an urban future where ubiquitous technology offers efficient solutions to the pathologies of the contemporary city. In response, a rapidly growing social-scientific literature is critically exploring how the smart city imaginary (SCI) promotes ötechno-utopian’ fantasies, ignoring the risks of a technologically determined future. In this paper we begin by considering SCI as emblematic of the colonization of contemporary (urban) futures by vested interests, arguing for the need for diverse and plural imaginaries and thus for a re-engagement of the social sciences. We explore how critical social scientific contributions to shaping futures might be deepened through further engagement with utopian theory and speculative fiction, two traditions of future-orientated thinking that seek to combine critique with constructive thinking about alternatives. We therefore contribute to ö50 + 50 Theme 2: Framing Futures in 2068-the limits of and opportunities for futures research’ by 1) extending critique of contemporary claims about (smart urban) futures, and; 2) exploring how utopianism and fiction can expand ways of thinking, imagining and knowing futures.}
}
@article{MOLINARO20231150,
title = {A goal-centric outlook on learning},
journal = {Trends in Cognitive Sciences},
volume = {27},
number = {12},
pages = {1150-1164},
year = {2023},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2023.08.011},
url = {https://www.sciencedirect.com/science/article/pii/S1364661323002073},
author = {Gaia Molinaro and Anne G.E. Collins},
keywords = {goals, learning, decision-making, reinforcement learning, rewards, abstraction, motivation, computational modeling},
abstract = {Goals play a central role in human cognition. However, computational theories of learning and decision-making often take goals as given. Here, we review key empirical findings showing that goals shape the representations of inputs, responses, and outcomes, such that setting a goal crucially influences the central aspects of any learning process: states, actions, and rewards. We thus argue that studying goal selection is essential to advance our understanding of learning. By following existing literature in framing goal selection within a hierarchy of decision-making problems, we synthesize important findings on the principles underlying goal value attribution and exploration strategies. Ultimately, we propose that a goal-centric perspective will help develop more complete accounts of learning in both biological and artificial agents.}
}
@incollection{ZHUGE2016149,
title = {15 - Limitations and challenges},
editor = {Hai Zhuge},
booktitle = {Multi-Dimensional Summarization in Cyber-Physical Society},
publisher = {Morgan Kaufmann},
pages = {149-151},
year = {2016},
series = {Computer Science Reviews and Trends},
isbn = {978-0-12-803455-2},
doi = {https://doi.org/10.1016/B978-0-12-803455-2.00015-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128034552000159},
author = {Hai Zhuge},
keywords = {Summarization, limitations, challenges, representations, computing},
abstract = {The limitation of summarisation lies in the natural differences between human and machine, between languages, and between the ways of observation and thinking of authors and those of readers. The significant evolution of documents in form and function in cyber-physical society challenges the paradigm of summarization research.}
}
@article{ALANO20221,
title = {Professor Richard Carter (1945–2021)},
journal = {Trends in Parasitology},
volume = {38},
number = {1},
pages = {1-3},
year = {2022},
issn = {1471-4922},
doi = {https://doi.org/10.1016/j.pt.2021.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S1471492221002609},
author = {Pietro Alano and Richard Culleton and Christian Doerig and Louis Miller},
abstract = {The malaria research community lost a pioneer when Professor Richard Carter passed away at the age of 76 on 4 September 2021. Richard was an exceptionally brilliant malariologist, always inquisitive and gifted with an unorthodox way of thinking.}
}
@article{MAHOWALD2024517,
title = {Dissociating language and thought in large language models},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {6},
pages = {517-540},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.01.011},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324000275},
author = {Kyle Mahowald and Anna A. Ivanova and Idan A. Blank and Nancy Kanwisher and Joshua B. Tenenbaum and Evelina Fedorenko},
keywords = {large language models, language and thought, cognitive neuroscience, linguistic competence, computational modeling},
abstract = {Large language models (LLMs) have come closest among all models to date to mastering human language, yet opinions about their linguistic and cognitive capabilities remain split. Here, we evaluate LLMs using a distinction between formal linguistic competence (knowledge of linguistic rules and patterns) and functional linguistic competence (understanding and using language in the world). We ground this distinction in human neuroscience, which has shown that formal and functional competence rely on different neural mechanisms. Although LLMs are surprisingly good at formal competence, their performance on functional competence tasks remains spotty and often requires specialized fine-tuning and/or coupling with external modules. We posit that models that use language in human-like ways would need to master both of these competence types, which, in turn, could require the emergence of separate mechanisms specialized for formal versus functional linguistic competence.}
}
@article{WANG2022e09982,
title = {Applying the post-digital strategy of anexact architecture to non-standard design practices within the challenging construction contexts},
journal = {Heliyon},
volume = {8},
number = {8},
pages = {e09982},
year = {2022},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2022.e09982},
url = {https://www.sciencedirect.com/science/article/pii/S2405844022012701},
author = {Sining Wang and Dandan Lin},
keywords = {Design practice strategy, Post-digital architecture, Parametric design, Developing region, Non-standard architecture},
abstract = {New architectural forms offered by digital design approaches often appear incompatible with the prescribed precision and control in construction, especially in developing regions where advanced implementation means are limited. In response, this paper suggests working with design practice indeterminacy. Named ‘anexact architecture’, the post-digital design practice strategy presents a convergent diagram of seeking the feasible design solution space. It relies on the procedural parametric modelling to constantly integrate computation and humanisation, so that a rigorous built outcome is capable of accommodating project-specific idiosyncrasies and constraints. The demonstrator projects are discussed based on the combination of the Participatory Action Research method and the idea of anexact architecture. This paper aims to illustrate the peculiarity of anexact architecture and its ideology of treating design delivery uncertainties as essentials rather than negatives when practicing in a volatile construction context.}
}
@article{SURYARAJ2024124407,
title = {Block based motion estimation model using CNN with representative point matching algorithm for object tracking in videos},
journal = {Expert Systems with Applications},
volume = {255},
pages = {124407},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.124407},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424012739},
author = {C.K. Suryaraj and M.R. Geetha},
keywords = {Motion Estimation, Object Tracking, CNN, RPM, SSIM, Video Sequence, Computation Time},
abstract = {Motion estimation is considered significant for tracking the movement of an object in video sequences, and it is widely used in various video processing applications. Traditionally, many researchers focus on pixel-based motion estimation for object tracking, but it experienced increased computation time and cost. To reduce computation time, the utilization of a block-based motion estimation approach for object tracking is a recent trend. The existing block-based approach faces difficulty in finding representative points within the intensity domain. Therefore, this current research merged the deep learning approach with a block-matching algorithm for achieving efficient object tracking. In this proposed work, initially, video sequences are collected from a benchmark video dataset. Then, the acquired video sequences are segmented into frames. From the segmented frames, current and previous frames are considered for motion estimation. Frames are sent for the data augmentation process in which the process of flipping, cropping, and rotation is carried out. Then, the augmented frames are sent into Convolutional Neural Network (CNN) for feature extraction. Representative Point Matching (RPM) is used to estimate the motion vector based on the extracted features. After estimating the motion vector, the similarity between two consecutive frames is found using Structural Similarity Index (SSIM) technique. Finally, based on the similarity score, the movement of an object in the video is tracked effectively. Simulation analysis of the proposed block-based motion estimation model is done by evaluating some performance metrics. RMSE, PSNR, Execution Time, SSIM, and accuracy obtained for the proposed model are 27.5, 26.5 db, 31 sec, 0.91, and 94 %. This analysis suggested that the proposed CNN-RPM motion estimation model performs better in tracking the movement of the object.}
}
@article{SHEFFIELD2024100333,
title = {Understanding Cognitive Behavioral Therapy for Psychosis Through the Predictive Coding Framework},
journal = {Biological Psychiatry Global Open Science},
volume = {4},
number = {4},
pages = {100333},
year = {2024},
issn = {2667-1743},
doi = {https://doi.org/10.1016/j.bpsgos.2024.100333},
url = {https://www.sciencedirect.com/science/article/pii/S2667174324000466},
author = {Julia M. Sheffield and Aaron P. Brinen and Brandee Feola and Stephan Heckers and Philip R. Corlett},
keywords = {Belief updating, CBTp, Persecutory delusions, Predictive coding, Psychotherapy, Volatility},
abstract = {Psychological treatments for persecutory delusions, particularly cognitive behavioral therapy for psychosis, are efficacious; however, mechanistic theories explaining why they work rarely bridge to the level of cognitive neuroscience. Predictive coding, a general brain processing theory rooted in cognitive and computational neuroscience, has increasing experimental support for explaining symptoms of psychosis, including the formation and maintenance of delusions. Here, we describe recent advances in cognitive behavioral therapy for psychosis–based psychotherapy for persecutory delusions, which targets specific psychological processes at the computational level of information processing. We outline how Bayesian learning models employed in predictive coding are superior to simple associative learning models for understanding the impact of cognitive behavioral interventions at the algorithmic level. We review hierarchical predictive coding as an account of belief updating rooted in prediction error signaling. We examine how this process is abnormal in psychotic disorders, garnering noisy sensory data that is made sense of through the development of overly strong delusional priors. We argue that effective cognitive behavioral therapy for psychosis systematically targets the way sensory data are selected, experienced, and interpreted, thus allowing for the strengthening of alternative beliefs. Finally, future directions based on these arguments are discussed.}
}
@incollection{BUJA2005391,
title = {14 - Computational Methods for High-Dimensional Rotations in Data Visualization},
editor = {C.R. Rao and E.J. Wegman and J.L. Solka},
series = {Handbook of Statistics},
publisher = {Elsevier},
volume = {24},
pages = {391-413},
year = {2005},
booktitle = {Data Mining and Data Visualization},
issn = {0169-7161},
doi = {https://doi.org/10.1016/S0169-7161(04)24014-7},
url = {https://www.sciencedirect.com/science/article/pii/S0169716104240147},
author = {Andreas Buja and Dianne Cook and Daniel Asimov and Catherine Hurley},
abstract = {There exist many methods for visualizing complex relations among variables of a multivariate dataset. For pairs of quantitative variables, the method of choice is the scatterplot. For triples of quantitative variables, the method of choice is 3D data rotations. Such rotations let us perceive structure among three variables as shape of point scatters in virtual 3D space. Although not obvious, three-dimensional data rotations can be extended to higher dimensions. The mathematical construction of high-dimensional data rotations, however, is not an intuitive generalization. Whereas three-dimensional data rotations are thought of as rotations of an object in space, a proper framework for their high-dimensional extension is better based on rotations of a low-dimensional projection in high-dimensional space. The term “data rotations” is therefore a misnomer, and something along the lines of “high-to-low dimensional data projections” would be technically more accurate. To be useful, virtual rotations need to be under interactive user control, and they need to be animated. We therefore require projections not as static pictures but as movies under user control. Movies, however, are mathematically speaking one-parameter families of pictures. This article is therefore about one-parameter families of low-dimensional projections in high-dimensional data spaces. We describe several algorithms for dynamic projections, all based on the idea of smoothly interpolating a discrete sequence of projections. The algorithms lend themselves to the implementation of interactive visual exploration tools of high-dimensional data, such as so-called grand tours, guided tours and manual tours.}
}
@incollection{MARWALA202185,
title = {Chapter 7 - Bounded rational counterfactuals},
editor = {Tshilidzi Marwala},
booktitle = {Rational Machines and Artificial Intelligence},
publisher = {Academic Press},
pages = {85-96},
year = {2021},
isbn = {978-0-12-820676-8},
doi = {https://doi.org/10.1016/B978-0-12-820676-8.00012-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128206768000120},
author = {Tshilidzi Marwala},
keywords = {Rational counterfactuals, Bounded rationality, Optimization, Artificial intelligence},
abstract = {The rational counterfactual is identified from the factual and the knowledge of the laws that govern the relationships between the antecedent and the consequent of the factual, which maximizes the attainment of the desired consequent. However, the attainment of the desired consequent is not perfect and is, in fact, limited, which makes these counterfactuals bounded rational counterfactuals. In counterfactual thinking, factual statements such as “The COVID-19 afflicted the world, and the world economy contracted by 3%,” has the counterfactual “The COVID-19 did not afflict the world, and the world economy grew by 3%.” In this chapter, we use intelligent machines that use AI to build bounded rational counterfactuals. It is observed that intelligent machines can achieve bounded rational counterfactual better than human agents. In general, quantifiable factual easily has bounded rational counterfactuals when compared to qualitative counterfactuals.}
}
@article{SCHREIBER20142544,
title = {A few bad ideas on the way to the triumph of parallel computing},
journal = {Journal of Parallel and Distributed Computing},
volume = {74},
number = {7},
pages = {2544-2547},
year = {2014},
note = {Special Issue on Perspectives on Parallel and Distributed Processing},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2013.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S0743731513002177},
author = {Robert Schreiber},
keywords = {Parallelism, Amdahl, Automatic parallelization, Accelerators, Exascale},
abstract = {Parallelism has become mainstream, in the multicore chip, the GPU, and the internet datacenter running MapReduce. In my field, large-scale scientific computing, parallelism now reigns triumphant. It was no simple, direct route that led to this triumph. Along the way, we were confused by ideas that, in retrospect, turned out to be distractions and errors. The thinking behind them was reasonable, but wrong. One can learn from a dissection of mistakes, so I will retell part of the story here.}
}
@article{NISHANT2020102104,
title = {Artificial intelligence for sustainability: Challenges, opportunities, and a research agenda},
journal = {International Journal of Information Management},
volume = {53},
pages = {102104},
year = {2020},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2020.102104},
url = {https://www.sciencedirect.com/science/article/pii/S0268401220300967},
author = {Rohit Nishant and Mike Kennedy and Jacqueline Corbett},
keywords = {Agenda for practice, AI, Artificial intelligence, Climate change, Environmental governance, Natural environment, Research agenda, Sustainability},
abstract = {Artificial intelligence (AI) will transform business practices and industries and has the potential to address major societal problems, including sustainability. Degradation of the natural environment and the climate crisis are exceedingly complex phenomena requiring the most advanced and innovative solutions. Aiming to spur groundbreaking research and practical solutions of AI for environmental sustainability, we argue that AI can support the derivation of culturally appropriate organizational processes and individual practices to reduce the natural resource and energy intensity of human activities. The true value of AI will not be in how it enables society to reduce its energy, water, and land use intensities, but rather, at a higher level, how it facilitates and fosters environmental governance. A comprehensive review of the literature indicates that research regarding AI for sustainability is challenged by (1) overreliance on historical data in machine learning models, (2) uncertain human behavioral responses to AI-based interventions, (3) increased cybersecurity risks, (4) adverse impacts of AI applications, and (5) difficulties in measuring effects of intervention strategies. The review indicates that future studies of AI for sustainability should incorporate (1) multilevel views, (2) systems dynamics approaches, (3) design thinking, (4) psychological and sociological considerations, and (5) economic value considerations to show how AI can deliver immediate solutions without introducing long-term threats to environmental sustainability.}
}
@article{BEATY2017189,
title = {Creative constraints: Brain activity and network dynamics underlying semantic interference during idea production},
journal = {NeuroImage},
volume = {148},
pages = {189-196},
year = {2017},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2017.01.012},
url = {https://www.sciencedirect.com/science/article/pii/S1053811917300125},
author = {Roger E. Beaty and Alexander P. Christensen and Mathias Benedek and Paul J. Silvia and Daniel L. Schacter},
keywords = {Creativity, Divergent thinking, Cognitive control, Functional connectivity, Default network, Executive control network},
abstract = {Functional neuroimaging research has recently revealed brain network interactions during performance on creative thinking tasks—particularly among regions of the default and executive control networks—but the cognitive mechanisms related to these interactions remain poorly understood. Here we test the hypothesis that the executive control network can interact with the default network to inhibit salient conceptual knowledge (i.e., pre-potent responses) elicited from memory during creative idea production. Participants studied common noun-verb pairs and were given a cued-recall test with corrective feedback to strengthen the paired association in memory. They then completed a verb generation task that presented either a previously studied noun (high-constraint) or an unstudied noun (low-constraint), and were asked to “think creatively” while searching for a novel verb to relate to the presented noun. Latent Semantic Analysis of verbal responses showed decreased semantic distance values in the high-constraint (i.e., interference) condition, which corresponded to increased neural activity within regions of the default (posterior cingulate cortex and bilateral angular gyri), salience (right anterior insula), and executive control (left dorsolateral prefrontal cortex) networks. Independent component analysis of intrinsic functional connectivity networks extended this finding by revealing differential interactions among these large-scale networks across the task conditions. The results suggest that interactions between the default and executive control networks underlie response inhibition during constrained idea production, providing insight into specific neurocognitive mechanisms supporting creative cognition.}
}
@article{JACKSON2012370,
title = {Information technology use and creativity: Findings from the Children and Technology Project},
journal = {Computers in Human Behavior},
volume = {28},
number = {2},
pages = {370-376},
year = {2012},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2011.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S0747563211002147},
author = {Linda A. Jackson and Edward A. Witt and Alexander Ivan Games and Hiram E. Fitzgerald and Alexander {von Eye} and Yong Zhao},
keywords = {Videogames, Creativity, Children, Technology use},
abstract = {This research examined relationships between children’s information technology (IT) use and their creativity. Four types of information technology were considered: computer use, Internet use, videogame playing and cell phone use. A multidimensional measure of creativity was developed based on Sternberg and Lubart, 1999, Subrahmanyam et al., 2006 test of creative thinking. Participants were 491 12-year olds; 53% were female, 34% were African American and 66% were Caucasian American. Results indicated that videogame playing predicted of all measures of creativity. Regardless of gender or race, greater videogame playing was associated with greater creativity. Type of videogame (e.g., violent, interpersonal) was unrelated to videogame effects on creativity. Gender but not race differences were obtained in the amount and type of videogame playing, but not in creativity. Implications of the findings for future research to test the causal relationship between videogame playing and creativity and to identify mediator and moderator variables are discussed.}
}
@article{GUO2017677,
title = {Research on Element Importance of Shafting Installation Based on QFD and FMEA},
journal = {Procedia Engineering},
volume = {174},
pages = {677-685},
year = {2017},
note = {13th Global Congress on Manufacturing and Management Zhengzhou, China 28-30 November, 2016},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2017.01.205},
url = {https://www.sciencedirect.com/science/article/pii/S1877705817302059},
author = {Qi Guo and Kuangjie Sheng and Zheng Wang and Xilin Zhang and hengyi Yang and Rui Miao},
keywords = {Quality Function Deployment, Failure Mode and Effects Analysis, Marine Shafting, Comprehensive Importance},
abstract = {Development in today's shipbuilding economy is transforming from the quantitative growth to the quality growth. Quality function deployment (QFD) and failure mode and effects analysis (FMEA) adopt different ways of thinking, they remedy their respective limitations for each other, that can effectively guide the quality control. This paper is combined of HuDong ZhongHua Shipbuilding (group) co. LTD.’s shafting installation process, starting from the QFD customer requirements for finding the importance of production process elements and correction by FMEA, ultimately acquire the comprehensive importance of shafting installation process elements.}
}
@article{BLOTE2000221,
title = {Mental computation and conceptual understanding},
journal = {Learning and Instruction},
volume = {10},
number = {3},
pages = {221-247},
year = {2000},
issn = {0959-4752},
doi = {https://doi.org/10.1016/S0959-4752(99)00028-6},
url = {https://www.sciencedirect.com/science/article/pii/S0959475299000286},
author = {Anke W. Blöte and Anton S. Klein and Meindert Beishuizen},
keywords = {Arithmetic, Procedural flexibility, Conceptual understanding},
abstract = {The goal of this study was to assess the strategic flexibility of students in mental arithmetic up to the number 100. Sixty Dutch second-graders who took part in an experimental ‘realistic arithmetic’ program participated in the study. Results showed that students' preference for certain mathematical procedures depended on the number characteristics of the problems. This indicates that the students had a good conceptual understanding of numbers and procedures. Their actual use of these procedures, however, was somewhat limited. Most problems were solved within a sequential structure. A completely different procedure was used for solving subtraction problems that had a very small difference between the two numbers. Furthermore, it was found that a substantial increase in the students' use of a base-ten procedure occurred after the introduction of this procedure in the mathematics curriculum. Students' preference for this procedure also increased, although to a lesser extent. Another finding of the study was that students exhibited more flexible strategic behaviour with context problems than with numerical-expression problems.}
}
@incollection{TEZDUYAR199521,
title = { - Massively parallel finite element computation of 3d flows - mesh update strategies in computation of moving boundaries and interfaces°†},
editor = {A. Ecer and J. Hauser and P. Leca and J. Periaux},
booktitle = {Parallel Computational Fluid Dynamics 1993},
publisher = {North-Holland},
address = {Amsterdam},
pages = {21-30},
year = {1995},
isbn = {978-0-444-81999-4},
doi = {https://doi.org/10.1016/B978-044481999-4/50131-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780444819994501316},
author = {T. Tezduyar and S. Aliabadi and M. Behr and A. Johnson and S. Mittal},
abstract = {Publisher Summary
This chapter describes the parallel implicit finite element computations of compressible and incompressible flows with the Connection Machine (CM)—CM-200 and CM-5. The parallel implementations are based on the assumption that the mesh is unstructured. The computations of flow problems involving moving boundaries and interfaces are achieved by using the deformable-spatial-domain or stabilized space-time method. In this method, with special mesh update strategies, the frequency of remeshing is minimized. This avoids the projection errors generated by remeshing and also avoids the cost associated with repeated mesh generation and parallelization setup. This method and its implementation on the massively parallel supercomputers provide a new capability to solve a large class of practical problems involving free surfaces, two-liquid interfaces, and fluid-structure interactions. Now 3D incompressible flow computations can be carried out at sustained speeds of up to 7.0 GigaFLOPS on the CM-5. The 3D compressible flow computations are carried out at sustained speeds of up to 12.2 GigaFLOPS on the CM-5. This parallel performance is significant in the sense that now there is a new level of computational capability in finite element solution of 3D flow problems. Several 3D flow problems are solved using these parallel and update mesh strategies. The chapter discusses the computation of incompressible flow occurring between two concentric cylinders, sloshing in a liquid-filled container subjected to vertical vibrations, and supersonic flow past a delta-wing.}
}
@article{GAO2022509,
title = {An integrated simulation method for PVSS parametric design using multi-objective optimization},
journal = {Frontiers of Architectural Research},
volume = {11},
number = {3},
pages = {509-526},
year = {2022},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2021.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S209526352100087X},
author = {Qing Gao and Ying Yang and Qian Wang},
keywords = {Integrated simulation, PV shading System, Parametric design, Multi-objective optimization, Thermal-daylighting balance},
abstract = {An adequate strategy for achieving energy efficiency when designing a photovoltaic shading system (PVSS) shall find an equilibrium between sunlight heat gain and daylight transmittances through effective analysis tools in a building's early design phases. However, traditional simulation methods are either time-consuming or lacking architectonical thinking. This paper proposes a new method for architects to integrate thermal and daylighting performance by using parametric script modelling and optimize their balance with multi-objective optimization (MOO) algorithm in PVSS design. A case study was conducted to demonstrate the workflow of proposed integrated simulation method in PVSS design, and further compared the results with that of three single-objective optimizations under the same design requirement. The findings show that the integrated framework is a feasible method for PVSS design and can be extended into the design of other advance shading system or building integrated photovoltaic.}
}
@article{BELLA2023100509,
title = {Circular dichroism simulations of chiral buckybowls by means curvature analyses},
journal = {FlatChem},
volume = {40},
pages = {100509},
year = {2023},
issn = {2452-2627},
doi = {https://doi.org/10.1016/j.flatc.2023.100509},
url = {https://www.sciencedirect.com/science/article/pii/S2452262723000417},
author = {Giovanni Bella and Giuseppe Bruno and Antonio Santoro},
keywords = {Buckybowl, Chirality, Curvature, TD-DFT, Circular dichroism},
abstract = {A detailed understanding and interpretation of chiral properties of molecular systems, especially in condensed phase, often requires computational models that allow their structural and electronic features to be connected to the observed experimental spectra. The present paper is focused on modelling the circular dichroism spectra of chiral buckybowls, combining topological aspects and the density functional theory. For the first time Ball Pivoting Algorithm was proposed to hook up the chemical topology to the DFT through the surface reconstruction. Particularly, the gaussian curvature of a constructed probe set of corannulene and sumanene derivatives was used as discriminant parameter to benchmark a list of 10 functionals (B3LYP, B97D, M06-2X, HSEH1PBE, wB97XD, CAM-B3LYP, LC-wPBE, TPSSTPSS, mPW1PW91 and APFD). The latter provide to be noticeably accurate to reproduce the curvature effect of the considered molecules. A TD-DFT/BOMD mixed approach provided a comprehensive overview of the spectral chiral pattern prediction trends when multiple DFT functionals are scanned. The preliminary topological analysis efforts were then recompensed with the very precise computed CD spectra, again APFD confirmed as the leader functional, this time for TD-DFT vertical transition calculations. Therefore, we strongly recommend the use of the of dispersion embedded APFD functional coupled with the 6–311++G(2d,2p) basis set for the computation of the functionalized chiral buckybowls ECD spectra. © 2017 Elsevier Inc. All rights reserved.}
}
@article{CIULLO2021100349,
title = {A framework for building climate storylines based on downward counterfactuals: The case of the European Union Solidarity fund},
journal = {Climate Risk Management},
volume = {33},
pages = {100349},
year = {2021},
issn = {2212-0963},
doi = {https://doi.org/10.1016/j.crm.2021.100349},
url = {https://www.sciencedirect.com/science/article/pii/S2212096321000784},
author = {Alessio Ciullo and Olivia Martius and Eric Strobl and David N. Bresch},
keywords = {Climate storylines, Downward counterfactuals, European Union Solidarity Fund},
abstract = {Recent research introduced the concept of climate storylines as an alternative approach to estimate climate impact and better deal with uncertainties. A climate storyline is an event-based approach which aims at building “physically self-consistent unfolding of past events, or of plausible future events or pathways”. As such, climate storylines may profit from downward counterfactual thinking, which aims at analyzing how past events could have been worse. Notwithstanding the various applications of downward counterfactual thinking in the natural risk management literature, no study relates this with the climate storyline approach. The main goal of this paper is thus to introduce a framework that supports the development of climate storylines from downward counterfactuals. The framework is event-oriented, it focuses on impact, and it is designed to be applied in a participatory fashion. As a proof-of-concept application, we study the impact of tropical cyclones on the European Union Solidarity Fund (EUSF) without conducting a participatory analysis. Tropical cyclones represent a serious threat for the European outermost regions, and their impact to the EUSF capital availability has never been studied. We find that payouts due to tropical cyclones can hamper a recovery of the fund if large payouts concurrently occur in mainland Europe. To avoid this also considering future changes, an increase in capitalization up to 90 % percent may be required.}
}
@article{SCHUELLER1997197,
title = {A state-of-the-art report on computational stochastic mechanics},
journal = {Probabilistic Engineering Mechanics},
volume = {12},
number = {4},
pages = {197-321},
year = {1997},
note = {A State-of-the-Art Report on Computational Stochastic Mechanics},
issn = {0266-8920},
doi = {https://doi.org/10.1016/S0266-8920(97)00003-9},
url = {https://www.sciencedirect.com/science/article/pii/S0266892097000039},
author = {G.I. Schuëller}
}
@article{SUYOTO2015328,
title = {Parametric Approach as a Tool for Decision-making in Planning and Design Process. Case study: Office Tower in Kebayoran Lama},
journal = {Procedia - Social and Behavioral Sciences},
volume = {184},
pages = {328-337},
year = {2015},
note = {REFLECTIONS ON CREATIVITY: PUBLIC ENGAGEMENT AND THE MAKING OF PLACE},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2015.05.098},
url = {https://www.sciencedirect.com/science/article/pii/S1877042815033479},
author = {William Suyoto and Aswin Indraprastha and Heru W. Purbo},
keywords = {parametric design, discrete method, office tower, building modeling},
abstract = {This study offers discrete method in parametric design to solve problems during design process (programming, site planning, massing, structure planning, and facade planning). This study is applied in the design of office tower in Kebayoran Lama, Jakarta. The objective of the study is to explore the uses of parametric design method, yet, maintains its time feasibility. The result of the study is a method for planning and design that is more advantageous than the conventional ones in terms of simultaneous, coordinated and accountable. This method enables designer to do many iterations and monitor changes during the design process. However, the method needs a higher skill in logical thinking during the process, which demands time.}
}
@article{GROUT2014680,
title = {Taking Computer Science and Programming into Schools: The Glyndŵr/BCS Turing Project},
journal = {Procedia - Social and Behavioral Sciences},
volume = {141},
pages = {680-685},
year = {2014},
note = {4th World Conference on Learning Teaching and Educational Leadership (WCLTA-2013)},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2014.05.119},
url = {https://www.sciencedirect.com/science/article/pii/S1877042814035435},
author = {Vic Grout and Nigel Houlden},
keywords = {Computer science, programming, computing curriculum, teacher training, British Computer Society (BCS) Academy, Computing At School (CAS), Council of Professors and Heads of Computing (CPHC), Lego NXT Mindstorm, Raspberry Pi, Robot C, Scratch, Picoboards ;},
abstract = {2012 and 2013 have been challenging years for Computer Science (CS) education in the UK. After decades of national neglect, there has been a sudden impetus to reintroduce CS into the 11-16 age school curriculums. Immediate obstacles include a generation of children with no CS background and an estimated need for 20,000 new CS teachers - existing UK IT teachers being insufficiently qualified and experienced. The Computing at School (CAS) movement has been instrumental in this quantum transition from an IT to Computing syllabus, as have the British Computer Society (BCS), leading UK universities and a number of major international technology companies, including Microsoft, Google, IBM, British Telecom and Facebook.This paper discusses the background to this position and the progress being made to address these challenges. It describes, in particular, the work of the BCS-funded Glyndwr University ‘Turing Project’ in introducing Welsh high-school students and staff to high-level programming and ‘computational thinking’. The Turing Project uses an innovative combination of Lego NXT Mindstorm robots, Raspberry Pi computers and PicoBoard hardware together with the Robot C and Scratch programming platforms. The paper discusses initial objectives and the general approach, describes focused delivery across different age groups and ability ranges and presents results and analysis demonstrating the effectiveness of the programme. Lessons learnt and future directions are considered in conclusion.}
}
@article{GUNNING2021169,
title = {Brain-based mechanisms of late-life depression: Implications for novel interventions},
journal = {Seminars in Cell & Developmental Biology},
volume = {116},
pages = {169-179},
year = {2021},
note = {Special Issue: Myelin edited by Gonçalo Castelo-Branco and Roman Chrast / Special issue: Aging in the nervous system edited by Mara Mather},
issn = {1084-9521},
doi = {https://doi.org/10.1016/j.semcdb.2021.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S1084952121001117},
author = {Faith M. Gunning and Lauren E. Oberlin and Maddy Schier and Lindsay W. Victoria},
keywords = {Aging, Depression, Functional connectivity, White matter, Apathy, Executive function},
abstract = {Late-life depression (LLD) is a particularly debilitating illness. Older adults suffering from depression commonly experience poor outcomes in response to antidepressant treatments, medical comorbidities, and declines in daily functioning. This review aims to further our understanding of the brain network dysfunctions underlying LLD that contribute to disrupted cognitive and affective processes and corresponding clinical manifestations. We provide an overview of a network model of LLD that integrates the salience network, the default mode network (DMN) and the executive control network (ECN). We discuss the brain-based structural and functional mechanisms of LLD with an emphasis on their link to clinical subtypes that often fail to respond to available treatments. Understanding the brain networks that underlie these disrupted processes can inform the development of targeted interventions for LLD. We propose behavioral, cognitive, or computational approaches to identifying novel, personalized interventions that may more effectively target the key cognitive and affective symptoms of LLD.}
}
@article{TWORZYDLO199387,
title = {Towards an automated environment in computational mechanics},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {104},
number = {1},
pages = {87-143},
year = {1993},
issn = {0045-7825},
doi = {https://doi.org/10.1016/0045-7825(93)90208-F},
url = {https://www.sciencedirect.com/science/article/pii/004578259390208F},
author = {W.W. Tworzydlo and J.T. Oden},
abstract = {Effective methods leading to an automated, computer-based solution of complex engineering design problems are studied in this paper. In particular, methods of automation of the finite element analyses are of primary interest here. This includes algorithmic approaches, based on error estimation. adaptivity and smart algorithms, as well as heuristic approaches based on methods of knowledge engineering. A computational environment, which interactively couples h-p adaptive finite element methods with object oriented programming and expert system tools, is presented. Several examples illustrate the merit and potential of the approaches studied here and confirm the feasibility of developing fully automated design environments.}
}
@article{CALEFFI2024110672,
title = {Distributed quantum computing: A survey},
journal = {Computer Networks},
volume = {254},
pages = {110672},
year = {2024},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2024.110672},
url = {https://www.sciencedirect.com/science/article/pii/S1389128624005048},
author = {Marcello Caleffi and Michele Amoretti and Davide Ferrari and Jessica Illiano and Antonio Manzalini and Angela Sara Cacciapuoti},
keywords = {Quantum internet, Quantum networks, Quantum communications, Quantum computing, Quantum computation, Distributed quantum computing, Quantum algorithms, Quantum compiler, Quantum compiling, Simulator},
abstract = {Nowadays, quantum computing has reached the engineering phase, with fully-functional quantum processors integrating hundreds of noisy qubits. Yet – to fully unveil the potential of quantum computing out of the labs into the business reality – the challenge ahead is to substantially scale the qubit number, reaching orders of magnitude exceeding thousands of fault-tolerant qubits. To this aim, the distributed quantum computing paradigm is recognized as the key solution for scaling the number of qubits. Indeed, accordingly to such a paradigm, multiple small-to-moderate-scale quantum processors communicate and cooperate for executing computational tasks exceeding the computational power of single processing devices. The aim of this survey is to provide the reader with an overview about the main challenges and open problems arising with distributed quantum computing from a computer and communications engineering perspective. Furthermore, this survey provides an easy access and guide towards the relevant literature and the prominent results in the field.}
}
@incollection{LI2014249,
title = {Chapter 8 - Image Processing at Your Fingertips: The New Horizon of Mobile Imaging},
editor = {Joel Trussell and Anuj Srivastava and Amit K. Roy-Chowdhury and Ankur Srivastava and Patrick A. Naylor and Rama Chellappa and Sergios Theodoridis},
series = {Academic Press Library in Signal Processing},
publisher = {Elsevier},
volume = {4},
pages = {249-264},
year = {2014},
booktitle = {Academic Press Library in Signal Processing: Volume 4},
issn = {2351-9819},
doi = {https://doi.org/10.1016/B978-0-12-396501-1.00008-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012396501100008X},
author = {Xin Li},
keywords = {Mobile imaging, Mobile computing, Interactive image processing, Human network interaction},
abstract = {In this chapter, we briefly review the history of mobile imaging and current trend of mobile computing—namely interacting with a computer without an interface. Specifically, we highlight a list of image processing problems at fingertips: intelligent image acquisition, interactive image matting, dynamic image mosaicing and supervised image restoration. The unifying theme is how human interaction can reshape our thinking of conventional image processing algorithms. Several promising applications related to fingertip image processing are discussed at the end.}
}
@article{DUENASDIEZ2019514,
title = {How Chemistry Computes: Language Recognition by Non-Biochemical Chemical Automata. From Finite Automata to Turing Machines},
journal = {iScience},
volume = {19},
pages = {514-526},
year = {2019},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2019.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S2589004219302858},
author = {Marta Dueñas-Díez and Juan Pérez-Mercader},
keywords = {Chemistry, Chemical Reaction, Computer Science, Theory of Computation},
abstract = {Summary
Every problem in computing can be cast as decision problems of whether strings are in a language or not. Computations and language recognition are carried out by three classes of automata, the most complex of which is the Turing machine. Living systems compute using biochemistry; in the artificial, computation today is mostly electronic. Thinking of chemical reactions as molecular recognition machines, and without using biochemistry, we realize one automaton in each class by means of one-pot, table top chemical reactors: from the simplest, Finite automata, to the most complex, Turing machines. Language acceptance/rejection criteria by automata can be formulated using energy considerations. Our Turing machine uses the Belousov-Zhabotinsky chemical reaction and checks the same symbol in an Avogadro′s number of processors. Our findings have implications for chemical and general computing, artificial intelligence, bioengineering, the study of the origin and presence of life on other planets, and for artificial biology.}
}
@article{GUPTA20062290,
title = {Towards a new paradigm for innovative training methods for capacity building in remote sensing},
journal = {Advances in Space Research},
volume = {38},
number = {10},
pages = {2290-2298},
year = {2006},
note = {Remote Sensing of Oceanographic Processes and Land Surfaces; Space Science Education and Outreach},
issn = {0273-1177},
doi = {https://doi.org/10.1016/j.asr.2006.06.017},
url = {https://www.sciencedirect.com/science/article/pii/S0273117706004285},
author = {R.K. Gupta and P.M. Bala Manikavelu and D. Vijayan and T.S. Prasad},
keywords = {Thinking curricula, Innovative training methods, Capacity building, Remote sensing},
abstract = {Everybody uses a bulb to illustrate an idea but nobody shows where the current comes from. Majority of remote sensing user community comes from natural and social sciences domain while remote sensing technology evolves from physical and engineering sciences. To ensure inculcation and internalization of remote sensing technology by application/resource scientists, trainer needs to transfer physical and engineering concepts in geometric manner. Here, the steering for the transfer of knowledge (facts, procedures, concepts and principles) and skills (thinking, acting, reacting and interacting) needs to take the trainees from Known to Unknown, Concrete to Abstract, Observation to Theory and Simple to Complex. In the initial stage of training/education, experiential learning by instructor led exploring of thematic details in false colour composite (FCC) as well as in individual black and white spectral band(s) imagery by trainees not only creates interest, confidence build-up and orientation towards purposeful learning but also helps them to overcome their inhibitions towards the physical and engineering basal. The methodology to be adopted has to inculcate productive learning, emphasizing more on thinking and trial and error aspects as opposed to reproductive learning based dominantly on being told and imitation. The delivery by trainer needs to ensure dynamic, stimulating and effective discussions through deluging questions pertaining to analysis, synthesis and evaluation nature. This would ensure proactive participation from trainees. Hands-on module leads to creative concretization of concepts. To keep the trainees inspired to learn in an auto mode during post-training period, they need to consciously swim in the current and emerging knowledge pool during training programme. This is achieved through assignment of seminar delivery task to the trainees. During the delivery of seminar, peers and co-trainees drive the trainee to communicate the seminar content not only in what but also in how and why mode. The interest culminated in this manner keeps the entropy of the trainee minimized even during post-training professional life. So, such germinated trainee would always generate positive induction among colleagues; thus, helping in realizing multiplier effect. Based upon above thought process(es), the paper discusses the concept of “thinking curricula” and associated cares needed in training deliveries.}
}
@article{WESSMANENZINGER2019105,
title = {Grade 5 children’s drawings for integer addition and subtraction open number sentences},
journal = {The Journal of Mathematical Behavior},
volume = {53},
pages = {105-128},
year = {2019},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2018.03.010},
url = {https://www.sciencedirect.com/science/article/pii/S0732312317300731},
author = {Nicole M. Wessman-Enzinger},
keywords = {Integers, Integer addition and subtraction, Learner-generated drawings, Number line, Models, Instructional models, Student thinking},
abstract = {Three Grade 5 children participated in a microgenetic study embedded in 12-week teaching experiment on integer addition and subtraction. They solved open number sentences in four individual sessions across the 12-weeks and produced drawings. Through the lens of learner-generated drawings and qualitative analysis, these drawings provide perspective into the children’s thinking about integer addition and subtraction. The following categories are described: Single and Double Set of Objects, Number Sequences, Empty Number Lines, Number Lines, Number Sentences, Sign Emphasis, and Answer in Box Only. One student drew sets of objects frequently and the other students drew number lines more. Descriptions of how use of their drawings changed over time are provided. Implications point to a re-examination of integer instructional models and insight into potential learning progressions.}
}
@article{PUDANE2017517,
title = {Human Emotional Behavior Simulation in Intelligent Agents: Processes and Architecture},
journal = {Procedia Computer Science},
volume = {104},
pages = {517-524},
year = {2017},
note = {ICTE 2016, Riga Technical University, Latvia},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.01.167},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917301680},
author = {Mara Pudane and Egons Lavendelis and Michael A. Radin},
keywords = {Affective agents, Emotive agents, Human behavior simulation, Agent internal architecture},
abstract = {The paper describes and discusses processes needed for human emotional behaviour simulation, in particular, emotion incorporation into rational thinking, as well as presents corresponding agent architecture. Such system would enable various application fields, perhaps one of the most important being enhancing smart devices with emotions. Decreasing frequency of social contact has become an urgent issue, particularly among young people. Emotional and social intelligence are however highly desired set of skills which is impossible to develop without interacting with others. Although this problem has been acknowledged, and there are some efforts to facilitate social contact, e.g., by augmented virtual reality games, that is still not enough. There is a need to develop environment that would allow learning exactly social and emotional skills. This on-going research aims at developing intelligent agents that are able to express and incorporate affects into rational processes.}
}
@article{HALLOWELL2023100240,
title = {Democratising or disrupting diagnosis? Ethical issues raised by the use of AI tools for rare disease diagnosis},
journal = {SSM - Qualitative Research in Health},
volume = {3},
pages = {100240},
year = {2023},
issn = {2667-3215},
doi = {https://doi.org/10.1016/j.ssmqr.2023.100240},
url = {https://www.sciencedirect.com/science/article/pii/S2667321523000240},
author = {Nina Hallowell and Shirlene Badger and Francis McKay and Angeliki Kerasidou and Christoffer Nellåker},
keywords = {Computational phenotyping, Rare disease, Diagnosis, AI, Qualitative interviews},
abstract = {Computational phenotyping (CP) technology uses facial recognition algorithms to classify and potentially diagnose rare genetic disorders on the basis of digitised facial images. This AI technology has a number of research as well as clinical applications, such as supporting diagnostic decision-making. Using the example of CP, we examine stakeholders’ views of the benefits and costs of using AI as a diagnostic tool within the clinic. Through a series of in-depth interviews (n ​= ​20) with: clinicians, clinical researchers, data scientists, industry and support group representatives, we report stakeholder views regarding the adoption of this technology in a clinical setting. While most interviewees were supportive of employing CP as a diagnostic tool in some capacity we observed ambivalence around the potential for artificial intelligence to overcome diagnostic uncertainty in a clinical context. Thus, while there was widespread agreement amongst interviewees concerning the public benefits of AI assisted diagnosis, namely, its potential to increase diagnostic yield and enable faster more objective and accurate diagnoses by up skilling non specialists and thereby enabling access to diagnosis that is potentially lacking, interviewees also raised concerns about ensuring algorithmic reliability, expunging algorithmic bias and that the use of AI could result in deskilling the specialist clinical workforce. We conclude that, prior to widespread clinical implementation, on-going reflection is needed regarding the trade-offs required to determine acceptable levels of bias and conclude that diagnostic AI tools should only be employed as an assistive technology within the dysmorphology clinic.}
}
@incollection{TONDEUR202424,
title = {Chapter 3 - Quality improvement movements},
editor = {Yves Tondeur},
booktitle = {Sustainable Quality Improvements for Isotope Dilution in Molecular Ultratrace Analyses},
publisher = {Elsevier},
pages = {24-70},
year = {2024},
isbn = {978-0-443-29034-3},
doi = {https://doi.org/10.1016/B978-0-443-29034-3.00022-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443290343000223},
author = {Yves Tondeur},
keywords = {Accreditation & technology-in-use, Commitment-based approach, Empirical vs. rational methods, Isomer selectivity, Isotope dilution, Known & documented quality, Legislating competition, Methods innovation rule, Performance assessment, Precision & trueness, Purpose of quality control samples, Quick fixes vs. fundamental solution, Structural conflicts},
abstract = {Emerging over recent years is the notion that quality improvements are hard to come by, when in fact, countless opportunities to integrate new developments are overlooked primarily because of the restrictive ways in which analytical protocols have been written and enforced, or the misconceptions about their function. A point of instability was reached. The manifestation of a quality malaise can be seen through the efforts by many to enhance quality by attempting to transfer the responsibility for quality back to those doing the work and to those who need the work products. The testing industry is now forced into abandoning old formal structures, mental models, and behaviors. Realigning our thinking, discovering the limits, and identifying the structural conflicts are essential if one wants to improve quality. This chapter makes clear that doing the same thing than before better is not enough, or to solely implement quick fixes can be wasteful; somehow, we need to ensure the application of the method coevolves with its environment. As chemists, what can we do?}
}
@article{GUO2024324,
title = {Optimization of robot manipulator configuration calibration by using Zhang neural network for repetitive motion},
journal = {Applied Mathematical Modelling},
volume = {134},
pages = {324-348},
year = {2024},
issn = {0307-904X},
doi = {https://doi.org/10.1016/j.apm.2024.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S0307904X24002853},
author = {Pengfei Guo and Yunong Zhang and Shuai Li and Ning Tan},
keywords = {Temporally dependent quadratic programming, Filtered reciprocal-kind Zhang neural network, Lyapunov stability, Robot manipulator configuration calibration},
abstract = {High precision and low complexity control algorithm plays an important role in the developing of the end-effector instrumentation of different robot manipulators. In order to reduce the kinetic energy and the high-speed drift phenomenon of the repetitive motion tracking task, the robot manipulator needs to calibrate its configuration. In this paper, we formulate the configuration calibration of the robot manipulator for the repetitive motion task as a future quadratic programming optimization problem constrained with equality constraints, which is also regarded as a fundamental problem in artificial intelligence and modern control engineering. Zhang neural network, which is a canonical method, can be adopted to deal with the continuous form of the future optimization problem, named as temporally dependent quadratic programming problem with equality constraints. In order to overcome the issue of temporally dependent inverse computing, a novel Zhang neural network model and its uncertain disturbance tolerant model, which are termed as filtered reciprocal-kind Zhang neural network model and uncertain disturbance tolerant filtered reciprocal-kind Zhang neural network model, respectively, are proposed by integrating the energy-type cost function and Zhang neural network design formula for solving the temporally dependent quadratic programming problem with equality constraints in this paper. Based on the Euler discrete formula and the models, the discrete filtered reciprocal-kind Zhang neural network and the discrete uncertain disturbance tolerant filtered reciprocal-kind Zhang neural network algorithms are proposed for solving the future quadratic programming problem with equality constraints and the robot manipulator configuration calibration problem of repetitive motion. The convergence properties of the reciprocal-kind Zhang neural network model and its corresponding uncertain disturbance tolerant model are obtained by Lyapunov stability theory of nonlinear system and its corresponding perturbed system, while the convergence property of the filtered reciprocal-kind Zhang neural network model is analyzed by the limit thinking. For the repetitive motion task, three experiments for solving the configuration calibration problem of PUMA560, Kinova Jaco2, and Franka Emika Panda robot manipulators are performed to illustrate the effectiveness, robustness and superiority of our proposed discrete filtered reciprocal-kind Zhang neural network algorithms.}
}
@article{FINGER2025101535,
title = {When kids juggle it all: Biliteracy instruction and the development of discourse connectedness in L1 and L2 writing},
journal = {Cognitive Development},
volume = {73},
pages = {101535},
year = {2025},
issn = {0885-2014},
doi = {https://doi.org/10.1016/j.cogdev.2024.101535},
url = {https://www.sciencedirect.com/science/article/pii/S0885201424001205},
author = {Ingrid Finger and Cristiane Ely Lemke and Larissa da Silva Cury and Natália Bezerra Mota and Janaina Weissheimer},
keywords = {Bilingual writing development, Discourse connectedness, Graph analysis, Narrative writing},
abstract = {The present longitudinal study explored how bilingual educational contexts shape children's cognitive and linguistic development. Its main goal was to investigate the development of discourse connectedness (measured by long-range connectedness - LSC) in written narratives in Portuguese (L1) and English (L2) by 78 children of a bilingual school in Brazil within a year span (from 2021 to 2022). Participants created a narrative in their L1 or L2 based on a sequence of five images, which were analyzed with the computational tool SpeechGraphs (Mota et al., 2014). Connectedness scores were expected to vary as a function of Language (L1, L2) and of Year of data collection (Time 1, Time 2), favoring, respectively, the L1 and Time 2. The results confirmed our hypotheses, with long-range recurrence (LSC) scores in the L1 narratives higher than in the L2 at both times of data collection. In addition, the longitudinal analysis revealed higher connectedness scores for narratives written in Time 2 in both languages. Overall, our findings indicate that the children's performance in terms of connectedness progressed in a parallel way in the two languages during the school years, with an expected advantage for the narratives written in their dominant language. In addition, they highlight the potential of using SpeechGraphs - a cost-effective, non-invasive computational tool - to analyze children's use of two prestige languages in a particular bilingual educational context.}
}
@article{ORAN1992251,
title = {Reactive-flow computations on a massively parallel computer},
journal = {Fluid Dynamics Research},
volume = {10},
number = {4},
pages = {251-271},
year = {1992},
issn = {0169-5983},
doi = {https://doi.org/10.1016/0169-5983(92)90025-R},
url = {https://www.sciencedirect.com/science/article/pii/016959839290025R},
author = {Elaine S. Oran and Jay P. Boris and C.Richard DeVore},
abstract = {Results are described of recent research and model developments for performing large-scale multidimensional compressible reacting-flow computations on the Connection Machine, a very fine-grained, parallel computer capable of multigigaflop performance. We are interested both in having general-purpose computer programs for routine production computations and in evaluating the architecture of the computer for a wide range of computational fluid dynamics and reacting-flow applications. We describe the hurdles involved in rethinking the structure and the algorithms to best suit this kind of computer, provide some relative timings for different programs, and describe ways of dealing with special constraints (such as periodic boundary conditions) imposed by the architecture. Finally, representative results are presented for several reacting and nonreacting computations, including the development and propagation of a spark in a hydrogen-oxygen mixture, an imploding detonation, and the generation of beam-channel turbulence.}
}
@incollection{RUNCO200771,
title = {Chapter 3 - Biological Perspectives on Creativity},
editor = {Mark A. Runco},
booktitle = {Creativity},
publisher = {Academic Press},
address = {Burlington},
pages = {71-113},
year = {2007},
isbn = {978-0-12-602400-5},
doi = {https://doi.org/10.1016/B978-012602400-5/50003-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780126024005500034},
author = {Mark A. Runco},
abstract = {Publisher Summary
This chapter discusses various aspects of biological perspectives on creativity. Some of the research on creativity as of late involves the brain and biological correlates of originality, novelty, and insight. Handedness is sometimes used as an indication of hemispheric dominance or hemisphericity, with right-handed people being compared to left-handed people. There are several reports of left-handed persons outnumbering the right-handed in creative and eminent samples. Hemisphericity and other important brain structures and processes contributing to creative thinking and behavior have been studied with EEG, PET, cerebral blood flow, and MRI techniques. Numerous EEG studies suggest that there are particular brain-wave patterns and brain structures that are associated with creative problem solving, or at least specific phases within the problem solving process. EEGs suggest a complex kind of activity while individuals work on divergent thinking tasks. The complexity disappears when those same individuals work on convergent thinking tasks. It is found that the role of the prefrontal cortex in creative thinking and behavior comes from several sources and uses different methodologies.}
}
@incollection{ZHUGE201655,
title = {4 - The think lens},
editor = {Hai Zhuge},
booktitle = {Multi-Dimensional Summarization in Cyber-Physical Society},
publisher = {Morgan Kaufmann},
pages = {55-65},
year = {2016},
series = {Computer Science Reviews and Trends},
isbn = {978-0-12-803455-2},
doi = {https://doi.org/10.1016/B978-0-12-803455-2.00004-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128034552000044},
author = {Hai Zhuge},
keywords = {Think lens, Semantic lens, models, semantic images, multi-dimensional, semantic link network},
abstract = {The nature of many research problems is about scale and dimension of observation and thinking. Whether the patterns and rules on one scale still hold on the other scale? Whether the patterns and rules on one dimension or some dimensions still hold on the other dimension or some other dimensions? Summarization is also about the scale and the dimension of motivation, representation and thinking. Human eyes can focus on not only a part of a representation but also the whole from a certain distance like the lens of camera. The think lens is a mechanism that can zoom in and out while observing, searching, mapping, analysing, planning, predicting, calculating, reasoning, imaging, and representing patterns through semantic computing on various representations according to some principles and rules. This section presents a concept model of the think lens for realising general summarisation in cyber-physical society.}
}
@article{BRAUND2013175,
title = {First steps in teaching argumentation: A South African study},
journal = {International Journal of Educational Development},
volume = {33},
number = {2},
pages = {175-184},
year = {2013},
issn = {0738-0593},
doi = {https://doi.org/10.1016/j.ijedudev.2012.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S0738059312000417},
author = {Martin Braund and Zena Scholtz and Melanie Sadeck and Robert Koopman},
keywords = {Critical thinking, Argumentation, Student teachers, Science},
abstract = {South African student teachers were studied to see how they coped with requirements to teach science using argumentation. Lesson observations, plans, reflective logs, post-teaching interviews and assessment of pupils’ argumentation were used to compare student teachers’ preparedness and interactions with pupils. Two clusters of students were identified representing high preparedness and low interaction. A high degree of preparedness alone did not guarantee high levels of argumentation. Schools’ educational situations were independent of success in teaching argumentation. The outcomes and implications for further development of teaching critical thinking are discussed.}
}
@article{KOWALSKI2020103693,
title = {Effects of attention training technique on brain function in high- and low-cognitive-attentional syndrome individuals: Regional dynamics before, during, and after a single session of ATT},
journal = {Behaviour Research and Therapy},
volume = {132},
pages = {103693},
year = {2020},
issn = {0005-7967},
doi = {https://doi.org/10.1016/j.brat.2020.103693},
url = {https://www.sciencedirect.com/science/article/pii/S0005796720301479},
author = {Joachim Kowalski and Małgorzata Wierzba and Marek Wypych and Artur Marchewka and Małgorzata Dragan},
keywords = {Attention training technique, Metacognitve therapy, Attention, fMRI, S-REF},
abstract = {Objective
Attention Training Technique (ATT) is a key therapeutic tool in metacognitive therapy. There are numerous studies on the behavioral effects of ATT, however the neural mechanisms at work in the training are yet to be uncovered. To date there have been no controlled fMRI studies of ATT.
Method
We conducted a randomized double-blind controlled study of two groups with varying levels of cognitive-attentional syndrome (CAS). Groups with high (n = 43) and low (n = 46) levels of CAS underwent a single session of ATT or a control condition (CON) in an MRI scanner. Participants underwent resting state functional MRI (rsfMRI) sessions and rumination induction sessions both pre- and post-intervention Functional connectivity analyses and inter-subject correlations analyses were computed. We also collected data on emotion and attention functioning pre- and post-intervention.
Results
We did not observe any behavioral effects of ATT. However, direct comparison between ATT and CON sessions revealed greater inter-subject correlations in almost all hubs belonging to the studied functional networks. Moreover, subjects who received ATT showed diminished connectivity in the fronto-parietal network during ruminations and diminished connectivity of the precuneus with lateral occipital cortices and the intraparietal sulcus in abstract thinking and rsfMRI, respectively. Furthermore, some of the observed effects in functional connectivity and inter-subject correlations were specific to different levels of CAS.
Conclusions
Our results may support a proposed neural mechanism for ATT: disengagement of attention from CAS-type processing in either low- or high-CAS individuals. It is also possible that some neural effects of ATT are specific to individuals with different levels of CAS.}
}
@article{BAILEY20158,
title = {Metacognitive beliefs moderate the relationship between catastrophic misinterpretation and health anxiety},
journal = {Journal of Anxiety Disorders},
volume = {34},
pages = {8-14},
year = {2015},
issn = {0887-6185},
doi = {https://doi.org/10.1016/j.janxdis.2015.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S0887618515000791},
author = {Robin Bailey and Adrian Wells},
keywords = {Health anxiety, Metacognition, Catastrophic misinterpretation, Moderation, S-REF model},
abstract = {Catastrophic misinterpretations of bodily symptoms have a central role in cognitive-behavioural models of health anxiety. However, the metacognitive (S-REF) model postulates that psychological disturbance is linked more to beliefs about thinking i.e., metacognition. Equally the relationship between catastrophic misinterpretation and health anxiety should be moderated by metacognition, in particular negative beliefs about the uncontrollability and danger of thinking (MCQNeg). Participants (N=351) completed measures to examine the relationship between these variables. Results indicated positive relationships between metacognition, catastrophic misinterpretation, and health anxiety. Moderation analysis showed that the effect of catastrophic misinterpretations on health anxiety was explained by the proposed interaction with metacognition. Follow-up regression analysis demonstrated the interaction term explained variance in health anxiety when controlling for other variables, and was a stronger unique predictor of health anxiety than catastrophic misinterpretation. Metacognition appears to be an important factor in the relationship between catastrophic misinterpretation and health anxiety, and would have important implications for existing models and treatment.}
}
@incollection{PAGEL201749,
title = {Chapter Four - Testing for Machine Consciousness},
editor = {J.F. Pagel and Philip Kirshtein},
booktitle = {Machine Dreaming and Consciousness},
publisher = {Academic Press},
address = {San Diego},
pages = {49-65},
year = {2017},
isbn = {978-0-12-803720-1},
doi = {https://doi.org/10.1016/B978-0-12-803720-1.00004-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128037201000049},
author = {J.F. Pagel and Philip Kirshtein},
keywords = {Thinking, intelligence, attention, intentionality, volition, self-awareness, artificial intelligence, AI, autonomous entity, Turing Test, Chinese Room Test},
abstract = {Thinking, intelligence, data integration, and attention are aspects of consciousness for which tests have been designed. A short history of the Computer Science field, a description, and an assessment of results obtained to this point for the Turing Test and Chinese Room Test are part of this chapter. Alternative definitions of artificial intelligence are presented. Applied tests for consciousness including those for intelligence, attention, intentionality, volition, and self-awareness are discussed as applied to the assessment of machine systems. Strong AI and the concept of autonomous entities are defined and addressed. The presence of dream-equivalent states is discussed as a potential marker for human-equivalent consciousness.}
}
@article{KIRIMTAY2025111785,
title = {Tau and MAP6 establish labile and stable domains on microtubules},
journal = {iScience},
volume = {28},
number = {3},
pages = {111785},
year = {2025},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2025.111785},
url = {https://www.sciencedirect.com/science/article/pii/S2589004225000446},
author = {Koray Kirimtay and Wenqiang Huang and Xiaohuan Sun and Liang Qiang and Dong V. Wang and Calvin T. Sprouse and Erin M. Craig and Peter W. Baas},
keywords = {Cell Biology, Cellular neuroscience},
abstract = {Summary
We previously documented that individual microtubules in the axons of cultured juvenile rodent neurons consist of a labile domain and a stable domain and that experimental depletion of tau results in selective shortening and partial stabilization of the labile domain. After first confirming these findings in adult axons, we sought to understand the mechanism that accounts for the formation and maintenance of these microtubule domains. We found that fluorescent tau and MAP6 ectopically expressed in RFL-6 fibroblasts predominantly segregate on different microtubules or different domains on the same microtubule, with the tau-rich ones becoming more labile than in control cells and the MAP6-rich ones being more stable than in control cells. These and other experimental findings, which we studied further using computational modeling with tunable parameters, indicate that these two MAPs do not merely bind to pre-existing stable and labile domains but actually create stable and labile domains on microtubules.}
}
@article{SCHULTZ2022104766,
title = {Animacy and the prediction of behaviour},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {140},
pages = {104766},
year = {2022},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2022.104766},
url = {https://www.sciencedirect.com/science/article/pii/S014976342200255X},
author = {Johannes Schultz and Chris D. Frith},
keywords = {Animacy, Action prediction, Goal-directed action, Mentalizing, Theory-of-Mind, Intentions, Economic games, Social cognition},
abstract = {To survive, all animals need to predict what other agents are going to do next. We review neural mechanisms involved in the steps required for this ability. The first step is to determine whether an object is an agent, and if so, how sophisticated it is. This involves brain regions carrying representations of animate agents. The movements of the agent can then be anticipated in the short term based solely on physical constraints. In the longer term, taking into account the agent’s goals and intentions is useful. Observing goal directed behaviour activates the neural action observation network, and predicting future goal directed behaviour is helped by the observer’s own action generating mechanisms. Intentions are critically important in determining actions when interacting with other agents, as several intentions can lie behind an action. Here, interpretation is helped by prior beliefs about the agent and the brain’s mentalising system is engaged. Biologically-constrained computational models of action recognition exist, but equivalent models for understanding intentional agents remain to be developed.}
}
@article{MENG201248,
title = {Extracting linguistic rules from data sets using fuzzy logic and genetic algorithms},
journal = {Neurocomputing},
volume = {78},
number = {1},
pages = {48-54},
year = {2012},
note = {Selected papers from the 8th International Symposium on Neural Networks (ISNN 2011)},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2011.05.029},
url = {https://www.sciencedirect.com/science/article/pii/S0925231211004711},
author = {Dan Meng and Zheng Pei},
keywords = {Computing with Words, Linguistic rules, Fuzzy logic, Genetic algorithms},
abstract = {Linguistic rules in natural language are useful and consistent with human way of thinking. They are very important in multi-criteria decision making due to their interpretability. In this paper, our discussions concentrate on extracting linguistic rules from data sets. In the end, we firstly analyze how to extract complex linguistic data summaries based on fuzzy logic. Then, we formalize linguistic rules based on complex linguistic data summaries, in which, the degree of confidence of linguistic rules from a data set can be explained by linguistic quantifiers and its linguistic truth from the fuzzy logical point of view. In order to obtain a linguistic rule with a higher degree of linguistic truth, a genetic algorithm is used to optimize the number and parameters of membership functions of linguistic values. Computational results show that the proposed method is an alternative method for extracting linguistic rules with linguistic truth from data sets.}
}
@article{CHANG2017160,
title = {Dynamic modeling approaches to characterize the functioning of health systems: A systematic review of the literature},
journal = {Social Science & Medicine},
volume = {194},
pages = {160-167},
year = {2017},
issn = {0277-9536},
doi = {https://doi.org/10.1016/j.socscimed.2017.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S0277953617305300},
author = {Angela Y. Chang and Osondu Ogbuoji and Rifat Atun and Stéphane Verguet},
keywords = {Health systems, Dynamic modeling, Systems thinking, System dynamics},
abstract = {Universal Health Coverage (UHC) is one of the targets for the United Nations Sustainable Development Goal 3. The impetus for UHC has led to an increased demand for time-sensitive tools to enhance our knowledge of how health systems function and to evaluate impact of system interventions. We define the field of “health system modeling” (HSM) as an area of research where dynamic mathematical models can be designed in order to describe, predict, and quantitatively capture the functioning of health systems. HSM can be used to explore the dynamic relationships among different system components, including organizational design, financing and other resources (such as investments in resources and supply chain management systems) – what we call “inputs” – on access, coverage, and quality of care – what we call “outputs”, toward improved health system “outcomes”, namely increased levels and fairer distributions of population health and financial risk protection. We undertook a systematic review to identify the existing approaches used in HSM. We identified “systems thinking” – a conceptual and qualitative description of the critical interactions within a health system – as an important underlying precursor to HSM, and collated a critical collection of such articles. We then reviewed and categorized articles from two schools of thoughts: “system dynamics” (SD)” and “susceptible-infected-recovered-plus” (SIR+). SD emphasizes the notion of accumulations of stocks in the system, inflows and outflows, and causal feedback structure to predict intended and unintended consequences of policy interventions. The SIR + models link a typical disease transmission model with another that captures certain aspects of the system that impact the outcomes of the main model. These existing methods provide critical insights in informing the design of HSM, and provide a departure point to extend this research agenda. We highlight the opportunity to advance modeling methods to further understand the dynamics between health system inputs and outputs.}
}
@article{CAO2020118,
title = {Computational parameter identification of strongest influence on the shear resistance of reinforced concrete beams by fiber reinforcement polymer},
journal = {Structures},
volume = {27},
pages = {118-127},
year = {2020},
issn = {2352-0124},
doi = {https://doi.org/10.1016/j.istruc.2020.05.031},
url = {https://www.sciencedirect.com/science/article/pii/S2352012420302435},
author = {Yan Cao and Qingming Fan and Sadaf {Mahmoudi Azar} and Rayed Alyousef and Salim T. Yousif and Karzan Wakil and Kittisak Jermsittiparsert and Lanh {Si Ho} and Hisham Alabduljabbar and Abdulaziz Alaskar},
keywords = {FRP: reinforced concrete, Shear resistance, Selection procedure, ANFIS},
abstract = {Bars made of fiber reinforcement polymer (FRP) are in common usage for concrete reinforcing instead of steel reinforcing since steel could be affected by corrosion. The concrete beams reinforced by FRP bars have been studied mostly in longitudinal direction without shear reinforcement. The primary objective of this investigation was to design and advance an algorithm for selection procedure of the parameters influence on prediction of shear resistance of reinforced concrete beams by FRP. Six input parameters were used which represent geometric and mechanical properties of the bars as well as shear features. These parameters are: web width, tensile reinforcement depth, ratio of shear and depth, concrete compressive strength, ratio of FRP reinforcement, FRP modulus of elasticity and beam shear resistance. The searching algorithm is based on combination of artificial neural network and fuzzy logic principle or adaptive neuro fuzzy inference system (ANFIS). Based on the obtained results ratio of shear and depth has the strongest influence on the prediction of shear resistance of reinforced concrete beams by FRP. Moreover, combination of tensile reinforcement depth and ratio of shear and depth is the most influential combination of two parameters on the prediction of shear resistance of reinforced concrete beams by FRP. Finally, combination of tensile reinforcement depth, ratio of shear and depth and FRP modulus of elasticity is the most influential combination of three parameters on the prediction of shear resistance of reinforced concrete beams by FRP.}
}
@article{LEE1993255,
title = {Interval computation as deduction in chip},
journal = {The Journal of Logic Programming},
volume = {16},
number = {3},
pages = {255-276},
year = {1993},
issn = {0743-1066},
doi = {https://doi.org/10.1016/0743-1066(93)90045-I},
url = {https://www.sciencedirect.com/science/article/pii/074310669390045I},
author = {J.H.M. Lee and M.H. {Van Emden}},
abstract = {Logic programming realizes the ideal of “computation is deduction,” but not when floating-point numbers are involved. In that respect logic programming languages are as careless as conventional computation: they ignore the fact that floating-point operations are only approximate and that it is not easy to tell how good the approximation is. It is our aim to extend the benefits of logic programming to computation involving floating-point arithmetic. Our starting points are the ideas of Cleary and the CHIP programming language. Cleary proposed a relational form of interval arithmetic that was incorporated in BNR Prolog in such a way that variables already bound can be bound again. In this way the usual logical interpretation of computation no longer holds. In this paper we develop a technique for narrowing intervals that we relate both to Cleary's work and to the constraint-satisfaction techniques of artificial intelligence. We then modify CHIP by allowing domains to be intervals of real numbers. To reduce arithmetic primitives with interval domains, we use our interval narrowing technique as an implementation of the looking-ahead inference rule. We show that the result is a system where answers are logical consequences of a declarative logic program, even when floating-point computations have been used. We believe ours is the first system with this property.}
}
@article{SENAPATI202449,
title = {Oxymoron: An Automatic Detection from the Corpus},
journal = {Procedia Computer Science},
volume = {244},
pages = {49-56},
year = {2024},
note = {6th International Conference on AI in Computational Linguistics},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.177},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924029788},
author = {Apurbalal Senapati},
keywords = {Oxymoron, Antonymy, Corpus, Computational linguistic, Natural Language Processing, Bengali language},
abstract = {An oxymoron is a linguistic phenomenon in which a pair of opposite or antonymous words are combined to convey a new meaning. Sometimes, it is used to express figurative, irony, or rhetoric within the text. This issue has received relatively less attention in the realms of linguistics and computational disciplines. Oxymorons play a significant role in various language-processing applications. This study represents a pioneering effort in the exploration of oxymorons in the Bengali language. A corpus-based study of oxymoron is a fundamental issue that has not been explored so far. A system has been proposed for the automated recognition of oxymorons from a given corpus. Frequency analysis, semantic similarity, and an antonym dictionary have been employed to discern oxymorons within the corpus. The system achieved promising results when tested on a Bengali corpus, and found 308 distinct oxymorons. A corpus-based descriptive statistics is measured in two different corpora. The most common oxymorons are ranked based on their frequency. Their notable presence underscores the importance of the Bengali language. This study aimed to explore fundamental questions concerning oxymorons, such as the automated detection of oxymorons within a corpus, descriptive statistics regarding oxymorons across languages, and the process of their construction and creation. Additionally, efforts were made to extract oxymorons from large language models using zero-shot prompts, but the results were not as promising compared to our proposed system.}
}
@article{SHEARER2021,
title = {Foodborne Illness Outbreak Investigation for One Health Postsecondary Education},
journal = {Journal of Microbiology & Biology Education},
volume = {22},
number = {2},
year = {2021},
issn = {1935-7877},
doi = {https://doi.org/10.1128/jmbe.00129-21},
url = {https://www.sciencedirect.com/science/article/pii/S193578772100143X},
author = {Adrienne E. H. Shearer and Kalmia E. Kniel},
keywords = {food safety, investigation, One Health, education, microbiology, public health, escape room, problem-based learning, epidemiology, environment},
abstract = {One Health concepts were incorporated in a foodborne disease outbreak investigation with game features of data presented as visual and manipulative clues. Postsecondary pre-veterinary medicine and animal biosciences students and food science students (n = 319) enrolled in an introductory animal and food sciences course over a 3-year period received a brief introduction to foodborne illness, an outbreak scenario, and investigative tasks to complete individually or in groups.
ABSTRACT
One Health concepts were incorporated in a foodborne disease outbreak investigation with game features of data presented as visual and manipulative clues. Postsecondary pre-veterinary medicine and animal biosciences students and food science students (n = 319) enrolled in an introductory animal and food sciences course over a 3-year period received a brief introduction to foodborne illness, an outbreak scenario, and investigative tasks to complete individually or in groups. Tasks addressed epidemiology, laboratory, environment, traceback, recall, and prevention concepts. Gamification of the exercise involved generation of a numerical code to unlock a combination lock as an indication of successful organization, compilation, and interpretation of data. Students presented investigation findings and responses to critical thought questions on their roles. Student surveys on engagement and self-perceived change in conceptual understanding indicated that nearly all expressed increased understanding of outbreak investigations, safe food production, and environmental water as a transmission vehicle. Volunteered learned concepts indicated enhanced appreciation for the complexity of food safety and interdisciplinary connections. Students enjoyed the exercise (92%) and cited the clues and group interaction among the most enjoyable features. Objective assessment of student conceptual learning with the subset of students who conducted the investigation individually (n = 58) demonstrated significant increase in correct test responses (49% pretest; 76% posttest) after completion of the investigation for all questions combined and across all learning objectives. These data demonstrate the value of a foodborne disease investigation with escape room gamification features for engaging students in One Health concepts and exercising problem-solving, critical thinking, and skills for independent and collaborative work.}
}
@article{ALDAYA2024116708,
title = {Tachyons in “momentum-space” representation},
journal = {Nuclear Physics B},
volume = {1008},
pages = {116708},
year = {2024},
issn = {0550-3213},
doi = {https://doi.org/10.1016/j.nuclphysb.2024.116708},
url = {https://www.sciencedirect.com/science/article/pii/S0550321324002748},
author = {V. Aldaya and J. Guerrero and F.F. López-Ruiz},
abstract = {Obtaining the momentum space associated with tachyonic “particles” from the Poincaré group manifold proves to be rather intricate, departing very much from the ordinary dual to Minkowski space directly parametrized by space-time translations of the Poincaré group. In fact, although described by the constants of motion (Noether invariants) associated with space-time translations, they depend non-trivially on the parameters of the rotation subgroup. However, once the momentum space is parametrized by the Noether invariants, it behaves as that of ordinary particles. On the other hand, the evolution parameter is no longer the one associated with time translation, whose Noether invariant, Po, is now a basic one. Evolution takes place in a spatial direction. These facts not only make difficult the computation of the corresponding representation, but also force us to a sound revision of several traditional ingredients related to Cauchy hypersurface, scalar product and, of course, causality. After that, the theory becomes consistent and could shed new light on some special physical situations like inflation or traveling inside a black hole.}
}
@article{SAQIB2024105516,
title = {Novel Recurrent neural networks for efficient heat transfer analysis in radiative moving porous triangular fin with heat generation},
journal = {Case Studies in Thermal Engineering},
volume = {64},
pages = {105516},
year = {2024},
issn = {2214-157X},
doi = {https://doi.org/10.1016/j.csite.2024.105516},
url = {https://www.sciencedirect.com/science/article/pii/S2214157X24015478},
author = {Sana Ullah Saqib and Umar Farooq and Nahid Fatima and Yin-Tzer Shih and Ahmed Mir and Lioua Kolsi},
keywords = {Permeable fin in a triangle form, Convection radiation fin effectiveness, Recurrent neural networks (RNNs), Lobatto III-A technique, AI-Based intelligent computing},
abstract = {This paper investigates the use of Artificial Intelligence (AI), notably Recurrent Neural Networks (RNNs), to analyze heat transfer in moving radiative porous triangular systems with heat generation (HTMPTHG). AI-based RNN models are employed to simulate and forecast the complex heat transfer behavior in these environments, offering a more precise and efficient analysis as compared to traditional numerical methods. The findings of the study highlights the intricate interactions among thermal radiation, porous media, and internal heat generation which plays an integral role in a number of industrial and engineering applications. Recurrent neural network (RNN) is validated to examine the temperature distribution efficiency in a new configuration of triangular, porous, moving fins. Various dimensionless parameters are analyzed for their impact on the effectiveness of portable, transparent, triangular fins. These parameters include permeability, radiation-conduction, Peclet number, thermo-geometric factors, convection-conduction, and surface temperature. The Lobatto III-A numerical technique for HTMPTHG is simulated computationally to provide the synthetic datasets. Then, the RNN supervised computational technique is applied to the generated datasets and the RNN outputs show negligible errors and closely align with numerical observations for all model variant. The effectiveness of Recurrent Neural Networks (RNNs) is rigorously proved through extensive experiments, demonstrating iterative convergence curves for mean squared error, control metrics of optimization and error distribution via histograms.The mean absolute percent error (MAPE), mean absolute error (MAE), and Nash-Sutcliffe efficiency (NSE) are all nearly zero, while the coefficient of determination (R2) is close to 1.Furthermore, there is strong evidence of the prediction accuracy and dependability of the RNN in the regression results for the HTMPTHG model.}
}
@article{NISSEL2024105856,
title = {Why wearing a yellow hat is impossible: Chinese and U.S. children's possibility judgments},
journal = {Cognition},
volume = {251},
pages = {105856},
year = {2024},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2024.105856},
url = {https://www.sciencedirect.com/science/article/pii/S0010027724001422},
author = {Jenny Nissel and Jiaying Xu and Lihanjing Wu and Zachary Bricken and Jennifer M. Clegg and Hui Li and Jacqueline D. Woolley},
keywords = {Cognitive development, Social development, Possibility, Intuitive theories, Cross-cultural, LIWC},
abstract = {When thinking about possibility, one can consider both epistemic and deontic principles (i.e., physical possibility and permissibility). Cultural influences may lead individuals to weigh epistemic and deontic obligations differently; developing possibility conceptions are therefore positioned to be affected by cultural surroundings. Across two studies, 251 U.S. and Chinese 4-, 6-, and 8-year-olds sampled from major metropolitan areas in Texas and the Hubei, Sichuan, Gansu, and Guangdong Provinces judged the possibility of impossible, improbable, and ordinary events. Across cultures and ages, children judged ordinary events as possible and impossible events as impossible; cultural differences emerged in developing conceptions of improbable events. Whereas U.S. children became more likely to judge these events possible with age, Chinese children's judgments remained consistent with age: Chinese 4- to 8-year-olds judged these events to be possible ∼25% of the time. In Study 2, to test whether this difference was attributable to differential prioritization of epistemic versus deontic constraints, children also judged whether each event was an epistemic violation (i.e., required magic to happen) and a deontic violation (i.e., would result in someone getting in trouble). With age, epistemic judgments were increasingly predictive of possibility judgments for improbable events for U.S. children, and decreasingly so for Chinese children. Contrary to our predictions, deontic judgments were not predictive. We propose that cultural valuation of norms might shape children's developing intuitions about possibility. We discuss our findings in light of three accounts of possibility conceptions, suggesting ways to integrate cultural context into each.}
}
@article{ISLAM2022100280,
title = {Industry 4.0: Skill set for employability},
journal = {Social Sciences & Humanities Open},
volume = {6},
number = {1},
pages = {100280},
year = {2022},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2022.100280},
url = {https://www.sciencedirect.com/science/article/pii/S2590291122000341},
author = {Md. Aminul Islam},
keywords = {Industry 4.0, Skills, Competencies, Graduates, A lower middle-income country, Bangladesh},
abstract = {This paper aims at finding whether students are ready to perform in the modern competitive business job arena. Most importantly, if they have the required skills and competencies to catch the opportunity offered by companies at the fourth industrial revolution where we notice the trend of automation and data exchange and IoT, cloud computing and cognitive computing have taken the lead. Our target participants in the survey include students from public and private universities in Bangladesh who will perform in the job market and who are already in the market. This is how we can bridge the gap between employers' expectations and students' perceptions of skills and competencies they acquire before entering the job market. After surveying and analyzing data collected from 361 undergraduate and graduate-level students, we found that both business and technology impact employment. Students are aware of the changing job market scenario, and they are trying to have those skills which will make them competent compared to the early years, but they are not prepared enough to accept the challenges faced in industry 4.0. This paper will be helpful for both the academicians to be aware of the future trend of the market so that they can prepare students to fight the challenges and do future research on them. At the same time, employers can get some ideas how students are thinking right now and how much training and development opportunity they should arrange for the newly recruited graduates who have lack expertise but if they are trained up, can be a source of strength for the companies.}
}
@article{SINGH2024101269,
title = {An empirical approach to understand the role of emotions in code comprehension},
journal = {Journal of Computer Languages},
volume = {79},
pages = {101269},
year = {2024},
issn = {2590-1184},
doi = {https://doi.org/10.1016/j.cola.2024.101269},
url = {https://www.sciencedirect.com/science/article/pii/S2590118424000121},
author = {Divjot Singh and Ashutosh Mishra and Ashutosh Aggarwal},
keywords = {Code comprehension, Systematic literature review, Emotions, Cognitive skills},
abstract = {Programming and cognitive skills are two pivotal abilities of programmers to maintain software products. First, this study included a systematic literature review on code comprehension, emotions, cognitive psychology, and belief-desire-intention domains to analyse various code comprehension monitoring techniques, performance metrics, and computational methodologies. Second, a case study is conducted to examine the influence of various emotional stages on programmers’ programming and cognitive skills while comprehending the software code. The categorization of the participants is done empirically based on their expertism level, and the same results are verified using various machine learning models and performance metrics.}
}
@article{RAHARINIRINA2021100332,
title = {Inferring gene regulatory networks from single-cell RNA-seq temporal snapshot data requires higher-order moments},
journal = {Patterns},
volume = {2},
number = {9},
pages = {100332},
year = {2021},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2021.100332},
url = {https://www.sciencedirect.com/science/article/pii/S266638992100180X},
author = {N. Alexia Raharinirina and Felix Peppert and Max {von Kleist} and Christof Schütte and Vikram Sunkara},
keywords = {single cell, RNA sequencing, time-course snapshots, Markov chains, chemical master equation, moment equations},
abstract = {Summary
Single-cell RNA sequencing (scRNA-seq) has become ubiquitous in biology. Recently, there has been a push for using scRNA-seq snapshot data to infer the underlying gene regulatory networks (GRNs) steering cellular function. To date, this aspiration remains unrealized due to technical and computational challenges. In this work we focus on the latter, which is under-represented in the literature. We took a systemic approach by subdividing the GRN inference into three fundamental components: data pre-processing, feature extraction, and inference. We observed that the regulatory signature is captured in the statistical moments of scRNA-seq data and requires computationally intensive minimization solvers to extract it. Furthermore, current data pre-processing might not conserve these statistical moments. Although our moment-based approach is a didactic tool for understanding the different compartments of GRN inference, this line of thinking—finding computationally feasible multi-dimensional statistics of data—is imperative for designing GRN inference methods.}
}
@article{NA2023105139,
title = {Towards a neurocomputational account of social controllability: From models to mental health},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {148},
pages = {105139},
year = {2023},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2023.105139},
url = {https://www.sciencedirect.com/science/article/pii/S0149763423001082},
author = {Soojung Na and Shawn A. Rhoads and Alessandra N.C. Yu and Vincenzo G. Fiore and Xiaosi Gu},
keywords = {Social controllability, Computational psychiatry, Reinforcement learning, Model-based learning, Model-free learning, Cognitive map},
abstract = {Controllability, or the influence one has over their surroundings, is crucial for decision-making and mental health. Traditionally, controllability is operationalized in sensorimotor terms as one’s ability to exercise their actions to achieve an intended outcome (also termed “agency”). However, recent social neuroscience research suggests that humans also assess if and how they can exert influence over other people (i.e., their actions, outcomes, beliefs) to achieve desired outcomes ("social controllability”). In this review, we will synthesize empirical findings and neurocomputational frameworks related to social controllability. We first introduce the concepts of contextual and perceived controllability and their respective relevance for decision-making. Then, we outline neurocomputational frameworks that can be used to model social controllability, with a focus on behavioral economic paradigms and reinforcement learning approaches. Finally, we discuss the implications of social controllability for computational psychiatry research, using delusion and obsession-compulsion as examples. Taken together, we propose that social controllability could be a key area of investigation in future social neuroscience and computational psychiatry research.}
}
@article{BROWN201511,
title = {On unifiers, diversifiers, and the nature of pattern recognition},
journal = {Pattern Recognition Letters},
volume = {64},
pages = {11-20},
year = {2015},
note = {Philosophical Aspects of Pattern Recognition},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2015.04.014},
url = {https://www.sciencedirect.com/science/article/pii/S0167865515001312},
author = {Gavin Brown},
keywords = {Nature of pattern recognition, Unifying, Diversifying, Dyson},
abstract = {We study a dichotomy of scientific styles, unifying and diversifying, as proposed by Freeman J. Dyson. We discuss the extent to which the dichotomy transfers from the natural sciences (where Dyson proposed it) to the field of Pattern Recognition. To address this we must firstly ask what it means to be a “unifier” or “diversifier” in a field, and what are the relative merits of each style of thinking. Secondly, given that Dyson applied this to the sciences, does it also apply in a field known to be a blend of science and engineering? Parallels are drawn to Platonic/Aristotelian views, and to Cartesian/Baconian science, and questions are asked on what drives the Kuhnian paradigm shifts of our field. This article is intended not to marginalise individuals into categories (unifier/diversifier) but instead to demonstrate the utility of philosophical reflection on our field, showing the depth and complexities a seemingly simple idea can unearth.}
}
@article{DEVINK20222744,
title = {Cooperativity as quantification and optimization paradigm for nuclear receptor modulators††Electronic supplementary information (ESI) available: Experimental details, supporting figures and tables. See DOI: 10.1039/d1sc06426f},
journal = {Chemical Science},
volume = {13},
number = {9},
pages = {2744-2752},
year = {2022},
issn = {2041-6520},
doi = {https://doi.org/10.1039/d1sc06426f},
url = {https://www.sciencedirect.com/science/article/pii/S2041652023017297},
author = {Pim J. {de Vink} and Auke A. Koops and Giulia D'Arrigo and Gabriele Cruciani and Francesca Spyrakis and Luc Brunsveld},
abstract = {ABSTRACT
Nuclear Receptors (NRs) are highly relevant drug targets, for which small molecule modulation goes beyond a simple ligand/receptor interaction. NR–ligands modulate Protein–Protein Interactions (PPIs) with coregulator proteins. Here we bring forward a cooperativity mechanism for small molecule modulation of NR PPIs, using the Peroxisome Proliferator Activated Receptor γ (PPARγ), which describes NR–ligands as allosteric molecular glues. The cooperativity framework uses a thermodynamic model based on three-body binding events, to dissect and quantify reciprocal effects of NR–coregulator binding (KID) and NR–ligand binding (KIID), jointly recapitulated in the cooperativity factor (α) for each specific ternary ligand·NR·coregulator complex formation. These fundamental thermodynamic parameters allow for a conceptually new way of thinking about structure–activity-relationships for NR–ligands and can steer NR modulator discovery and optimization via a completely novel approach.}
}
@article{NEVES2009834,
title = {Structuring an MCDA model using SSM: A case study in energy efficiency},
journal = {European Journal of Operational Research},
volume = {199},
number = {3},
pages = {834-845},
year = {2009},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2009.01.053},
url = {https://www.sciencedirect.com/science/article/pii/S0377221709002033},
author = {L.P. Neves and L.C. Dias and C.H. Antunes and A.G. Martins},
keywords = {Problem structuring methods, Multiple criteria analysis, SSM, Value Focused Thinking, Energy efficiency},
abstract = {This work presents the use of a problem structuring method, Soft Systems Methodology (SSM), to structure a Multi-Criteria Decision Analysis (MCDA) model, aimed at appraising energy efficiency initiatives. SSM was useful to help defining clearly the decision problem context and the main actors involved, as well as to unveil the relevant objectives for each stakeholder. Keeney’s Value Focused Thinking approach was then used to refine and structure the list of objectives according to the perspective of the main evaluators identified. In addition to describing this particular case study, this paper aims at providing some general guidelines on how SSM may facilitate the emergence of objectives for MCDA models.}
}
@incollection{KRAAK2009468,
title = {Geovisualization},
editor = {Rob Kitchin and Nigel Thrift},
booktitle = {International Encyclopedia of Human Geography},
publisher = {Elsevier},
address = {Oxford},
pages = {468-480},
year = {2009},
isbn = {978-0-08-044910-4},
doi = {https://doi.org/10.1016/B978-008044910-4.00033-X},
url = {https://www.sciencedirect.com/science/article/pii/B978008044910400033X},
author = {M.-J. Kraak},
keywords = {Alternative visualization, Cartography, Cognition, Coordinated-multiple-views, Geocomputation, Geoservices, Geovisualization, Information visualization, Interfaces, Maps, Representation, Spatiotemporal data, Usability, Visual exploration, Visual representation, Visual thinking},
abstract = {Recent developments in information and communication technology (ICT) have introduced many new opportunities, and have influenced many scientific disciplines in application of their methods and techniques. From a mapping perspective, this includes cartography and related disciplines like scientific visualization, image analysis and remote sensing, information visualization, exploratory data analysis, visual analytics, and GI Science. Interactivity and dynamics are prominent keywords and allow one not only to apply maps and diagrams to present-known facts but also to analyze and explore unknown data. The environment in which the maps and diagrams are used has also changed and often includes coordinated multiple views display via the Internet. This allows for simultaneous alternative views of the data and stimulates visual thinking, resulting in geovisualization.}
}
@article{ROBERTSON2009136,
title = {Impact of CAD tools on creative problem solving in engineering design},
journal = {Computer-Aided Design},
volume = {41},
number = {3},
pages = {136-146},
year = {2009},
note = {Computer Support for Conceptual Design},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2008.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S0010448508001334},
author = {B.F. Robertson and D.F. Radcliffe},
keywords = {CAD, Creativity, Conceptual design},
abstract = {This paper presents the results of a survey of CAD users that examined the ways in which their computational environment may influence their ability to design creatively. This extensive online survey builds upon the findings of an earlier observational case study of the use of computer tools by a small engineering team. The case study was conducted during the conceptual and detailed stages of the design of a first-to-world product. Four mechanisms by which CAD tools may influence the creative problem solving process were investigated: enhanced visualisation and communication, circumscribed thinking, premature design fixation and bounded ideation. The prevalence of these mechanisms was examined via a series of questions that probed the user’s mode of working, attitudes, and responses to hypothetical situations. The survey showed good support for the first three mechanisms and moderate support for the fourth. The results have important implications for both the users and designers of CAD tools.}
}
@incollection{MARTIGNON2001382,
title = {Algorithms},
editor = {Neil J. Smelser and Paul B. Baltes},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences},
publisher = {Pergamon},
address = {Oxford},
pages = {382-385},
year = {2001},
isbn = {978-0-08-043076-8},
doi = {https://doi.org/10.1016/B0-08-043076-7/00549-0},
url = {https://www.sciencedirect.com/science/article/pii/B0080430767005490},
author = {L. Martignon},
abstract = {The concept of algorithm is central to the modern view of a thinking machine, be it the human mind or the modern computer. An algorithm is a well-defined mathematical recipe for the solution of a well-defined task. It is presented as a finite set of steps or instructions that can be applied to unlimited sets of possibilities. There is a clear-cut rule for the operation to be performed at each step, as well as a clear-cut specification of the conditions under which to terminate the process. An algorithm may contain loops, that is, there may be steps that return to previous steps. Algorithms can be sequential or parallel. An algorithm that produces a ‘yes’ or ‘no’ answer is, decision algorithm. An algorithm that constructs or determines a specific solution to a given problem is a computation algorithm.}
}
@article{NASSIRI201329,
title = {Computational modelling of long bone fractures fixed with locking plates – How can the risk of implant failure be reduced?},
journal = {Journal of Orthopaedics},
volume = {10},
number = {1},
pages = {29-37},
year = {2013},
issn = {0972-978X},
doi = {https://doi.org/10.1016/j.jor.2013.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S0972978X13000020},
author = {M. Nassiri and B. MacDonald and J.M. O'Byrne},
keywords = {Modeling, Fracture, Locking, Plate, Failure},
abstract = {Background and purpose
The Locking Compression Plate (LCP) is part of a new plate generation requiring an adapted surgical technique and new thinking about commonly used concepts of internal fixation using plates. Knowledge of the fixation stability provided by these new plates is very limited and clarification is still necessary to determine how the mechanical stability and the risk of implant failure can best be controlled.
Methods
Upon validation, a finite element model of an LCP attached to a cylinder was developed to simulate and analyse the biomechanics of a transverse long bone fracture fixed with a locking plate. Of special interest were the factors influencing the mechanical conditions at the fracture site, the control of interfragmentary movement and implant failure.
Results
Several factors were shown to influence stability in compression. Increasing translation and/or fracture angle post fixation reduced construct stability. Axial stiffness was also influenced by the working length and plate-bone distance. The fracture gap had no effect on the construct stability when no bone contact occurred during loading. Stress analysis of the LCP demonstrated that the maximum Von Mises stresses were found in the innermost screws at the screw-head junction.
Interpretation
For the clinical use of the LCP as a locked internal fixator in fractures with an interfragmentary gap of 1 mm, at least two to four plate holes near the fracture gap should be omitted to allow fracture motion and bone contact to occur. This will also achieve a larger area of stress distribution on the plate and reduce the likelihood of fatigue failure due to cyclic loading.}
}
@article{LU2024103920,
title = {The integrated multi-performance fast optimization strategy for battery thermal management system},
journal = {Case Studies in Thermal Engineering},
volume = {54},
pages = {103920},
year = {2024},
issn = {2214-157X},
doi = {https://doi.org/10.1016/j.csite.2023.103920},
url = {https://www.sciencedirect.com/science/article/pii/S2214157X23012261},
author = {Hao Lu and Xiaole Tang and Hongchang Li and Wenjun Zhao and Xiqiang Chang and Weifang Lin},
keywords = {Short-cut computation, Computational fluid dynamics, Weighted average, Optimization algorithm},
abstract = {Increased battery energy density is required to boost electric vehicle endurance; however, this also raises the possibility of thermal runaway and power battery explosion. Improving the cooling system performance requires optimization and enhancement of classical systems. Traditional design approaches struggle to simultaneously enhance multiple aspects of performance, while an optimization based on Computational Fluid Dynamics (CFD) methods is often inefficient. Therefore, by integrating a flow resistance network model (FRNM) with a weighted average optimization algorithm (INFO), an efficient optimization for the comprehensive performance of the system can be achieved. Five optimized systems under different airflow rates were obtained through optimization. A comparison with two existing systems validated the effectiveness of the optimized system. The results demonstrate that, compared to the two reference systems, the optimized system decreases the maximum temperature difference by 65.51 % and 39.07 %, respectively. Furthermore, the improvement in temperature uniformity is more significant, increasing by 63.76 % and 34.40 %, respectively.}
}
@article{PIVIK2012548,
title = {Eating breakfast enhances the efficiency of neural networks engaged during mental arithmetic in school-aged children},
journal = {Physiology & Behavior},
volume = {106},
number = {4},
pages = {548-555},
year = {2012},
issn = {0031-9384},
doi = {https://doi.org/10.1016/j.physbeh.2012.03.034},
url = {https://www.sciencedirect.com/science/article/pii/S0031938412001394},
author = {R.T. Pivik and Kevin B. Tennal and Stephen D. Chapman and Yuyuan Gu},
keywords = {Morning nutrition, Mental arithmetic, Preadolescents, Time–frequency analysis},
abstract = {To determine the influence of a morning meal on complex mental functions in children (8–11y), time–frequency analyses were applied to electroencephalographic (EEG) activity recorded while children solved simple addition problems after an overnight fast and again after having either eaten or skipped breakfast. Power of low frequency EEG activity [2Hertz (Hz) bands in the 2–12Hz range] was determined from recordings over frontal and parietal brain regions associated with mathematical thinking during mental calculation of correctly answered problems. Analyses were adjusted for background variables known to influence or reflect the development of mathematical skills, i.e., age and measures of math competence and math fluency. Relative to fed children, those who continued to fast showed greater power increases in upper theta (6–8Hz) and both alpha bands (8–10Hz; 10–12Hz) across sites. Increased theta suggests greater demands on working memory. Increased alpha may facilitate task-essential activity by suppressing non-task-essential activity. Fasting children also had greater delta (2–4Hz) and greater lower-theta (4–6Hz) power in left frontal recordings—indicating a region-specific emphasis on both working memory for mental calculation (theta) and activation of processes that suppress interfering activity (delta). Fed children also showed a significant increase in correct responses while children who continued to fast did not. Taken together the findings suggest that neural network activity involved in processing numerical information is functionally enhanced and performance is improved in children who have eaten breakfast, whereas greater mental effort is required for this mathematical thinking in children who skip breakfast.}
}
@article{BIRJALI201765,
title = {Machine Learning and Semantic Sentiment Analysis based Algorithms for Suicide Sentiment Prediction in Social Networks},
journal = {Procedia Computer Science},
volume = {113},
pages = {65-72},
year = {2017},
note = {The 8th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN 2017) / The 7th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH-2017) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.08.290},
url = {https://www.sciencedirect.com/science/article/pii/S187705091731699X},
author = {Marouane Birjali and Abderrahim Beni-Hssane and Mohammed Erritali},
keywords = {Sentiment Analysis, Machine Learning, Suicide, Social Networks, Tweets, Semantic Sentiment Analysis},
abstract = {Sentiment analysis is one of the new challenges appeared in automatic language processing with the advent of social networks. Taking advantage of the amount of information is now available, research and industry have sought ways to automatically analyze sentiments and user opinions expressed in social networks. In this paper, we place ourselves in a difficult context, on the sentiments that could thinking of suicide. In particular, we propose to address the lack of terminological resources related to suicide by a method of constructing a vocabulary associated with suicide. We then propose, for a better analysis, to investigate Weka as a tool of data mining based on machine learning algorithms that can extract useful information from Twitter data collected by Twitter4J. Therefore, an algorithm of computing semantic analysis between tweets in training set and tweets in data set based on WordNet is proposed. Experimental results demonstrate that our method based on machine learning algorithms and semantic sentiment analysis can extract predictions of suicidal ideation using Twitter Data. In addition, this work verify the effectiveness of performance in term of accuracy and precision on semantic sentiment analysis that could thinking of suicide.}
}
@article{READ200577,
title = {Early computational processing in binocular vision and depth perception},
journal = {Progress in Biophysics and Molecular Biology},
volume = {87},
number = {1},
pages = {77-108},
year = {2005},
note = {Biophysics of Excitable Tissues},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2004.06.005},
url = {https://www.sciencedirect.com/science/article/pii/S007961070400063X},
author = {Jenny Read},
abstract = {Stereoscopic depth perception is a fascinating ability in its own right and also a useful model of perception. In recent years, considerable progress has been made in understanding the early cortical circuitry underlying this ability. Inputs from left and right eyes are first combined in primary visual cortex (V1), where many cells are tuned for binocular disparity. Although the observation of disparity tuning in V1, combined with psychophysical evidence that stereopsis must occur early in visual processing, led to initial suggestions that V1 was the neural correlate of stereoscopic depth perception, more recent work indicates that this must occur in higher visual areas. The firing of cells in V1 appears to depend relatively simply on the visual stimuli within local receptive fields in each retina, whereas the perception of depth reflects global properties of the stimulus. However, V1 neurons appear to be specialized in a number of respects to encode ecologically relevant binocular disparities. This suggests that they carry out essential pre-processing underlying stereoscopic depth perception in higher areas. This article reviews recent progress in developing accurate models of the computations carried out by these neurons. We seem close to achieving a mathematical description of the initial stages of the brain's stereo algorithm. This is important in itself––for instance, it may enable improved stereopsis in computer vision––and paves the way for a full understanding of how depth perception arises.}
}