@article{ROOS2020112975,
title = {Online conferences – Towards a new (virtual) reality},
journal = {Computational and Theoretical Chemistry},
volume = {1189},
pages = {112975},
year = {2020},
issn = {2210-271X},
doi = {https://doi.org/10.1016/j.comptc.2020.112975},
url = {https://www.sciencedirect.com/science/article/pii/S2210271X20302759},
author = {Goedele Roos and Julianna Oláh and Rebecca Ingle and Rika Kobayashi and Milica Feldt},
keywords = {Virtual conference, Virtual Winter School on Computational Chemistry, Hybrid online/in-person conference},
abstract = {The recent article: Nature 579, 327–328 (2020), ending with the phrase: “You can’t just suddenly make a conference be online.”, has motivated us to write about the practicalities and philosophy of running online events, drawing on our extensive experience running an annual online computational chemistry conference. Our goals for this online conference series have always been: (1) Availability; (2) Community building and (3) Supporting young scientists. In this article, we highlight the motivations behind our initiative, how this has influenced the organisation of our online meeting, and discuss the benefits as well as the drawbacks of virtual meetings. Virtual conferences may not fully replace in-person meetings, but they are rapidly becoming an accepted alternative format. We discuss the hybrid online/in-person conference format as a future possibility that may offer an opportunity to reduce the environmental impact and accessibility barriers associate with in-person meetings without comprising networking and community-building opportunities.}
}
@article{MANLEY201427,
title = {A framework for simulating large-scale complex urban traffic dynamics through hybrid agent-based modelling},
journal = {Computers, Environment and Urban Systems},
volume = {44},
pages = {27-36},
year = {2014},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2013.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S0198971513001129},
author = {Ed Manley and Tao Cheng and Alan Penn and Andy Emmonds},
keywords = {Agent-based simulation, Urban complexity, Human cognition, Collective phenomena, Traffic flow, Hybrid simulation},
abstract = {Urban road traffic dynamics are the product of the behaviours and interactions of thousands, often millions of individuals. Traditionally, models of these phenomena have incorporated simplistic representations of individual behaviour, ensuring the maximisation of simulation scale under given computational constraints. Yet, by simplifying representations of behaviour, the overall predictive capability of the model inevitably reduces. In this work a hybrid agent-based modelling framework is introduced that aims to balance the demands of behavioural realism and computational capacity, integrating a descriptive representation of driver behaviour with a simplified, collective model of traffic flow. The hybridisation of these approaches within an agent-based modelling framework yields a representation of urban traffic flow that is driven by individual behaviour, yet, in reducing the computational intensity of simulated physical interaction, enables the scalable expansion to large numbers of agents. A real-world proof-of-concept case study is presented, demonstrating the application of this approach, and showing the gains in computational efficiency made in utilising this approach against traditional agent-based approaches. The paper concludes in addressing how this model might be extended, and exploring the role hybrid agent-based modelling approaches may hold in the simulation of other complex urban phenomena.}
}
@article{YIN2024133163,
title = {Mobileception-ResNet for transient stability prediction of novel power systems},
journal = {Energy},
volume = {309},
pages = {133163},
year = {2024},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2024.133163},
url = {https://www.sciencedirect.com/science/article/pii/S0360544224029384},
author = {Linfei Yin and Wei Ge},
keywords = {Transient stability, Deep learning, MobileNet-v2, Convolutional neural network, Inception-ResNet-v2},
abstract = {Power system transient stability prediction (TSP) is particularly important as power systems change and evolve, including the rapid growth of renewable energy, the proliferation of electric vehicles, and the construction of smart grids. Traditional time-domain simulation methods are time-consuming and cannot achieve online prediction. Direct methods are poorly adapted and cannot be applied to complex power systems. Existing machine learning algorithms only classify the transient stability without providing the degree of transient stability of the system. Therefore, a fast and accurate power system TSP method is needed to assist operators in implementing timely measures to improve the stability of the power system running. This study proposes a Mobileception-ResNet network, Mobileception-ResNet is formed by Inception-ResNet-v2, MobileNet-v2, and a fully connected layer. In this study, Mobileception-ResNet and nine comparison models are experimented on two node systems, i.e., the IEEE 10–39 and 69–300 systems. In the IEEE 10–39 system, the root mean square error, mean absolute error, and mean absolute percentage error of Mobileception-ResNet are 44.13 %, 36.74 %, and 39.96 % lower, and the coefficient of determination is 0.04 % higher, respectively, when compared to the comparative model with the best evaluation indicator; in the IEEE 69–300 system, the corresponding values are 2.6 %, 12.83 %, 12.55 %, and 0.01 %, respectively.}
}
@article{XU2021104922,
title = {Brain decoding in multiple languages: Can cross-language brain decoding work?},
journal = {Brain and Language},
volume = {215},
pages = {104922},
year = {2021},
issn = {0093-934X},
doi = {https://doi.org/10.1016/j.bandl.2021.104922},
url = {https://www.sciencedirect.com/science/article/pii/S0093934X2100016X},
author = {Min Xu and Duo Li and Ping Li},
keywords = {Cross-language brain decoding, Neural representation, Multivariate pattern analysis, Computational modeling, Multilingualism},
abstract = {The approach of cross-language brain decoding is to use models of brain decoding from one language to decode stimuli of another language. It has the potential to provide new insights into how our brain represents multiple languages. While it is possible to decode semantic information across different languages from neuroimaging data, the approach’s overall success remains to be tested and depends on a number of factors such as cross-language similarity, age of acquisition/proficiency levels, and depth of language processing. We expect to see continued progress in this domain, from a traditional focus on words and concrete concepts toward the use of naturalistic experimental tasks involving higher-level language processing (e.g., discourse processing). The approach can also be applied to understand how cross-modal, cross-cultural, and other nonlinguistic factors may influence neural representations of different languages. This article provides an overview of cross-language brain decoding with suggestions for future research directions.}
}
@article{LEACH2024,
title = {The engineering legacy of the FIFA World Cup Qatar 2022: Al Janoub stadium},
journal = {Proceedings of the Institution of Civil Engineers - Structures and Buildings},
year = {2024},
issn = {0965-0911},
doi = {https://doi.org/10.1680/jstbu.22.00127},
url = {https://www.sciencedirect.com/science/article/pii/S0965091124000155},
author = {Jon Leach and Craig Sparrow and Federico Iori and Hamad N. Al-Nuaimi and Mohammed Z. E. B. Elshafie and Nasser A. Al-Nuaimi},
keywords = {buildings, structures & design, thermal effects, wind loading & aerodynamics},
abstract = {Al Janoub was the first new-build stadium designed for the FIFA World Cup Qatar 2022. This paper describes the journey of the engineering design of the 40 000 seat stadium, from the concept and detailed design development stages led by AECOM and Zaha Hadid Architects, through to the design and build contract on site. An architectural jewel located in Al Wakrah, just south of the city of Doha, the stadium was a world-first, using state-of-the-art computational analysis and physical modelling to create a safe, cooled environment that satisfies FIFA's requirements for both player and spectator comfort in the extreme temperatures of the region. A sustainable post-tournament legacy was also a key factor of the design, allowing it to be reduced to a 20 000-capacity stadium for the local football club and community. The task of integrating the stadium's stringent performance requirements on this path-finder project, including extensive scientific research and development, was a challenge that was overcome through close collaboration between the design team and the Supreme Committee's subject matter experts. The project's success as a test-bed helped it to set the standard for other stadia as part of the overall FIFA World Cup Qatar 2022 programme.}
}
@article{HAO201630,
title = {Reflection enhances creativity: Beneficial effects of idea evaluation on idea generation},
journal = {Brain and Cognition},
volume = {103},
pages = {30-37},
year = {2016},
issn = {0278-2626},
doi = {https://doi.org/10.1016/j.bandc.2016.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S0278262616300057},
author = {Ning Hao and Yixuan Ku and Meigui Liu and Yi Hu and Mark Bodner and Roland H. Grabner and Andreas Fink},
keywords = {Idea evaluation, Idea generation, Creativity, Alpha, EEG},
abstract = {The present study aimed to explore the neural correlates underlying the effects of idea evaluation on idea generation in creative thinking. Participants were required to generate original uses of conventional objects (alternative uses task) during EEG recording. A reflection task (mentally evaluating the generated ideas) or a distraction task (object characteristics task) was inserted into the course of idea generation. Behavioral results revealed that participants generated ideas with higher originality after evaluating the generated ideas than after performing the distraction task. The EEG results revealed that idea evaluation was accompanied with upper alpha (10–13Hz) synchronization, most prominent at frontal cortical sites. Moreover, upper alpha activity in frontal cortices during idea generation was enhanced after idea evaluation. These findings indicate that idea evaluation may elicit a state of heightened internal attention or top-down activity that facilitates efficient retrieval and integration of internal memory representations.}
}
@article{KUGURAKOVA2015112,
title = {Anthropomorphic Artificial Social Agent with Simulated Emotions and its Implementation},
journal = {Procedia Computer Science},
volume = {71},
pages = {112-118},
year = {2015},
note = {6th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2015, 6-8 November Lyon, France},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.12.217},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915036789},
author = {Vlada Kugurakova and Maxim Talanov and Nadir Manakhov and Denis Ivanov},
keywords = {intelligent agents, visualization, emotional artificial intelligence, neuromodulators, visual speech synthesis, expressive and controllable speech synthesis},
abstract = {In this paper we describe an emotional human-machine interface as an anthropomorphic social agent able to exhibit simulated emotions and react to emotional stimuli. We propose a neurobiologically inspired agent implementation that is based on mechanics of chemical and physiological processes within human brain. Implementation of model features simulation of neuromodulators such as dopamine, serotonin, and noradrenaline. Demonstration of emotions is achieved via combining aforementioned neuromodulators in different proportions. The Lovheim cube of emotions is used for this purpose. Topic of “uncanny valley” phenomenon and its effect on human-machine interactions is also mentioned. In conclusion of this paper we have proposed realistic computation model allowing us to visualize agents mimics in sync with his speech, and have made a working prototype of aforementioned model.}
}
@article{ISOLAN2024111786,
title = {Monte Carlo analysis of dosimetric issues in space exploration},
journal = {Radiation Physics and Chemistry},
volume = {221},
pages = {111786},
year = {2024},
issn = {0969-806X},
doi = {https://doi.org/10.1016/j.radphyschem.2024.111786},
url = {https://www.sciencedirect.com/science/article/pii/S0969806X24002780},
author = {Lorenzo Isolan and Valentina Sumini and Marco Sumini},
keywords = {Space habitat, MCNP6, Unstructured mesh, Topology optimization, Radiation protection},
abstract = {The Radiation protection is of paramount importance in the planning of human exploration activities in space. The related risks must be considered with respect to two aspects: devising a proper shielding and providing answers to the requirement of an effective dosimetry evaluation in astronaut's activities. Both aspects have been considered using the Monte Carlo (MC) code MCNP 6.2 as the reference tool. As case study an application devised for the National Aeronautics and Space Administration (NASA) Artemis program has been chosen. The project aims to establish a sustainable human presence on the Moon, envisioning the realization of an outpost that will serve as a steppingstone for space exploration endeavors. A Class III shelter, in situ resource utilization (ISRU) built habitat for the Moon, has been designed through computational methods and topology optimization techniques, and analyzed in terms of radiation shielding performances and the strictly related structural behavior. The outpost must be able to withstand temperature variations, micrometeorite impacts, and the absence of a substantial atmosphere. Any solution studied to respect the constraints must devise robust and innovative materials and techniques to create habitats that have as goal the shielding from the Galactic Cosmic Rays (GCR) and from the solar flares to provide a safe and habitable environment at the time scales scheduled for the missions. Moreover, the outpost design must incorporate strategies for extracting and utilizing local resources. Overcoming such challenges will pave the way for the establishment of a sustainable human presence on the Moon and serve as a crucial leap for future space exploration missions.}
}
@article{POGGIO1981258,
title = {Marr's computational approach to vision},
journal = {Trends in Neurosciences},
volume = {4},
pages = {258-262},
year = {1981},
issn = {0166-2236},
doi = {https://doi.org/10.1016/0166-2236(81)90081-3},
url = {https://www.sciencedirect.com/science/article/pii/0166223681900813},
author = {T. Poggio},
abstract = {In the last 7 years a new computational approach has led to promising advances in our understanding of visual perception. The foundations of the approach, its overall framework and its first solid results are largely due to the work of a single man, David Marr at MIT. Now, after his death in Boston on 17 November, 1980, research in vision will never be the same.}
}
@incollection{DORST200723,
title = {2 - Spanning oriented subspaces},
editor = {Leo Dorst and Daniel Fontijne and Stephen Mann},
booktitle = {Geometric Algebra for Computer Science},
publisher = {Morgan Kaufmann},
address = {Burlington},
pages = {23-64},
year = {2007},
series = {The Morgan Kaufmann Series in Computer Graphics},
isbn = {978-0-12-369465-2},
doi = {https://doi.org/10.1016/B978-012369465-2/50005-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780123694652500050},
author = {Leo Dorst and Daniel Fontijne and Stephen Mann},
abstract = {Publisher Summary
This chapter shows that a vector space is much more than merely a space of vectors, and that it is straightforward and useful to extend it computationally. The crucial idea here is to make the subspaces of vector space explicit elements of computation. To build the algebra of subspaces, the familiar lines and planes are revisited through the origin. This chapter investigates their geometrical properties carefully and formalizes those by the aid of a new algebraic outer product, which algebraically builds subspaces from vectors. The structure it produces is considered for the Grassmann space of subspaces of a vector space Rn, and defines many terms to describe its features. Throughout this chapter, it considers a real n-dimensional vector space Rn, but has no need for a metric; additionally, it only treats its homogeneous subspaces (i.e., subspaces containing the origin). The chapter starts with an n-dimensional vector space. However, the definition of a vector space in linear algebra is more general than what is needed in this book, being defined over arbitrary fields of scalars. To develop thinking about subspaces, the homogeneous subspaces of a 3-D space are considered.}
}
@article{LI2022101701,
title = {A framework and method for Human-Robot cooperative safe control based on digital twin},
journal = {Advanced Engineering Informatics},
volume = {53},
pages = {101701},
year = {2022},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2022.101701},
url = {https://www.sciencedirect.com/science/article/pii/S1474034622001604},
author = {Hao Li and Wenfeng Ma and Haoqi Wang and Gen Liu and Xiaoyu Wen and Yuyan Zhang and Miying Yang and Guofu Luo and Guizhong Xie and Chunya Sun},
keywords = {Human-robot collaboration, Digital twin, Safety control, Machine vision, Convolutional neural network},
abstract = {Human-robot collaboration (HRC) combines the robot’s mechanical properties and predictability with human experience, logical thinking, and strain capabilities to alleviate production efficiency. However, ensuring the safety of the HRC process in-real time has become an urgent issue. Digital twin extends functions of virtual models in the design phase of the physical counterpart in the production phase through virtual-real interactive feedback, data fusion analysis, advanced computational features, etc. This paper proposes an HRC safety control framework and corresponding method based on the digital twin. In the design phase, virtual simulation and virtual reality technology are integrated to construct virtual twins of various HRC scenarios for testing and analyzing potential safety hazards. In the production phase, the safety distance between humans and robots of the HRC scene is monitored and calculated by an iterative algorithm according to machine vision and a convolutional neural network. Finally, the virtual twin is driven based on real-scene data, real-time online visual monitoring, and optimization of the HRC’s overall process. A case study using ABB-IRB1600 is presented to verify the feasibility of the proposed approach.}
}
@article{OFOSUAMPONG2024100127,
title = {Artificial intelligence research: A review on dominant themes, methods, frameworks and future research directions},
journal = {Telematics and Informatics Reports},
volume = {14},
pages = {100127},
year = {2024},
issn = {2772-5030},
doi = {https://doi.org/10.1016/j.teler.2024.100127},
url = {https://www.sciencedirect.com/science/article/pii/S2772503024000136},
author = {Kingsley Ofosu-Ampong},
keywords = {Artificial intelligence, Classification, Literature review, Technological issues, Research agenda},
abstract = {This article presents an analysis of artificial intelligence (AI) in information systems and innovation-related journals to determine the current issues and stock of knowledge in AI literature, research methodology, frameworks, level of analysis and conceptual approaches. By doing this, the article aims to identify research gaps that can guide future investigations. A total of 85 peer-reviewed articles from 2020 to 2023 were used in the analysis. The findings show that extant literature is skewed towards the prevalence of technological issues and highlights the relatively lower focus on other themes, such as contextual knowledge co-creation issues, conceptualisation, and application domains. While there have been increasing technological issues with artificial intelligence, the three identified areas of security concern are data security, model security and network security. Furthermore, the review found that contemporary AI, which continually drives the boundaries of computational capabilities to tackle increasingly intricate decision-making challenges, distinguishes itself from earlier iterations in two primary aspects that significantly affect organisational learning in dealing with AI's potential: autonomy and learnability. This study contributes to AI research by providing insights into current issues, research methodology, level of analysis and conceptual approaches, and AI framework to help identify research gaps for future investigations.}
}
@article{MAFTEI2022107032,
title = {Using fake news as means of cyber-bullying: The link with compulsive internet use and online moral disengagement},
journal = {Computers in Human Behavior},
volume = {127},
pages = {107032},
year = {2022},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2021.107032},
url = {https://www.sciencedirect.com/science/article/pii/S0747563221003551},
author = {Alexandra Maftei and Andrei-Corneliu Holman and Ioan-Alex Merlici},
keywords = {Fake news, Online moral disengagement, Cyberbullying, Compulsive internet use},
abstract = {Online moral disengagement and cyberbullying can enhance fake news spreading. We explored the links between these variables and compulsive Internet use in a sample of 509 teenagers and adults aged 11 to 67. We investigated the effect of compulsive Internet use on cyberbullying through fake news creation and/or distribution, both direct and via moral disengagement, and the related differences between adults and teenagers. The indirect effect of compulsive Internet use on cyberbullying through moral disengagement was significant in adolescents, but not in adults. As assumed, teenagers scored significantly higher than adults on all the primary variables. Contrary to our expectations, no significant gender differences emerged, regardless of participants' age, in terms of compulsive Internet use, moral disengagement, nor cyberbullying. The results emphasize the importance of relevant online education programs designed to engage both teenagers and adults in critical thinking that might help in the fake news detection process, especially during the COVID-19 pandemic.}
}
@article{MONTEIRO2023100076,
title = {Environmental assessment in concrete pole industries},
journal = {CEMENT},
volume = {13},
pages = {100076},
year = {2023},
issn = {2666-5492},
doi = {https://doi.org/10.1016/j.cement.2023.100076},
url = {https://www.sciencedirect.com/science/article/pii/S2666549223000221},
author = {Nathalie Barbosa Reis Monteiro and José Machado {Moita Neto} and Elaine Aparecida {da Silva}},
keywords = {Concrete poles, Life cycle, Environmental impact},
abstract = {Purpose
Companies that manufacture poles generate several negative environmental impacts, whose extent needs to be assessed to find ways to mitigate them.
Methods
In this research, Life Cycle Assessment (LCA) was used as a methodology to measure the potential environmental impacts throughout the poles' life cycle. Primary data (amount of cement, gravel, sand, steel rebars, energy, water) were collected from industries located in Teresina, Piauí, Brazil, and information from the Ecoinvent 3.7.1 database (transport, solid waste, liquid effluents, particulate matter) was used.
Results and discussion
The literature addresses pole production from a different perspective, making this study relevant to disseminate the life cycle thinking in concrete pole production. However, the literature points to a correlation trend for ecotoxicity and human toxicity indicators, as well as the results found in this research. Waste disposal stands out as an important source of impact for these industries, confirming the necessity of efficient management of these materials at the end of their lifespan and during the production process. The scenario analysis showed that is possible to reduce the potential impacts of these industries.
Conclusion
The reuse of waste within the industry itself is feasible (using a shredder for this purpose) and can contribute to decreasing the extraction of natural deposits in various production processes related to the poles' life cycle and reducing their accumulation in the environment. The use of inputs from closer suppliers is a strategy that contributes to mitigating the potential impact of gaseous emissions, reducing the impact that generates global warming and climate change. In addition, other papers show viable alternatives in different scenarios, based on complex laboratory studies. Nevertheless, his approach shows how impacts can be mitigated with the adoption of simple actions such as the reuse of effluents and residues from these industries. It is possible to redefine the production process through a scenario close to the ideal, bringing environmental sustainability to the sector.}
}
@article{POURFOULADI2025107722,
title = {PoliBrick plugin as a parametric tool for digital stereotomy modelling},
journal = {Computers & Structures},
volume = {311},
pages = {107722},
year = {2025},
issn = {0045-7949},
doi = {https://doi.org/10.1016/j.compstruc.2025.107722},
url = {https://www.sciencedirect.com/science/article/pii/S004579492500080X},
author = {Mohammad Pourfouladi and Natalia Pingaro and Marco Valente},
keywords = {PoliBrick Plugin, Software Development, Masonry Construction, Brick Pattern, Stereotomy, Single and Double Curvature Vaults},
abstract = {This paper presents the development of a new plugin that is both simple and user-friendly for the digital modelling of multiple brick patterns in 3D on any surface, from simple flat walls to complex single and double curvature geometries. The plugin, named PoliBrick, is specifically conceived to assist in modelling different types of brickwork shells with intricate patterns, such as masonry arches and vaults. It excels in streamlining parametric modelling across a broad spectrum of free-form curved surfaces, standing out from existing tools. Developed for Rhino software within the Grasshopper environment, PoliBrick features an intuitive interface and comprises only six essential components. Its parametric method makes it competitive with any procedure documented in the literature, as it can accurately replicate brick assemblies on all types of free-form shells. PoliBrick can reproduce, with immediate feedback, any brick arrangement, including patterns like basket weave, stretcher bond, herringbone bond, and many others. Such a functionality addresses a significant gap in current software tools, which cannot often handle curved geometries with complex brick layouts. Moreover, the new plugin can be integrated into a variety of software tools to enable pre-analysis capabilities for the structural evaluation of single and double curvature vaulted structures, using preferred methods like finite element or distinct element approaches. It also supports robotic fabrication processes by considering paths and construction order, enhancing its practical utility in modern construction techniques. PoliBrick is benchmarked on some case studies to demonstrate the validity of the developed procedure and the robustness of the proposed algorithm, which is expected to be effective in markedly reducing the computational effort in pre-structural analysis modelling phases and allows designers to take into account the non-negligible role of stereotomy in curved structures.}
}
@incollection{SEDIG2005239,
title = {17 A descriptive framework for designing interaction for visual abstractions},
editor = {Grant Malcolm},
series = {Studies in Multidisciplinarity},
publisher = {Elsevier},
volume = {2},
pages = {239-254},
year = {2005},
booktitle = {Multidisciplinary Approaches to Visual Representations and Interpretations},
issn = {1571-0831},
doi = {https://doi.org/10.1016/S1571-0831(04)80045-5},
url = {https://www.sciencedirect.com/science/article/pii/S1571083104800455},
author = {K. Sedig and J. Morey},
abstract = {This chapter propses a descriptive framework for categorisation and characterisation of the different forms of interaction with visual abstractions (VAs). Abstract visual representations play an important role in assisting human reasoning, thinking, and understanding processes. There are different forms of designing interaction with these representations. The goal of this chapter is to provide a descriptive framework to guide the designers and evaluators of cognitive tools to determine the appropriate forms of interaction that can facilitate the understanding of abstract concepts, patterns, structures and processes. The framework is described and substantiated using a number of VAs that represent and communicate mathematical ideas.}
}
@article{PESSOA2019158,
title = {Neural dynamics of emotion and cognition: From trajectories to underlying neural geometry},
journal = {Neural Networks},
volume = {120},
pages = {158-166},
year = {2019},
note = {special Issue in Honor of the 80th Birthday of Stephen Grossberg},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2019.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608019302242},
author = {Luiz Pessoa},
keywords = {Emotion, Cognition, Dynamics, Trajectories, Manifold},
abstract = {How can we study, characterize, and understand the neural underpinnings of cognitive-emotional behaviors as inherently dynamic processes? In the past 50 years, Stephen Grossberg has developed a research program that embraces the themes of dynamics, decentralized computation, emergence, selection and competition, and autonomy. The present paper discusses how these principles can be heeded by experimental scientists to advance the understanding of the brain basis of behavior. It is suggested that a profitable way forward is to focus on investigating the dynamic multivariate structure of brain data. Accordingly, central research problems involve characterizing “neural trajectories” and the associated geometry of the underlying “neural space.” Finally, it is argued that, at a time when the development of neurotechniques has reached a fever pitch, neuroscience needs to redirect its focus and invest comparable energy in the conceptual and theoretical dimensions of its research endeavor. Otherwise we run the risk of being able to measure “every atom” in the brain in a theoretical vacuum.}
}
@article{NAGHDY2025102445,
title = {Collaboration with GenAI in Engineering Research Design},
journal = {Data & Knowledge Engineering},
pages = {102445},
year = {2025},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2025.102445},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X25000400},
author = {Fazel Naghdy},
keywords = {literature review, hypothesis, research design, GenAI, research gaps},
abstract = {Over the past five years, the fast development and use of generative artificial intelligence (GenAI) and large language models (LLMs) has ushered in a new era of study, teaching, and learning in many domains. The role that GenAIs can play in engineering research is addressed. The related previous works report on the potential of GenAIs in the literature review process. However, such potential is not demonstrated by case studies and practical examples. The previous works also do not address how GenAIs can assist with all the steps traditionally taken to design research. This study examines the effectiveness of collaboration with GenAIs at various stages of research design. It explores whether collaboration with GenAIs can result in more focused and comprehensive outcomes. A generalised approach for collaboration with AI tools in research design is proposed. A case study to develop a research design on the concept of “shared machine-human driving” is deployed to show the validity of the articulated concepts. The case study demonstrates both the pros and cons of collaboration with GenAIs. The results generated at each stage are rigorously validated and thoroughly examined to ensure they remain free from inaccuracies or hallucinations and align with the original research objectives. When necessary, the results are manually adjusted and refined to uphold their integrity and accuracy. The findings produced by the various GenAI models utilized in this study highlight the key attributes of generative artificial intelligence, namely speed, efficiency, and scope. However, they also underscore the critical importance of researcher oversight, as unexamined inferences and interpretations can render the results irrelevant or meaningless.}
}
@article{SUCHANTKE2020439,
title = {Space sustainability in Martian orbits — First insights in a technical and regulatory analysis},
journal = {Journal of Space Safety Engineering},
volume = {7},
number = {3},
pages = {439-446},
year = {2020},
note = {Space Debris: The State of Art},
issn = {2468-8967},
doi = {https://doi.org/10.1016/j.jsse.2020.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S2468896720300677},
author = {Isabell Suchantke and Francesca Letizia and Vitali Braun and Holger Krag},
abstract = {Hazards from the outer space environment either natural (space weather and asteroids) or artificial (space debris and the growing number of satellites launched to orbit) pose a rising risk to space flight activities. The awareness for space sustainability and space safety has seen a continuous increase in recent years and does not stop at the Earth's sphere of influence. The first spacefaring nations start thinking about sustainability in cislunar space and the Martian environment. This work deals with the issue of space debris in Martian orbits in the light of planetary protection. A Mars Sustainability Framework has been developed. This includes a study on the orbital and regulatory environment of Mars, long-term propagation of orbits of artificial objects and the two natural moons, and the analysis of objects evolution and first approaches for collision probability computation. With this work, the issue of space debris beyond Earth orbit is analysed at an early stage.}
}
@article{DASILVA2024105785,
title = {Optimization of open web steel beams using the finite element method and genetic algorithms},
journal = {Structures},
volume = {60},
pages = {105785},
year = {2024},
issn = {2352-0124},
doi = {https://doi.org/10.1016/j.istruc.2023.105785},
url = {https://www.sciencedirect.com/science/article/pii/S2352012423018738},
author = {Amilton Rodrigues {da Silva} and Gabriela Pereira Lubke},
keywords = {Open-web beams, Optimization, Genetic algorithm, Finite element method},
abstract = {Studies on structural optimization have gained prominence recently, and the search to consume resources in a more conscious and effective way encourages the use of such techniques in all fields. In this respect, this study aims to use computational optimization techniques to determine the maximum load-bearing capacity of hollow-core steel beams for two groups of different shear lines, one generating beams with opening in the shape of hexagons and the other having the shape of ellipses. The second group includes beams with circular openings as a particular case. A three-node triangular finite element for the analysis of structures in plane stress is used for the structural analysis of the beams. The design variables define the shape and number of opening in the beam, and a computational formulation using a genetic algorithm is presented to find the cut line that maximizes the load capacity of the beam considering different ultimate and service limit states. Numerical and experimental models in the literature are used to validate the implementations presented in this article, and the results of optimized hollow core beams are presented, demonstrating the efficiency of the formulations used.}
}
@article{FAN2020248,
title = {From Brain Science to Artificial Intelligence},
journal = {Engineering},
volume = {6},
number = {3},
pages = {248-252},
year = {2020},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2019.11.012},
url = {https://www.sciencedirect.com/science/article/pii/S2095809920300035},
author = {Jingtao Fan and Lu Fang and Jiamin Wu and Yuchen Guo and Qionghai Dai},
keywords = {Artificial intelligence, Brain science},
abstract = {Reviewing the history of the development of artificial intelligence (AI) clearly reveals that brain science has resulted in breakthroughs in AI, such as deep learning. At present, although the developmental trend in AI and its applications has surpassed expectations, an insurmountable gap remains between AI and human intelligence. It is urgent to establish a bridge between brain science and AI research, including a link from brain science to AI, and a connection from knowing the brain to simulating the brain. The first steps toward this goal are to explore the secrets of brain science by studying new brain-imaging technology; to establish a dynamic connection diagram of the brain; and to integrate neuroscience experiments with theory, models, and statistics. Based on these steps, a new generation of AI theory and methods can be studied, and a subversive model and working mode from machine perception and learning to machine thinking and decision-making can be established. This article discusses the opportunities and challenges of adapting brain science to AI.}
}
@article{PRINSLOO2021101515,
title = {Sustainability assessment framework and methodology with trans-disciplinary numerical simulation model for analytical floatovoltaic energy system planning assessments},
journal = {Sustainable Energy Technologies and Assessments},
volume = {47},
pages = {101515},
year = {2021},
issn = {2213-1388},
doi = {https://doi.org/10.1016/j.seta.2021.101515},
url = {https://www.sciencedirect.com/science/article/pii/S2213138821005269},
author = {F.C. Prinsloo and Peter Schmitz and Andrea Lombard},
keywords = {Floatovoltaic system synthesis, WELF-nexus environmental profiling, Sustainability profiling, Floating solar simulation model, FPV sustainability assessment},
abstract = {Floatovoltaics is rapidly emerging as a novel type of sustainable energy technology, in which solar photovoltaic installations are sited directly on open-water spaces. As an agro-renewable energy-generation technology, it makes dual use of water to generate revenue from under-utilised irrigation water surfaces while also offering mutually beneficial layers of land-saving, environmental conservation and water-preservation benefits. Standardised metrics for ground-mounted photovoltaic projects, however, do not properly account for the technology’s extended range of resource-use-efficiencies and impact-effect-positives. Such knowledge gaps hinder evidence-based scientific assessments in regulatory project permissions mandated by law. Technology planning and impact assessment practices can benefit from a computer-aided technique to characterise floatovoltaic performance profiles. This paper introduces a conceptual empirical modelling framework, a holistic system dynamics-thinking methodology and a computer synthesis model to empirically predict the performance and sustainability profiles of prospective floatovoltaic installations. By inherently exploring the techno-economic and techno-environmental externalities of floatovoltaic enterprises, it translates performance profiles into sustainability indicators, articulated as WELF-nexus parameters. The paper details the integrated analytical framework, mathematical modelling formulation and digital computer synthesis model towards quantitative floatovoltaic energy system planning and sustainability assessments. The study’s main finding is that an integrated techno-enviro-economic floatovoltaic assessment methodology can be successfully modelled as a context-sensitive synthesis technique in a system dynamics modelling environment. The proposed technique can find utility in solving real-world problems with assessments in efficiency, feasibility and sustainability for agricultural floatovoltaics.}
}
@article{PRADNYANA2025100307,
title = {An explainable ensemble model for revealing the level of depression in social media by considering personality traits and sentiment polarity pattern},
journal = {Online Social Networks and Media},
volume = {46},
pages = {100307},
year = {2025},
issn = {2468-6964},
doi = {https://doi.org/10.1016/j.osnem.2025.100307},
url = {https://www.sciencedirect.com/science/article/pii/S2468696425000084},
author = {Gede Aditra Pradnyana and Wiwik Anggraeni and Eko Mulyanto Yuniarno and Mauridhi Hery Purnomo},
keywords = {Explainable ensemble model, Personality trait, Sentiment polarity pattern, RoBERTa, Hybrid RF-BiLSTM},
abstract = {Early detection of depression in mental health is crucial for better intervention. Social media has been extensively used to examine users’ behavior, motivating researchers to develop an automatic depression detection model. However, the accuracy and clarity of the reasons behind the detection results still need to be improved. Current research focuses primarily on syntactic and semantic information in user-posted texts, while other aspects of users’ psychological characteristics are often overlooked. Therefore, this study addresses the gap by proposing a novel model integrating personality traits and sentiment polarity patterns into an explainable ensemble model. Specifically, we developed two base learners for the averaged and meta-ensemble learning strategy. The first learner employed the Robustly Optimized BERT Pre-training Approach (RoBERTa). For the second learner, we combined the Random Forest and Bidirectional Long Short-Term Memory (RF-BiLSTM) methods to effectively handle the combination of personality traits and sequential information in sentiment polarity patterns. These additional features are obtained by performing domain adaptation for personality prediction and sentiment analysis using a lexicon-based model. Based on the experimental results, our ensemble model improved depression detection results by leveraging the strengths of each base learner. Our model advanced the state-of-the-art, outperforming existing models with an increase in accuracy and F1-score of 4.14% and 2.99%, respectively. The model successfully enhanced the interpretability of detection results, providing a more comprehensive understanding of the factors underlying depressive symptoms. This research highlights the potential of considering alternative additional features as a promising avenue for enhancing depression detection in social media.}
}
@article{KUMAR202415,
title = {Hybrid approach of type-2 fuzzy inference system and PSO in asthma disease},
journal = {Clinical eHealth},
volume = {7},
pages = {15-26},
year = {2024},
issn = {2588-9141},
doi = {https://doi.org/10.1016/j.ceh.2024.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S2588914124000017},
author = {Tarun Kumar and Anirudh {Kumar Bhargava} and M.K. Sharma and Nitesh Dhiman and Neha Nain},
keywords = {Asthma, Type-2 fuzzy set, Type-2 fuzzy optimized system, Particle swarm optimization, Medical diagnostic},
abstract = {This research work presents a hybrid approach combining a type-2 fuzzy inference system with particle swarm optimization (PSO) to develop a type-2 fuzzy optimized inference system, specifically tailored for asthma patient data. Addressing the inherent uncertainty in medical diagnostics, this model enhances traditional type-1 fuzzy logic by incorporating ambiguity into linguistic variables and utilizing type-2 fuzzy if-then rules. The system is trained to minimize diagnostic error in asthma disease identification. Applied to a dataset comprising eight medical entities from asthma patients, the model demonstrates substantial accuracy improvements. Numerical computations validate the system, showing a decrease in error rate from 1.445 to 0.03, indicating a significant enhancement in diagnostic precision. These results underscore the potential of our model in medical diagnostic problems, providing a novel and effective tool for tackling the complexities of asthma diagnosis.}
}
@article{SHAHIM2021102345,
title = {Security of the digital transformation},
journal = {Computers & Security},
volume = {108},
pages = {102345},
year = {2021},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2021.102345},
url = {https://www.sciencedirect.com/science/article/pii/S0167404821001693},
author = {Abbas Shahim},
keywords = {Digital transformation, Digital security, Information security, Digital disruption, IT auditing},
abstract = {In the early days of computation the focus was mainly on designing, developing, maintaining, and administering infrastructures and information systems housed in data centers. To this extend, security was traditionally organized around the basic technical components (e.g. data center facilities). The point was that an associated security activity was mostly separated from a business context and in general executed by the technical staff. Security was not fully understood by other audiences because the computer terminologies were frequently used. When security elements (e.g. logical access protocols used for identification, authentication, authorization) became part of the financial statement audit, its context became clearer, and it was conducted for external auditors. However, the presented outcome of the work was not completely interpretable for these practitioners as again, it was mainly reported in Information Technology (IT) jargon, and was not linked with the financial statement either. With the emergence the Sarbanes–Oxley Act (SOX) and the fundamental role of IT in relation hereto, the context of security suddenly changed to a great extent. The audience extended as compliance, including security, became the dominating item on the agenda of many C-levels (e.g. CFOs).}
}
@article{ALHARRASI201958,
title = {Evidence for the involvement of a GABAergic mechanism in the effectiveness of natural and synthetically modified incensole derivatives in neuropharmacological disorders: A computational and pharmacological approach},
journal = {Phytochemistry},
volume = {163},
pages = {58-74},
year = {2019},
issn = {0031-9422},
doi = {https://doi.org/10.1016/j.phytochem.2019.04.007},
url = {https://www.sciencedirect.com/science/article/pii/S0031942218308239},
author = {Ahmed Al-Harrasi and Ajmal Khan and Najeeb Ur Rehman and Sulaiman Al-Shidhani and Nasiara Karim and Imran Khan and Sobia Ahsan Halim and Ahmed Al-Rawahi and Javid Hussain and Rene Csuk},
keywords = {Incensole, Incensone, Incensfuran, Antidepressant, Anxiolytic, Anticonvulsant, Homology modelling, Molecular docking, ADMET prediction},
abstract = {In the course of our continuing exploration for novel bioactive lead compounds (s) from the species Boswellia, we have recently reported incensole derivatives isolated from Boswellia papyrifera Hochst. Given the known antidepressant-like effects of incensole and incensole acetate, we herein present that the low dose intraperitoneal administration of incensole derivatives, namely, incensfuran and incensone, showed significant antidepressant-like effects in the forced swim test (FST) and tail suspension test (TST). Furthermore, these compounds were evaluated for their anxiolytic potential in the elevated plus maze (EPM) and light dark box (LDB) tests and anticonvulsant effects in pentylenetetrazole (PTZ)-induced seizure tests. In the EPM test, administration of these compounds led to dose-dependent increases in open arm entries and in the time spent in EPM open arms. Similar results were obtained in the LDB test, wherein compounds these caused significant increases in the number of transitions between lit and dark compartments and the time spent in the lit compartment. The anxiolytic-like effects in the EPM were not reversed by pretreatment with flumazenil, whereas PTZ and bicuculline (BIC) completely abolished the anxiolytic effects, showing the involvement of the non-benzodiazepine binding sites of GABAA receptors. All four compounds induced significantly elevated brain GABA levels, indicating the involvement of a GABAergic mechanism. Additionally, molecular docking was conducted to elucidate the mode of action for the anxiolytic and anticonvulsant effects of these derivatives. Moreover, these compounds also possess drug-like properties and excellent ADMET profiles.}
}
@article{DUFVA201917,
title = {Grasping the future of the digital society},
journal = {Futures},
volume = {107},
pages = {17-28},
year = {2019},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2018.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0016328717302252},
author = {Tomi Dufva and Mikko Dufva},
keywords = {Digitalisation, Digital society, Experiential foresight, Craft education, Art education, Artistic research, Embodied learning, Critical theory},
abstract = {Society is increasingly digitalised and connected, with computers and algorithms mediating much of people’s daily activity in one way or another. The degree of digitalisation and its consequences are challenging to understand because most people lack first-hand experience of what digitalisation actually feels like. Digitalisation is abstract and difficult to grasp, which leads to a detached sense of the digital surroundings. In this paper, we argue that in order to grasp the nature and future of a digitalised society, an embodied understanding of digitalisation is needed. Such an understanding should utilise ways of knowing other than rational thinking, challenge existing narratives and move from preparing for the future to exploring novelty. We focus on the importance of a broader understanding of digitalisation within the field of education and discuss how a more diverse view is essential to empower people to take part in a digitalised society. We use the concept of ‘digi-grasping’ to analyse awareness and involvement in the digital world. By digi-grasping we mean active sense-making and existing in a world that consists of both a digital and a physical world. We argue that through ‘grasping’ the digital world it is possible to create an ethical and aesthetic attachment to society. Digi-grasping can empower people to understand and question the choices and motivations behind current digital structures and create new structures. It is thus an important approach to shaping the futures of digital society. We illustrate the concept with examples representing different modes of being and doing at the interface of the digital and physical.}
}
@article{FEIZABADI2024103461,
title = {When and under what conditions ambidextrous supply chains prove effective? Insights from simulation and empirical studies},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {183},
pages = {103461},
year = {2024},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2024.103461},
url = {https://www.sciencedirect.com/science/article/pii/S1366554524000516},
author = {Javad {Feiz Abadi} and David M. Gligor and Somayeh {Alibakhshi Motlagh} and Raj Srivastava},
keywords = {Supply Chain Archetype, Ambidexterity, NK modeling, Paradoxes},
abstract = {Our research delves into the impact of ambidextrous supply chain activity configurations on performance, particularly in the dynamic and complex contexts of today's business landscape. Drawing from the rich literature on paradox theory, we aim to unravel the efficacy of ambidextrous supply chain setup in mitigating the tensions inherent in managing dynamism, complexities, munificence, and, as well as understanding the contextual factors that modulate this efficacy. To accomplish this, we construct a computational model that captures the resource allocation and search behavior of the ambidextrous supply chain archetype within the ever-shifting terrain of performance. Our findings reveal that ambidextrous supply chain configurations excel at reconciling paradoxical tensions stemming from high complexity, limited resource abundance, and turbulent market conditions. Empirical data substantiate these findings.}
}
@article{LIU2023100050,
title = {Literature review of digital twin technologies for civil infrastructure},
journal = {Journal of Infrastructure Intelligence and Resilience},
volume = {2},
number = {3},
pages = {100050},
year = {2023},
issn = {2772-9915},
doi = {https://doi.org/10.1016/j.iintel.2023.100050},
url = {https://www.sciencedirect.com/science/article/pii/S2772991523000257},
author = {Cheng Liu and Peining Zhang and Xuebing Xu},
keywords = {Digital Twin, Civil Infrastructure, Bridges, High-speed Railway},
abstract = {Currently, there are numerous drawbacks associated with infrastructure health monitoring and management, such as inefficiency, subpar real-time functionality, demanding data requirements, and high cost. Digital twin (DT), a hybrid of a computational simulation and an actual physical system, has been proposed to overcome these challenges and become increasingly popular for modeling civil infrastructure systems. This literature review summarized different methods to build digital twins in civil infrastructure. In addition, this review also introduced the current progress of digital twins in different infrastructure sectors, including smart cities and urban spaces, transport systems, and energy systems, along with detailed examples of their various applications. Finally, the current challenges in digital twin technologies for civil infrastructure are also highlighted.}
}
@article{CHAIARWUT2025101338,
title = {Enhancing executive mathematics problem-solving through a constructivist digital learning platform: Design, development and evaluation},
journal = {Social Sciences & Humanities Open},
volume = {11},
pages = {101338},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101338},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125000658},
author = {Supaluk Chaiarwut and Sanit Srikoon and Apirat Siritaratiwat and Parama Kwangmuang},
keywords = {Learning innovation, Digital platform, Mathematics problem solving},
abstract = {Recent international assessments have highlighted a global decline in mathematics performance, particularly among students in Thailand. This study aims to (1) design and evaluate a constructivist learning innovation model on a digital platform that promotes executive mathematics problem-solving and (2) develop and assess a prototype based on the designed model. A mixed-method research design was employed across two phases. Phase 1 involved designing and evaluating the learning model through document analysis and expert validation (n = 9). Phase 2 focused on developing and testing a prototype with experts (n = 15) and students (n = 30). Data collection utilized the Index of Item-Objective Congruence (IOC), System Usability Scale (SUS), and User Engagement Scale (UES). The model showed strong alignment with theoretical principles (IOC = 0.84). The prototype showed excellent usability (SUS = 91.0/100) and high engagement (UES = 4.26/5.00). Expert evaluations indicated high quality in content (M = 4.47, SD = 0.48), media (M = 4.40, SD = 0.50), and innovation design (M = 4.59, SD = 0.64). The findings validate the model's efficacy in promoting executive mathematics problem-solving skills through a constructivist digital platform approach.}
}
@article{SHIEH1993421,
title = {Massively parallel computational methods for finite element analysis of transient structural responses},
journal = {Computing Systems in Engineering},
volume = {4},
number = {4},
pages = {421-433},
year = {1993},
note = {Parallel Computational Methods for Large-Scale Structural Analysis and Design},
issn = {0956-0521},
doi = {https://doi.org/10.1016/0956-0521(93)90011-K},
url = {https://www.sciencedirect.com/science/article/pii/095605219390011K},
author = {R.C. Shieh},
abstract = {With the emphasis on the finitely damped system (e.g. control structure interaction) case, two fully implicit and two semi-implicit sets of finite element method-based numerical algorithms are formulated for transient response analysis of space frame and truss structures in a massively parallel processing (MPP) environment. All algorithm sets use an implicit force calculation/vector equation of motion assembly procedure. The semi-implicit algorithms are based on the explicit central difference (CD) and the fourth-order Runge-Kutta (RK4) schemes, respectively, in conjunction with the use of mass lumping techniques so that solution of the recurrence equations for unknown displacements is reduced to a trivial diagonal matrix inversion operation. The fully implicit algorithm sets are based on the Newmark Beta (NB) and CD schemes, respectively, in conjunction with use of the (iterative) preconditioned conjugate gradient (PCG) method for solving the linear algebraic recurrence equations. The semi-implicit algorithm sets are fully implemented and assessed on an MPP CM-2 computer. A preliminary assessment of the fully implicit sets of algorithms is made on a Sun Workstation. These numerical study results show that the newly formulated MPP algorithms are, to a varying degree, superefficient (or potentially superefficient) on the CM-2 compared with, and even highly competitive against, the conventional sequential algorithms on an advanced serial computer.}
}
@article{RIZZOLATTI1997562,
title = {Parietal cortex: from sight to action},
journal = {Current Opinion in Neurobiology},
volume = {7},
number = {4},
pages = {562-567},
year = {1997},
issn = {0959-4388},
doi = {https://doi.org/10.1016/S0959-4388(97)80037-2},
url = {https://www.sciencedirect.com/science/article/pii/S0959438897800372},
author = {Giacomo Rizzolatti and Leonardo Fogassi and Vittorio Gallese},
abstract = {Recent findings have altered radically our thinking about the functional role of the parietal cortex. According to this view, the parietal lobe consists of a multiplicity of areas with specific connections to the frontal lobe. These areas, together with the frontal areas to which they are connected, mediate distinct sensorimotor transformations related to the control of hand, arm, eye or head movements. Space perception is not unitary, but derives from the joint activity of the fronto-parietal circuits that control actions requiring space computation.}
}
@article{ZHANG20162579,
title = {Efficient vehicles path planning algorithm based on taxi GPS big data},
journal = {Optik},
volume = {127},
number = {5},
pages = {2579-2585},
year = {2016},
issn = {0030-4026},
doi = {https://doi.org/10.1016/j.ijleo.2015.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S0030402615019075},
author = {Jindong Zhang and Weibin Meng and QiangQiang Liu and Haofeng Jiang and Yujie Feng and Gang Wang},
keywords = {Taxi GPS trajectory, Big data, Driving stratagem, Map matching, Optimal path},
abstract = {The driving thinking of taxi drivers is always hidden in a large amount of taxis GPS data. An efficient driving stratagem derived from taxi drivers is provided for private car drivers. The five million pieces of taxis GPS data in Nanjing, China are analyzed: firstly, the data preprocessing is conducted for the reduction measuring error of GPS data with the expurgation of the static point, the drifting point, and the relatively independent point; then, the road intersections through the regional extreme points are found to restore map with the following three algorithms: the path selection algorithm based on probability, the improved Prim path selection algorithm, and the improved Prim path selection algorithm based on probability; at last, the SPFA (Shortest Path Faster Algorithm) is applied to the measurement of the road map gained from the previous three algorithms for optimal path planning with 40 pairs of starting points and termination points, and making a comparison of the road length among three methods. Through the experimental comparison, the third method namely the improved Prim path selection algorithm based on probability which proved to be more optimal than others two methods produces an efficient driving route more accurately.}
}
@article{RUSSELL2018114,
title = {Leveraging complexity for ecosystemic innovation},
journal = {Technological Forecasting and Social Change},
volume = {136},
pages = {114-131},
year = {2018},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2017.11.024},
url = {https://www.sciencedirect.com/science/article/pii/S0040162517316475},
author = {Martha G. Russell and Nataliya V. Smorodinskaya},
keywords = {Business network, Collaboration, Complexity, Innovation ecosystem, Innovation cluster, Global economy, Non-linearity},
abstract = {This paper looks at innovation ecosystems through the lens of complexity science, considering them as open non-linear entities that are characterized by changing multi-faceted motivations of networked actors, high receptivity to feedback, and persistent structural transformations. In the context of the growing organizational complexity of economies, driven by their adaptation to high uncertainty, and the central role of collaboration, we differentiate the innovation capacity of various types of business networks by the complexity of their internal interactions, thus identifying the place of innovation ecosystems in the world of business networks, as well as the place of innovation clusters among other innovation ecosystems. We observe how innovation ecosystems have been viewed in four different research streams: management literature; the inter-firm and business network stream of economic and sociological literature; the innovation policy and competitiveness agenda in economic literature; and the dichotomy of localized and economy-wide innovation ecosystems in policy studies (in economic literature, evolutionary geography, and regional research). We then describe generic properties of innovation ecosystems in terms of complexity science, viewing them as complex adaptive systems, paying special attention to the complexity of innovation clusters. We compare complexity thinking of modern economies, deriving from their emerging ecosystem design, with traditional thinking conceived for industrial era, drawing insights for a better transition to innovation-led growth. We conclude with a summary of key findings, practical and policy implications and recommendations for further study.}
}
@article{BOGGS19831,
title = {The integration of structure determination by computation, electron diffraction and microwave spectroscopy},
journal = {Journal of Molecular Structure},
volume = {97},
pages = {1-16},
year = {1983},
note = {Determination of Molecular Structure by Microwave Spectroscopy and Electron Diffraction},
issn = {0022-2860},
doi = {https://doi.org/10.1016/0022-2860(83)90171-0},
url = {https://www.sciencedirect.com/science/article/pii/0022286083901710},
author = {James E. Boggs},
abstract = {The history of the interaction between experimental structure determinations by microwave spectroscopy and by gas phase electron diffraction is briefly reviewed in terms of three eras: (1) competition and antagonism, (2) comparison and correction, and (3) integration of analysis. A similar progression is noted for the relation between experimental and theoretical methods for studying molecular structure, with the present time straddling ages (2) and (3). Examples are given from a variety of studies involving various degrees of methodological interaction. The true integration of experimental and computational structural studies is still in its infancy with the primary illustrations involving the evaluation of theoretical structural offset values from experimental evidence, the transfer of theoretically determined parameters into the fitting of experimental data, and the current development of methods for utilizing vibrational information obtained from the combined analysis of computed theoretical and experimental infrared data in the further analysis of experimental diffraction and microwave information.}
}
@article{LAL2023100791,
title = {IOT-based cyber security identification model through machine learning technique},
journal = {Measurement: Sensors},
volume = {27},
pages = {100791},
year = {2023},
issn = {2665-9174},
doi = {https://doi.org/10.1016/j.measen.2023.100791},
url = {https://www.sciencedirect.com/science/article/pii/S2665917423001277},
author = {Bechoo Lal and S. Ravichandran and R. Kavin and N. {Anil Kumar} and Dibyahash Bordoloi and R. {Ganesh Kumar}},
keywords = {Cyber security, Machine learning algorithms, Security, Repositories, Meta-classifier methods, Internet of things},
abstract = {Manual vulnerability evaluation tools produce erroneous data and lead to difficult analytical thinking. Such security concerns are exacerbated by the variety, imperfection, and redundancies of modern security repositories. These problems were common traits of producers and public vulnerability disclosures, which make it more difficult to identify security flaws through direct analysis through the Internet of Things (IoT). Recent breakthroughs in Machine Learning (ML) methods promise new solutions to each of these infamous diversification and asymmetric information problems throughout the constantly increasing vulnerability reporting databases. Due to their varied methodologies, those procedures themselves display varying levels of performance. The authors provide a method for cognitive cybersecurity that enhances human cognitive capacity in two ways. To create trustworthy data sets, initially reconcile competing vulnerability reports and then pre-process advanced embedded indicators. This proposed methodology's full potential has yet to be fulfilled, both in terms of its execution and its significance for security evaluation in application software. The study shows that the recommended mental security methodology works better when addressing the above inadequacies and the constraints of variation among cybersecurity alert mechanisms. Intriguing trade-offs are presented by the experimental analysis of our program, in particular the ensemble method that detects tendencies of computational security defects on data sources.}
}
@article{FITZPATRICK2020101942,
title = {The relation between academic abilities and performance in realistic word problems},
journal = {Learning and Individual Differences},
volume = {83-84},
pages = {101942},
year = {2020},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2020.101942},
url = {https://www.sciencedirect.com/science/article/pii/S1041608020301229},
author = {Cheryll L. Fitzpatrick and Darcy Hallett and Kyle R. Morrissey and Nadine R. Yıldız and Rutanya Wynes and Felix Ayesu},
keywords = {Word problems, Academic abilities, Educational psychology, Math cognition},
abstract = {The research on realistic word problems investigates how children (and even adults) largely fail to incorporate real-world knowledge into mathematical word problems. Because of this, most research in this area focuses on improving realistic thinking. However, very little research has explored what other abilities might predict which children actually do take real-world information into account, and what this might imply about the nature of realistic responding. We tested whether general academic abilities, such as verbal skill, reading comprehension, and math calculation skill, previously shown to be related to standard word problem performance, are related to realistic responses, and whether realistic responding is related to standard word problem solving. In our sample of sixth-grade students, only reading comprehension was independently predictive of solving realistic word problems. Performance on realistic word problems, however, was independently predictive of solving standard word problems. As such, realistic word problems may reflect problem solving ability independent of general academic ability, and therefore may be an ability worth fostering.}
}
@incollection{MENAMADATHIL202463,
title = {Chapter 4 - Machine learning approach for vaccine development-fundamentals},
editor = {Jayashankar Das and Sushma Dave and Siomar de Castro Soares and Sandeep Tiwari},
booktitle = {Reverse Vaccinology},
publisher = {Academic Press},
pages = {63-85},
year = {2024},
isbn = {978-0-443-13395-4},
doi = {https://doi.org/10.1016/B978-0-443-13395-4.00025-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443133954000253},
author = {Dhanalakshmi Menamadathil and Kajari Das and Sushma Dave and Jayashankar Das},
keywords = {Artificial intelligence, machine learning, support vector machine, logistic regression, extreme gradient boosting, convolutional neural network, recurrent neural networks, reverse vaccinology},
abstract = {Artificial intelligence (AI)–assisted vaccine creation has emerged as a significant development among the cutting-edge technologies that will help society in the 21st century. AI and machine learning technologies have brought answers to issues that have arisen as a result of the advent of recurring and emerging infectious diseases and the rise in antibiotic resistance. The rapid discovery of effective vaccines has been crucial in preparation for outbreaks, including epidemics and pandemics. The urgent requirement for precise vaccine creation in a short duration has led the way for researchers to investigate diverse vaccine-development technologies such as computational biology, structure-based antigen design, protein engineering, gene synthesis, and novel manufacturing platforms, With the advent of whole-genome sequencing and big data analytic platforms aided by AI, omics-based vaccine design has emerged, which is also known as reverse vaccinology (RV). RV accomplishes comprehensive immunogenicity profiling employing proteome and structural data. With the advancement of AI and deep learning algorithms, a range of modeling tools for accurate and precise prediction of immune-recognition patterns have been created, which may be utilized to generate novel vaccine candidates. Given that vaccinations are available for a few infectious illnesses, there is an urgent need for the quick development of vaccines for numerous lethal and developing infections, which can give prominence to RV. Within the course of this chapter, a thorough view of AI -employed algorithms and their role in RV is offered, with a particular emphasis on immunoinformatic and AI methods utilized in it.}
}
@article{AICHA2022107933,
title = {A mathematical formulation for processing time computing in disassembly lines and its optimization},
journal = {Computers & Industrial Engineering},
volume = {165},
pages = {107933},
year = {2022},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2022.107933},
url = {https://www.sciencedirect.com/science/article/pii/S0360835222000031},
author = {Mahdi Aicha and Imen Belhadj and Moncef Hammadi and Nizar Aifaoui},
keywords = {DP Evaluation, Index of Quality, Operating time, Optimization, Lean thinking},
abstract = {Disassembly is the first practice in maintenance and recycling of industrial products. For productivity and efficiency, it is necessary to optimize its operative manners by reducing: change of tools and directions, process variation, wastes, etc. The simulation of Disassembly Plan (DP) allows the detection and identification of difficulties from the design stage in order to avoid them. This paper proposes a mathematical formulation which combines two principal indicators: the index of Quality (Qi) and the index of processing Time (Ti) in order to choose the best and feasible disassembly plan. The Failure Mode, Effects and Criticality Analysis method is implemented to compute Qi. Ti is obtained according to real manufacturing constraints (workspace, layout, tools, machines, etc.). Based on 5S method, the workspace can be optimized which directly impacts the timing index and contribute to the selection of the best DP. A gear box is used to show up the efficiency of the proposed approach.}
}
@article{SHARMA2024100944,
title = {Towards intelligent industrial systems: A comprehensive survey of sensor fusion techniques in IIoT},
journal = {Measurement: Sensors},
volume = {32},
pages = {100944},
year = {2024},
issn = {2665-9174},
doi = {https://doi.org/10.1016/j.measen.2023.100944},
url = {https://www.sciencedirect.com/science/article/pii/S2665917423002805},
author = {Deepak sharma and Anuj kumar and Nitin Tyagi and Sunil S. Chavan and Syam Machinathu Parambil Gangadharan},
keywords = {Sensor fusion, Machine learning, Fault tolerance, Fault prediction, Neural network},
abstract = {Industrial Internet of Things (IIoT) is systems aim to facilitate human monitoring and the direction of efficient production of goods in industrial settings by linking a wide variety of intelligent devices such as sensors, actuators, and controllers. This is achieved by utilizing Internet of Things (IoT) to diagnose a problem with a specific IIoT part is to employ a basic diagnostic technique that's based on models and data. Physical models, signal patterns, and machine-learning strategies must be adequately built to account for system challenges. Another factor that could lead to an exponential rise in complexity is the ever-increasing interconnections between different electronic hardware. The knowledge-based defect diagnosis methods boost interoperability in the operation. Users don't need to be experts in the field to benefit from the system's high-level thinking and response to their queries. So, in advanced IIoT systems, a knowledge-based fault diagnostic approach is favored over traditional model-based and data-driven diagnosis methods. The goal of this study is to evaluate recent improvements in the design of knowledge-based defect detection in the context of IIoT systems, deductive and inductive reasoning, and many other forms of logical reasoning. IIoT-based systems have revolutionized industrial settings by connecting intelligent devices such as sensors, actuators, and controllers to enable efficient production and human monitoring. In this survey paper, we explore machine learning-based sensor fusion techniques within the realm of Industrial Internet of Things (IIoT), addressing critical challenges in fault detection and diagnosis.}
}
@article{LI2025108,
title = {Enhancing energy materials with data-driven methods: A roadmap to long-term hydrogen energy sustainability using machine learning},
journal = {International Journal of Hydrogen Energy},
volume = {119},
pages = {108-125},
year = {2025},
issn = {0360-3199},
doi = {https://doi.org/10.1016/j.ijhydene.2025.03.201},
url = {https://www.sciencedirect.com/science/article/pii/S0360319925013151},
author = {Cheng Li and Jianjun Ma and Des Gibson and Yijun Yan and Muhammad Haroon and Mehak {Bi Bi}},
keywords = {Hydrogen energy, Machine learning, Data driven, Artificial intelligence, Energy materials},
abstract = {In the past few years, there has been a lot of interest in studying new substances and figuring out how their structure affects their activity. This is seen as an alternative to the problems that come with traditional methods of making energy materials, like the high cost of computation, the time consumption, and the low success rate. Improving the study and production of energy materials requires new research, ideas, and methodologies. Some believe that data-driven materials science, enabled by recent advances in artificial intelligence (AI) and machine learning (ML), might modify current scientific knowledge and radically alter the production of energy materials. This includes essential advancements in hydrogen energy, like creating catalysts for producing hydrogen, finding materials for storing hydrogen, and improving fuel cell components. New findings in data-driven materials science suggest that ML technologies enable the development, identification and deployment of improved energy materials while simultaneously making their creation and improvement less of a hassle. This paper argues that funding research into alternative energy materials is an important first step towards achieving global carbon neutrality. Also included is a comprehensive ML concept overview covering topics like open-source databases, feature development, ML algorithms, and ML model assessment, among others. We discuss the modern developments in data-driven material sciences (DDMS) and technology, which cover topics such as materials for alkaline ion batteries, solar energy catalysis, and carbon dioxide recovery. This section concludes with some important ideas for making effective use of ML and some additional difficulties in creating new energy materials.}
}
@article{OLMEDO2015115,
title = {Quantitative characterization of chaordic tourist destination},
journal = {Tourism Management},
volume = {47},
pages = {115-126},
year = {2015},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2014.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S0261517714001812},
author = {Elena Olmedo and Ruth Mateos},
keywords = {Complexity, Chaos, Chaordic system, Tourism Arrivals},
abstract = {This paper highlights the new horizons opening with the applications of concepts from the application of the complexity science to tourism data, which are traditionally treated from an intradisciplinar point of view. From this new point of view, tourism is considered as a complex adaptive system. Complexity theory is rooted in the hard sciences, and social sciences have adopted it in recent times. Going a step further, we introduce the concept of chaordic system in tourism. This new thinking has appeared in the social sciences as a response to the current need to cope with contradictions and inconsistencies, adapting evolution without losing essence. We propose considering tourism as a chaordic system and analyzing the resulting managerial consequences. We propose the use of a set of measures to quantify a system as chaordic. Finally, we empirically analyze tourist arrivals to Majorca (Spain) to verify the existence of a chaordic system.}
}
@article{GRIFFEN20208695,
title = {Chemists: AI Is Here; Unite To Get the Benefits},
journal = {Journal of Medicinal Chemistry},
volume = {63},
number = {16},
pages = {8695-8704},
year = {2020},
issn = {1520-4804},
doi = {https://doi.org/10.1021/acs.jmedchem.0c00163},
url = {https://www.sciencedirect.com/science/article/pii/S1520480420001672},
author = {Edward J. Griffen and Alexander G. Dossetter and Andrew G. Leach},
abstract = {The latest developments in artificial intelligence (AI) have arrived into an existing state of creative tension between computational and medicinal chemists. At their most productive, medicinal and computational chemists have made significant progress in delivering new therapeutic agents into the clinic. However, the relationship between these communities has the prospect of being weakened by application of oversimplistic AI methods that, if they fail to deliver, will reinforce unproductive prejudices. We review what can be learned from our history of integrating QSAR and structure-based methods into drug discovery. Now with synthesis and testing available as contract services, the environment for computational innovation has changed and we consider the impact this may have on the relationships in our disciplines. We discuss the current state of interdisciplinary communication and suggest approaches to bring the subdisciplines together in order to improve computational medicinal chemistry and, most importantly, deliver better medicines to the clinic faster.
}
}
@article{GINEITYTE1999205,
title = {On the future of the Hückel model},
journal = {Journal of Molecular Structure: THEOCHEM},
volume = {491},
number = {1},
pages = {205-209},
year = {1999},
issn = {0166-1280},
doi = {https://doi.org/10.1016/S0166-1280(99)00116-5},
url = {https://www.sciencedirect.com/science/article/pii/S0166128099001165},
author = {V. Gineityte},
keywords = {Basis orbitals, Hückel model, Hamiltonian matrix},
abstract = {In an attempt to foresee the prospects of the qualitative trend in quantum chemistry, the place of the Hückel model is analyzed in the broad context of quantum mechanical and chemical perspectives on the molecular world. Quantum mechanics and chemistry are considered as complementary approaches to molecular structure and properties that are irreducible one to another. Arguments are given for the hypothesis that the Hückel model makes a separate level of investigation of molecules situated in between quantum mechanics and chemistry. In this context, the need is emphasized for development of new concepts immanent in the very Hückel model. These concepts are anticipated to play the role of terms for qualitative orbital thinking, the persistent need for which was emphasized recently (R. Hoffmann, J. Mol. Struct. (Theochem), 424 (1998) 1).}
}
@article{LOWRIE20112244,
title = {Gender differences in students’ mathematics game playing},
journal = {Computers & Education},
volume = {57},
number = {4},
pages = {2244-2248},
year = {2011},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2011.06.010},
url = {https://www.sciencedirect.com/science/article/pii/S0360131511001394},
author = {Tom Lowrie and Robyn Jorgensen},
keywords = {Gender studies, Elementary education, Pedagogical issues, Numeracy practices},
abstract = {The investigation monitored the digital game-playing behaviours of 428 primary-aged students (aged 10–12 years). Chi-square analysis revealed that boys tend to spend more time playing digital games than girls while boys and girls play quite different game genres. Subsequent analysis revealed statistically significant gender differences in terms of the types of mathematics-rich games students prefer to play. Girls preferred to play games that required problem solving, quantitative computations and the interpretation of graphs. Boys preferred games that required visual/spatial engagement. Given the fact that boys outperform girls on spatial tasks and mathematics assessment items that contain graphics, this study has implications for the development of students' mathematics sense making.}
}
@article{NAKAMURA20091639,
title = {A shift of mind – Introducing a concept creation model},
journal = {Information Sciences},
volume = {179},
number = {11},
pages = {1639-1646},
year = {2009},
note = {Including Special Issue on Chance Discovery},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2008.11.036},
url = {https://www.sciencedirect.com/science/article/pii/S0020025508004933},
author = {Jun Nakamura and Yukio Ohsawa},
keywords = {Creativity, Concept, Ambiguity and constraint},
abstract = {The ability to construct concepts is indispensable to both individual and evolutionary development. Our model involves the use of ambiguous stimuli to facilitate decision-making by promoting analogical reasoning. Toward this end, we have developed Web-based exercises in word categorization for the purpose of engaging participants in analogical reasoning that contributes to the integration of words and leads to the construction of new concepts. 12 graduate students and 20 junior high school students were presented with ambiguous information for the purpose of comparison between the senior and the junior students. We hypothesized that the senior students tend to behave with more insight rather than junior students with less activation of thought process. Our results suggested that the presentation of the ambiguous stimuli were associated with unique thought processes, which are consistent with approaches to word categorization that reflect either the experience of insight or the operation of a trial and error strategy, depending on the junior or the senior students. We showed that the senior students tend to be more like insight into categorization design, while the junior as rather try and error behavior, in consideration of needed time and actions in analogical thinking.}
}
@article{BARRON1992245,
title = {A bibliography on computational molecular biology and genetics},
journal = {Mathematical and Computer Modelling},
volume = {16},
number = {6},
pages = {245-319},
year = {1992},
issn = {0895-7177},
doi = {https://doi.org/10.1016/0895-7177(92)90166-I},
url = {https://www.sciencedirect.com/science/article/pii/089571779290166I},
author = {Sarah Barron and Matthew Witten and Gongxian Liu},
abstract = {The field of computational molecular biology and genetics is expanding at an enormous rate. Journals such as CABIOS and Nucleic Acids Research routinely publish articles on computational and mathematical aspects of biology. The purpose of this paper is to provide a bibliographic review of the literature in this area related to DNA mapping and sequence analysis. We have focused on computer and mathematical aspects of molecular biology and genetics (interpreted in a broad sense). Authors are solicited for their additions/corrections to this bibliography. Contact us at the above address.}
}
@article{BOEING2021102013,
title = {Spatial information and the legibility of urban form: Big data in urban morphology},
journal = {International Journal of Information Management},
volume = {56},
pages = {102013},
year = {2021},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2019.09.009},
url = {https://www.sciencedirect.com/science/article/pii/S0268401219302154},
author = {Geoff Boeing},
keywords = {OpenStreetMap, Urban design, Urban form, Urban morphology, Urban planning, Visualization},
abstract = {Urban planning and morphology have relied on analytical cartography and visual communication tools for centuries to illustrate spatial patterns, conceptualize proposed designs, compare alternatives, and engage the public. Classic urban form visualizations – from Giambattista Nolli’s ichnographic maps of Rome to Allan Jacobs’s figure-ground diagrams of city streets – have compressed physical urban complexity into easily comprehensible information artifacts. Today we can enhance these traditional workflows through the Smart Cities paradigm of understanding cities via user-generated content and harvested data in an information management context. New spatial technology platforms and big data offer new lenses to understand, evaluate, monitor, and manage urban form and evolution. This paper builds on the theoretical framework of visual cultures in urban planning and morphology to introduce and situate computational data science processes for exploring urban fabric patterns and spatial order. It demonstrates these workflows with OSMnx and data from OpenStreetMap, a collaborative spatial information system and mapping platform, to examine street network patterns, orientations, and configurations in different study sites around the world, considering what these reveal about the urban fabric. The age of ubiquitous urban data and computational toolkits opens up a new era of worldwide urban form analysis from integrated quantitative and qualitative perspectives.}
}
@article{LI2025125605,
title = {Traffic scenario frozen callback and adaptive neuro-fuzzy inference system based energy management strategy for connected fuel cell buses},
journal = {Applied Energy},
volume = {387},
pages = {125605},
year = {2025},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2025.125605},
url = {https://www.sciencedirect.com/science/article/pii/S0306261925003356},
author = {Menglin Li and Haoran Liu and Mei Yan and Boyu Guo and Jingda Wu and Guokai Jiang and Xupeng Fu},
keywords = {Connected fuel cell bus, Energy management strategy, Traffic scenario frozen callback, Adaptive neuro-fuzzy inference system},
abstract = {Exploring the full potential of energy savings for new energy vehicles in a future connected transportation system is a challenging task. To address how connected buses can leverage surrounding traffic information to improve their energy efficiency, an intelligent fuel cell bus energy management method based on traffic scenario frozen callback is proposed， which enables high real-time performance in online energy management. To tackle the issue of inconsistent data dimensions caused by random fluctuations in the number of vehicles in a fixed traffic flow, a traffic flow representation based on grid grayscale images is designed. Building upon this representation, a speed trajectory prediction model based on traffic scenario frozen callback is developed. Subsequently, offline historical global optimal data are used to construct a training dataset that links speed trajectories to optimal control sequences. An end-to-end energy management framework based on the adaptive neuro-fuzzy inference system (ANFIS) is presented and validated in scenarios that before entering bus station and after exiting bus station. Simulation results demonstrate that, the proposed energy management strategy (EMS) approaches the overall energy consumption of dynamic programming (DP), reaching 97.76 % and 98.82 % in the two kinds of scenarios of its performance, outperforms the other two comparative EMSs. In terms of timeliness, the computational time spent by the proposed EMS is only 0.2076 times and 0.1952 times that of traditional model predictive control (MPC)-based EMS in the separate scenario.}
}
@incollection{PANDEY202563,
title = {Chapter 4 - Impact of quantum computing on healthcare data security},
editor = {Gayathri Nagasubramanian and S. Rakesh Kumar and Valentina {Emilia Balas}},
booktitle = {Quantum Computing for Healthcare Data},
publisher = {Academic Press},
pages = {63-90},
year = {2025},
series = {Advances in Biomedical Informatics},
isbn = {978-0-443-29297-2},
doi = {https://doi.org/10.1016/B978-0-443-29297-2.00002-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780443292972000022},
author = {Manoj Kumar Pandey and Jyoti Upadhyay and Naresh Kumar Kar and Velliangiri Sarveshwaran},
keywords = {Quantum computing, security, cryptography, healthcare, challenges, sustainable development goals},
abstract = {With the potential to completely transform computation, quantum computing (QC) is a young topic at the vanguard of scientific inquiry and technological advancement. QC promises to bring about dramatic improvements in data security and processing capabilities when it is integrated into healthcare systems. Conventional encryption techniques like RSA and ECC are based on discrete logarithms and integer factorization, two cryptographic issues that are currently unsolvable but can be solved by QC. This trend, however, also makes it more likely that current cryptographic systems will be subject to quantum attacks, which will force the creation and use of encryption methods that are resistant to quantum attacks. Additionally, by employing quantum-resistant hashing techniques, QC enables improved data integrity verification, guaranteeing the veracity and validity of medical data. The applied application of quantum-resistant cryptography techniques and the integration of quantum secure protocols into the current healthcare infrastructure still facing some difficulties therefore anyhow these encouraging advancements in this technique. This chapter focuses on the effect of the QC on the security of healthcare data with particular importance on how it revolutionized encryption, data integrity, privacy protection, and other related issues.}
}
@article{CAUDEK2021317,
title = {Susceptibility to eating disorders is associated with cognitive inflexibility in female university students},
journal = {Journal of Behavioral and Cognitive Therapy},
volume = {31},
number = {4},
pages = {317-328},
year = {2021},
issn = {2589-9791},
doi = {https://doi.org/10.1016/j.jbct.2021.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S2589979121000159},
author = {Corrado Caudek and Claudio Sica and Silvia Cerea and Ilaria Colpizzi and Debora Stendardi},
keywords = {Eating disorders, Cognitive inflexibility, Individual differences, Computational modeling, Reversal learning},
abstract = {Summary
The inability to learn from and adapt to changing feedback in our environment may be etiologically linked to eating disorders (EDs). However, previous investigations on this issue have shown conflicting results. In the current study with a non-clinical sample of female students, we investigated the relation between cognitive inflexibility (CI) and vulnerability to EDs by using a modified version of the probabilistic reversal learning (PRL) task, which requires participants to adapt their response strategy according to changes in stimulus-reward contingencies. We found that females vulnerable to EDs in the general population showed an impaired PRL performance, also after controlling for comorbidity. However, our results also show that the ED construct comprises separate dimensions, which affect contingency learning in opposite manners: some individuals vulnerable to EDs showed impaired contingency learning; others used unimpaired contingency learning skills to pursue self-harming goals. Such results point to the necessity of an appropriate assessment of CI in order to better apply individualized treatment.}
}
@article{CHAUDHARI2025107968,
title = {Alzheimer’s disease prediction using CAdam optimized reinforcement learning-based deep convolutional neural network model},
journal = {Biomedical Signal Processing and Control},
volume = {108},
pages = {107968},
year = {2025},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2025.107968},
url = {https://www.sciencedirect.com/science/article/pii/S1746809425004793},
author = {Puja A. Chaudhari and Suhas S. Khot},
keywords = {Alzheimer prediction, CAdam optimizer, Magnetic Resonance Imaging, Reinforcement learning, Deep Convolutional neural network},
abstract = {Background
Alzheimer’s Disease (AD), a neurological disorder, gradually declines cognitive ability, but detecting it at an early stage can effectively mitigate symptoms. Due to the shortage of expertise medical staff, automatic diagnosis becomes highly important, however, a detailed analysis of brain disorder tissues is required for accurate diagnosis using magnetic resonance imaging (MRI). Various detection methods are introduced to detect AD through MRI, but extracting the optimal brain regions and informative features is still a complicated and time-consuming factor. Moreover, the class imbalance issue of the OASIS and ADNI datasets needs to be addressed.
Method
Here, a Coyote Adam optimized Reinforcement Learning-Deep Convolutional Neural Network (CAdam-RL-DCNN) is proposed to address the aforementioned issues on AD detection using MRI. The effectiveness of the proposed method relies on effectively detecting the features automatically and SMOTE handles the class imbalance issues of the dataset through the minority samples. The computational complexity of the model is reduced through the appropriate model training using the proposed CAdam optimizer, which incorporates adaptive parameters of Adam using social behaviors and invasive hunting of coyote optimizer. In addition, the hybrid features combining the ResNet features, statistical features and modified textural pattern reduces the data complexity and promotes the model training towards an improved performance in AD prediction.
Result
The proposed model attains 96.31% accuracy, 97.50% sensitivity, 94.06% specificity, 93.87% precision, 97.50% recall, and 95.65% F1-score using ADNI dataset. Furthermore, the proposed model attains the superior performance achieving 95.09% accuracy, 94.52% sensitivity, 95.57% specificity, 93.14% precision, 94.52% recall, and 93.83% F1-score using OASIS dataset respectively.}
}
@incollection{AI2019853,
title = {Study on the formation of chemical wave patterns for the Belousov–Zhabotinsky reaction system},
editor = {Anton A. Kiss and Edwin Zondervan and Richard Lakerveld and Leyla Özkan},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {46},
pages = {853-858},
year = {2019},
booktitle = {29th European Symposium on Computer Aided Process Engineering},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-12-818634-3.50143-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128186343501430},
author = {Jiali Ai and Wei Sun and Chi Zhai},
keywords = {far-from thermodynamic equilibrium, instabilities, reaction-diffusion system, Hopf bifurcation},
abstract = {The Belousov–Zhabotinsky (BZ) reaction system is famous because it can generate self-organized patterns, also known as “chemical waves”. Pattern formation out of an initially homogeneous system is seemingly violating the 2nd-law of thermodynamics (order is produced out of disorder), while in fact, the BZ reaction is an open, far-from thermodynamic equilibrium system, where instability is the cause of morphogenesis and Hopf bifurcation of the reaction kinetics can generate self-oscillatory state trajectories. In this paper, the evolution of the BZ reaction in a two dimensional diffusion system is studied by the numerical computation methods, for the purpose of reconstructing the chemical wave patterns. The similarity of the chemical waves to many complex systems in biology, ecology and engineering makes current study potentially significant. With the study of the pattern formation, we hope provide some thoughts on complex system theory, thermodynamics of the self-oscillatory reaction system, and numerical computation methods on complex patterns, etc.}
}
@article{HALL198939,
title = {Computational approaches to analogical reasoning: A comparative analysis},
journal = {Artificial Intelligence},
volume = {39},
number = {1},
pages = {39-120},
year = {1989},
issn = {0004-3702},
doi = {https://doi.org/10.1016/0004-3702(89)90003-9},
url = {https://www.sciencedirect.com/science/article/pii/0004370289900039},
author = {Rogers P. Hall},
abstract = {Analogical reasoning has a long history in artificial intelligence research, primarily because of its promise for the acquisition and effective use of knowledge. Defined as a representational mapping from a known “source” domain into a novel “target” domain, analogy provides a basic mechanism for effectively connecting a reasoner's past and present experience. Using a four-component process model of analogical reasoning, this paper reviews sixteen computational studies of analogy. These studies are organized chronologically within broadly defined task domains of automated deduction, problem solving and planning, natural language comprehension, and machine learning. Drawing on these detailed reviews, a comparative analysis of diverse contributions to basic analogy processes identifies recurrent problems for studies of analogy and common approaches to their solution. The paper concludes by arguing that computational studies of analogy are in a state of adolescence: looking to more mature research areas in artificial intelligence for robust accounts of basic reasoning processes and drawing upon a long tradition of research in other disciplines.}
}
@article{YANG201616,
title = {The future nexus of the Brahmaputra River Basin: Climate, water, energy and food trajectories},
journal = {Global Environmental Change},
volume = {37},
pages = {16-30},
year = {2016},
issn = {0959-3780},
doi = {https://doi.org/10.1016/j.gloenvcha.2016.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0959378016300036},
author = {Y.C. Ethan Yang and Sungwook Wi and Patrick A. Ray and Casey M. Brown and Abedalrazq F. Khalil},
keywords = {The Yarlung Tsangpo River, The Jamuna River, Water resources systems analysis, Transboundary water management, Ex post scenario analysis},
abstract = {Advance knowledge of conflicting trajectories of water–energy–food (WEF) nexus is highly relevant for water policy and planning, especially for basins that cross national boundaries. The Brahmaputra River Basin in South Asia, home for 130 million people, is such a basin. Development of new hydropower projects, upstream water diversions and possible climate changes introduce concerns among riparian countries about future water supply for energy and food production in the basin. This study presents a new hydro-economic water system model of the basin coupled with ex post scenario analysis under the “nexus thinking” concept to identify and illustrate where development paths are in conflict. Results indicate that the ability of future development to remain free of conflict hinges mostly on the amount of precipitation falling in the basin in the future. Uncertain future precipitation along with uncertain future temperature and the unknown amount of upstream water diversion combine to strongly influence future water, energy and food production in the basin. Specifically, decreases in precipitation coupled with large upstream diversions (e.g., diversion in the territory of China) would leave one or more riparian countries unable to secure enough water to produce their desired energy and food. Future climate projected by General Circulation Models suggest a warmer and wetter climate condition in the region, which is associated with an increase in streamflow and easing of conflicts at the WEF nexus in the basin. The methodology presented here is expected to be generally useful for diagnosing the conditions that may cause water resources development goals to not be achieved due to either changes in climate or water use among competing users.}
}
@article{JARLEBLAD2024108930,
title = {A framework for synthetic diagnostics using energetic-particle orbits in tokamaks},
journal = {Computer Physics Communications},
volume = {294},
pages = {108930},
year = {2024},
issn = {0010-4655},
doi = {https://doi.org/10.1016/j.cpc.2023.108930},
url = {https://www.sciencedirect.com/science/article/pii/S0010465523002758},
author = {H. Järleblad and L. Stagner and M. Salewski and J. Eriksson and M. Nocente and B.S. Schmidt and M. {Rud Larsen}},
keywords = {Nuclear fusion, Fast ions, Orbits, Weight functions},
abstract = {In fusion plasma physics, the large-scale trajectories of energetic particles in magnetic confinement devices are known as orbits. To effectively and efficiently be able to work with orbits, the Orbit Weight Computational Framework (OWCF) was developed. The OWCF constitutes a set of scripts, functions and applications capable of computing, visualizing and working with quantities related to fast-ion (FI) orbits in toroidally symmetric fusion devices. The current version is highly integrated with the DRESS code, which enables the OWCF to compute and analyze the orbit sensitivity for arbitrary neutron- and gamma-diagnostics. However, the framework is modular in the sense that any future codes (e.g. FIDASIM) can be easily integrated. The OWCF can also compute projected velocity spectra for FI orbits, which play a key role in many FI diagnostics. Via interactive applications, the OWCF can function both as a tool for investigative research but also for teaching. The OWCF will be used to analyze and simulate the diagnostic results of current and future fusion experiments such as ITER. The orbit weight functions computed with the OWCF can be used to reconstruct the FI distribution in terms of FI orbits from experimental measurements using tomographic inversion.}
}
@article{MASHAL201366,
title = {Enhanced left frontal involvement during novel metaphor comprehension in schizophrenia: Evidence from functional neuroimaging},
journal = {Brain and Language},
volume = {124},
number = {1},
pages = {66-74},
year = {2013},
issn = {0093-934X},
doi = {https://doi.org/10.1016/j.bandl.2012.11.012},
url = {https://www.sciencedirect.com/science/article/pii/S0093934X12002155},
author = {N. Mashal and T. Vishne and N. Laor and D. Titone},
keywords = {Schizophrenia, Novel metaphors, Lateralization, Language, fMRI},
abstract = {The neural basis involved in novel metaphor comprehension in schizophrenia is relatively unknown. Fourteen people with schizophrenia and fourteen controls were scanned while they silently read novel metaphors, conventional metaphors, literal expressions, and meaningless word-pairs. People with schizophrenia showed reduced comprehension of both novel and conventional metaphors. Furthermore, while controls showed enhanced brain activation in right inferior frontal gyrus (IFG) for novel metaphors versus meaningless word-pairs, people with schizophrenia showed an over-activation of left IFG and middle frontal gyrus (MFG). Direct comparison between the groups revealed greater activation in left precuneus for both novel metaphors and literal expressions vs. baseline for individuals with schizophrenia. Direct comparison for novel metaphors vs. literal expressions also revealed increased activation for individuals with schizophrenia in left MFG. These results suggest that the inefficient processing of novel metaphors in schizophrenia involves compensatory recruitment of additional brain regions that include the left MFG and left precuneus.}
}
@article{LEUKHIN2018300,
title = {Bio-plausible simulation of three monoamine systems to replicate emotional phenomena in a machine},
journal = {Procedia Computer Science},
volume = {145},
pages = {300-305},
year = {2018},
note = {Postproceedings of the 9th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2018 (Ninth Annual Meeting of the BICA Society), held August 22-24, 2018 in Prague, Czech Republic},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.11.075},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918323639},
author = {Alexey Leukhin and Max Talanov and Jordi Vallverdú and Fail Gafarov},
keywords = {affective computing, affective computation, spiking neural networks, bio-inspired cognitive architecture},
abstract = {In this paper we present the validation of the three-dimensional model of emotions by Hugo Lövheim the “cube of emotion” via neurosimulation in the NEST. We also present the extension of original “cube of emotion” with the bridge to computational processes parameters. The neurosimulation is done via re-implementation of dopamine (DA), serotonin (5-HT) and noradrenaline (NA) subsystems of a rat brain to replicate 8 basic psycho-emotional states according to the “cube of emotion”. Results of neu-rosimulations indicate the incremental influence of DA and NA over computational resources of a psycho-emotional state while 5-HT decreases the computational resources used to calculate a psycho-emotional state. This way we indicate the feasibility of the bio-plausible re-implementation of psycho-emotional states in a computational system. This approach could be useful extension of decision making and load balancing components of modern artificial agents as well as intelligent robotic systems.}
}
@article{HU2023100795,
title = {A cardiologist-like computer-aided interpretation framework to improve arrhythmia diagnosis from imbalanced training datasets},
journal = {Patterns},
volume = {4},
number = {9},
pages = {100795},
year = {2023},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2023.100795},
url = {https://www.sciencedirect.com/science/article/pii/S2666389923001502},
author = {Lianting Hu and Shuai Huang and Huazhang Liu and Yunmei Du and Junfei Zhao and Xiaoting Peng and Dantong Li and Xuanhui Chen and Huan Yang and Lingcong Kong and Jiajie Tang and Xin Li and Heng Liang and Huiying Liang},
keywords = {arrhythmia, inter-class bullying, waveform clustering, heartbeat splicing, Bayesian approach},
abstract = {Summary
Arrhythmias can pose a significant threat to cardiac health, potentially leading to serious consequences such as stroke, heart failure, cardiac arrest, shock, and sudden death. In computer-aided electrocardiogram interpretation systems, the inclusion of certain classes of arrhythmias, which we term “aggressive” or “bullying,” can lead to the underdiagnosis of other “vulnerable” classes. To address this issue, a method for arrhythmia diagnosis is proposed in this study. This method combines morphological-characteristic-based waveform clustering with Bayesian theory, drawing inspiration from the diagnostic reasoning of experienced cardiologists. The proposed method achieved optimal performance in macro-recall and macro-precision through hyperparameter optimization, including spliced heartbeats and clusters. In addition, with increasing bullying by aggressive arrhythmias, our model obtained the highest average recall and the lowest average drop in recall on the nine vulnerable arrhythmias. Furthermore, the maximum cluster characteristics were found to be consistent with established arrhythmia diagnostic criteria, lending interpretability to the proposed method.}
}
@article{COLOMBO2016291,
title = {Analysing the connectivity and communication of suicidal users on twitter},
journal = {Computer Communications},
volume = {73},
pages = {291-300},
year = {2016},
note = {Online Social Networks},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2015.07.018},
url = {https://www.sciencedirect.com/science/article/pii/S014036641500256X},
author = {Gualtiero B. Colombo and Pete Burnap and Andrei Hodorog and Jonathan Scourfield},
keywords = {Social media, Social network analysis, Twitter, Computational social science, Suicide},
abstract = {In this paper we aim to understand the connectivity and communication characteristics of Twitter users who post content subsequently classified by human annotators as containing possible suicidal intent or thinking, commonly referred to as suicidal ideation. We achieve this understanding by analysing the characteristics of their social networks. Starting from a set of human annotated Tweets we retrieved the authors’ followers and friends lists, and identified users who retweeted the suicidal content. We subsequently built the social network graphs. Our results show a high degree of reciprocal connectivity between the authors of suicidal content when compared to other studies of Twitter users, suggesting a tightly-coupled virtual community. In addition, an analysis of the retweet graph has identified bridge nodes and hub nodes connecting users posting suicidal ideation with users who were not, thus suggesting a potential for information cascade and risk of a possible contagion effect. This is particularly emphasised by considering the combined graph merging friendship and retweeting links.}
}
@incollection{VANDERFORD2017105,
title = {Chapter 10 - Transferable Skills: How to Describe What You Really Know},
editor = {Teresa M. Evans and Natalie Lundsteen and Nathan L. Vanderford},
booktitle = {ReSearch},
publisher = {Academic Press},
pages = {105-118},
year = {2017},
isbn = {978-0-12-804297-7},
doi = {https://doi.org/10.1016/B978-0-12-804297-7.00010-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128042977000100},
author = {Nathan L. Vanderford},
keywords = {Alternative careers, Biomedical science, Career path, Communicating skills, Graduate student, Job market, Life science, Nontraditional career, PhD, Postdoc, Self-assessment, Transferable skills},
abstract = {Think beyond your label—years of academic life have pushed you to fine-tune a statement regarding your research interests that is short and to the point. It often starts with “I am a doctoral student in…” To hone your transferable skills, or the skills that are valued in research as well as other career areas, you have to break away from thinking about yourself in those terms. Prove that you can do the job even when you do not have direct job experience—you will do this by learning to think broadly and comprehensively about your transferable skills. Know how to identify your transferable skills. For everything that you have achieved in your life, there is an accompanying set of skills that will add value to you as a job applicant. Know how to describe them. Know how to portray your transferable skills in industry terms. There are phrases that resonate with key industries and organizations in their search for new recruits. Identify the correct terms to be understood in your chosen career field.}
}
@article{LIANG2022119384,
title = {Dynamic Causal Modelling of Hierarchical Planning},
journal = {NeuroImage},
volume = {258},
pages = {119384},
year = {2022},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2022.119384},
url = {https://www.sciencedirect.com/science/article/pii/S1053811922005031},
author = {Qunjun Liang and Jinhui Li and Senning Zheng and Jiajun Liao and Ruiwang Huang},
keywords = {Dynamic Causal Modelling (DCM), Parametric Empirical Bayes (PEB), fMRI, neural architecture, individual difference},
abstract = {Hierarchical planning (HP) is a strategy that optimizes the planning by storing the steps towards the goal (lower-level planning) into subgoals (higher-level planning). In the framework of model-based reinforcement learning, HP requires the computation through the transition value between higher-level hierarchies. Previous study identified the dmPFC, PMC and SPL were involved in the computation process of HP respectively. However, it is still unclear about how these regions interaction with each other to support the computation in HP, which could deepen our understanding about the implementation of plan algorithm in hierarchical environment. To address this question, we conducted an fMRI experiment using a virtual subway navigation task. We identified the activity of the dmPFC, premotor cortex (PMC) and superior parietal lobe (SPL) with general linear model (GLM) in HP. Then, Dynamic Causal Modelling (DCM) was performed to quantify the influence of the higher- and lower-planning on the connectivity between the brain areas identified by the GLM. The strongest modulation effect of the higher-level planning was found on the dmPFC→right PMC connection. Furthermore, using Parametric Empirical Bayes (PEB), we found the modulation of higher-level planning on the dmPFC→right PMC and right PMC→SPL connections could explain the individual difference of the response time. We conclude that the dmPFC-related connectivity takes the response to the higher-level planning, while the PMC acts as the bridge between the higher-level planning to behavior outcome.}
}
@article{BECK2017110,
title = {Can bootstrapping explain concept learning?},
journal = {Cognition},
volume = {158},
pages = {110-121},
year = {2017},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2016.10.017},
url = {https://www.sciencedirect.com/science/article/pii/S0010027716302578},
author = {Jacob Beck},
keywords = {Bootstrapping, Concept learning, Susan Carey, Concepts, Computational constraints},
abstract = {Susan Carey’s account of Quinean bootstrapping has been heavily criticized. While it purports to explain how important new concepts are learned, many commentators complain that it is unclear just what bootstrapping is supposed to be or how it is supposed to work. Others allege that bootstrapping falls prey to the circularity challenge: it cannot explain how new concepts are learned without presupposing that learners already have those very concepts. Drawing on discussions of concept learning from the philosophical literature, this article develops a detailed interpretation of bootstrapping that can answer the circularity challenge. The key to this interpretation is the recognition of computational constraints, both internal and external to the mind, which can endow empty symbols with new conceptual roles and thus new contents.}
}
@article{ENE20141110,
title = {Open Loop Reverse Supply Chain Network Design},
journal = {Procedia - Social and Behavioral Sciences},
volume = {109},
pages = {1110-1115},
year = {2014},
note = {2nd World Conference on Business, Economics and Management},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2013.12.596},
url = {https://www.sciencedirect.com/science/article/pii/S187704281305235X},
author = {Seval Ene and Nursel Öztürk},
keywords = {Supply chain management, open loop system, product recovery, network design, mathematical programming},
abstract = {Reverse supply chain management is a significant issue for sustainable economy, product recovery and green thinking. The purpose of this study is to contribute product recovery management by designing open loop reverse supply chain network. The main difference between open loop and closed loop reverse supply chain is in returning of used products. In a closed loop reverse supply chain, used products are generally returned to original producers. But in an open loop reverse supply chain, used products are not returned to original producers, outsider firms recover them. This paper presents a mathematical model for multi stage and multi period reverse supply chain network, which maximizes total profit of the network. The proposed model determines facility locations and material flows between stages in each period. Numerical experiments showed the applicability and efficiency of the model.}
}
@article{WANG2021102528,
title = {Automatic diagnosis of ECG disease based on intelligent simulation modeling},
journal = {Biomedical Signal Processing and Control},
volume = {67},
pages = {102528},
year = {2021},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2021.102528},
url = {https://www.sciencedirect.com/science/article/pii/S1746809421001257},
author = {Xu Wang and Runchuan Li and Shuhong Wang and Shengya Shen and Wenzhi Zhang and Bing Zhou and Zongmin Wang},
keywords = {Intelligent simulation modeling, Rule, ECG diseases, Diagnosis},
abstract = {In order to better assist doctors in diagnosing cardiovascular diseases, a set of end-to-end automatic diagnosis algorithms for ECG diseases based on intelligent simulation modeling are proposed. Firstly, wavelet transform and threshold method are used to denoise the ECG signal and locate the waveform in this paper. Secondly, waveform features are extracted. Finally, the rule method is used to convert the doctors’ thinking of diagnosing the disease into a description of the ECG characteristics of the disease to diagnose the ECG disease, and the algorithm is verified on the public database CCDD and the private data all-in-one machine data. The results show that this method is not inferior to the deep learning method. Now 11 types of diseases and 10 types of rhythm can be diagnosed.}
}
@article{PARIKH2024138,
title = {A comprehensive study on epigenetic biomarkers in early detection and prognosis of Alzheimer's disease},
journal = {Biomedical Analysis},
volume = {1},
number = {2},
pages = {138-153},
year = {2024},
issn = {2950-435X},
doi = {https://doi.org/10.1016/j.bioana.2024.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S2950435X24000167},
author = {Dhruv Parikh and Manan Shah},
keywords = {Alzheimer’s Disease, Biomarkers, Detection, Epigenetics},
abstract = {Alzheimer's Disease (AD) is a neurodegenerative disorder characterized by beta-amyloid plaques and tau tangles, disrupting brain cell communication, causing atrophy, and leading to cognitive decline. It poses a substantial global health challenge, necessitating urgent research. Molecular biomarkers, reflecting AD progression, have been identified in diverse bodily tissues. Notably, emerging epigenetic biomarkers introduce a novel dimension to AD pathophysiology. However, their precise role in early AD detection and prognosis remains unclear. This review classifies various epigenetic biomarkers, emphasizing their potential in early detection and prognosis. Various epigenetic biomarkers like DNA methylation, non-coding RNAs, histone modification, OMICS, and many more get significantly altered during AD; these biomarkers being distinctly expressed in normal conditions to AD offer a huge therapeutic benefit to stop the progression or worsening it. We explore the therapeutic implications and propose integration with existing diagnostic methods to intervene in AD progression, mitigating exacerbation. Addressing challenges, we envision the future scope of these biomarkers, emphasizing their synergy with computational approaches for enhanced AD detection. This review contributes to the field by proposing a multifaceted approach that combines epigenetic markers with computational analysis to improve early detection and facilitate timely therapeutic interventions. Furthermore, we discuss the economic implications of these biomarkers, proposing that their early application could significantly reduce the financial burden of AD by delaying the progression and severity of the disease.}
}
@article{BAILLIE1989209,
title = {A comparison of the CM with the DAP for lattice gauge theory},
journal = {Parallel Computing},
volume = {12},
number = {2},
pages = {209-220},
year = {1989},
issn = {0167-8191},
doi = {https://doi.org/10.1016/0167-8191(89)90054-9},
url = {https://www.sciencedirect.com/science/article/pii/0167819189900549},
author = {Clive F Baillie and G {Stuart Pawley}},
keywords = {Connection Machine, Distributed Array Processor, SIMD, massively parallel, lattice gauge theory, QED, QCD, performance measurement, performance analysis},
abstract = {Lattice gauge theory is one of the most challenging large-scale scientific computations; a state of the art calculation requires at least 1014 floating-point operations, necessitating the use of advanced architecture massively parallel computers such as the Connection Machine (CM) made by Thinking Machines Corporation (TMC), and the Distributed Array Processor (DAP) made in the past by International Computers Limited (ICL) and currently by active Memory Technology (AMT). The most important gauge theory to be solved is that descrining the sub-nuclear world of high energy physics: Quantum Chromodynamics (QCD). The simples example of a gauge theory is Quantum Electro-dynamics (QED), the theory which describes the interaction of electrons and photons. Simulation of QCD requires computer software very similar to that for the simpler QED problem. Thus, as a first step towards computer simulation of QCD, we have developed code for QED on the CM, and compared this with similar code for the DAP. Experience with the DAP allows us to predict performances for QCD code on the CM, showing the latter to be a very serious proposition for such large-scale scientific computations.}
}
@article{OSTLUND1985109,
title = {WATERLOPP V2/64: A highly parallel machine for numerical computation},
journal = {Computer Physics Communications},
volume = {37},
number = {1},
pages = {109-117},
year = {1985},
issn = {0010-4655},
doi = {https://doi.org/10.1016/0010-4655(85)90142-0},
url = {https://www.sciencedirect.com/science/article/pii/0010465585901420},
author = {Neil S. Ostlund},
abstract = {Current technological trends suggest that the high performance scientific machines of the future are very likely to consist of a large number (greater than 1024) of processors connected and communicating with each other in some as yet undetermined manner. Such an assembly of processors should behave as a single machine in obtaining numerical solutions to scientific problems. However, the appropriate way of organizing both the hardware and software of such an assembly of processors is an unsolved and active area of research. It is particularly important to minimize the organizational overhead of interprocessor comunication, global synchronization, and contention for shared resources if the performance of a large number (n) of processors is to be anything like the desirable n times the performance of a single processor. In many situations, adding a processor actually decreases the performance of the overall system since the extra organizational overhead is larger than the extra processing power added. The systolic loop architecture is a new multiple processor architecture which attemps at a solution to the problem of how to organize a large number of asynchronous processors into an effective computational system while minimizing the organizational overhead. This paper gives a brief overview of the basic systolic loop architecture, systolic loop algorithms for numerical computation, and a 64-processor implementation of the architecture, WATERLOOP V2/64, that is being used as a testbed for exploring the hardware, software, and algorithmic aspects of the architecture.}
}
@article{CRISTOFARO2020344,
title = {“I feel and think, therefore I am”: An Affect-Cognitive Theory of management decisions},
journal = {European Management Journal},
volume = {38},
number = {2},
pages = {344-355},
year = {2020},
issn = {0263-2373},
doi = {https://doi.org/10.1016/j.emj.2019.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0263237319301094},
author = {Matteo Cristofaro},
keywords = {Sensemaking, Decision making, Socially situated cognition, Affect, Cognition, Rationality, Behavioral strategy},
abstract = {I propose an Affect-Cognitive Theory to comprehensively understand how decisions occur in organizations. To this aim, I first review the assumptions of sensemaking and decision-making streams of research, especially the influence of bounded rationality, affective states and their relationships with cognition; then, I integrate them on the common basis of socially situated cognition. This new theory emphasizes the role of affective states in determining/being determined by cognition and its errors, pointing out decision makers’ affect as the result of multi-level adaptations to the physical and social environment. Management decisions are path dependent but not immutable; they, indeed, bank on the predominant feeling resulting from the modifying interactions and regulations of decision makers with their physical and social environment. Here, decision makers are proposed as “emotional cognizers” overcoming the thinking-feeling dichotomy that has often featured in the study of management decisions. This theory is beneficial for behavioral strategy, offering the needed assumptions to intertwine human cognition, emotions, and social behavior.}
}
@article{RANA201761,
title = {Dynamic effects in the didehydro‐Diels‐Alder (DDDA) reaction of enyne‐ketoenes: 50% stepwise bond formation in spite of concerted transition state††This article is published as part of a special issue to celebrate the 80th birthday of Professor Waldemar Adam},
journal = {Journal of Physical Organic Chemistry},
volume = {30},
number = {9},
pages = {61-67},
year = {2017},
issn = {0894-3230},
doi = {https://doi.org/10.1002/poc.3732},
url = {https://www.sciencedirect.com/science/article/pii/S0894323022014072},
author = {Anup Rana and Indrajit Paul and Michael Schmittel},
abstract = {The C2─C6/Diels‐Alder cyclization of enyne‐ketoene 1 was studied by experiments, theoretical calculations, and dynamic trajectory computations. The failure to trap possible intermediate(s), indicates a concerted reaction mechanism. A detailed search for stationary points revealed a concerted mechanism and surprisingly a diradical intermediate with no direct connection to the enyne‐ketoene 1. To probe the accessibility of this intermediate quasiclassical trajectories were initiated from the concerted transition state structure. Notably, 36% of the trajectories reach the product zone directly and 5% arrive at the product via the intermediate diradical. Additionally, 31% of the trajectories go to the intermediate zone and stay there within the simulation time limit.}
}
@article{ROBINSON2021,
title = {Development of the Organonitrogen Biodegradation Database: Teaching Bioinformatics and Collaborative Skills to Undergraduates during a Pandemic},
journal = {Journal of Microbiology & Biology Education},
volume = {22},
number = {1},
year = {2021},
issn = {1935-7877},
doi = {https://doi.org/10.1128/jmbe.v22i1.2351},
url = {https://www.sciencedirect.com/science/article/pii/S1935787721000745},
author = {Serina L. Robinson and Troy Biernath and Caleb Rosenthal and Dean Young and Lawrence P. Wackett and Betsy M. Martinez-Vaz},
abstract = {Physical distancing and inaccessibility to laboratory facilities created an opportunity to transition undergraduate research experiences to remote, digital platforms, adding another level of pedagogy to their training. Basic bioinformatics skills together with critical analysis of scientific literature are essential for addressing research questions in modern biology.
ABSTRACT
Physical distancing and inaccessibility to laboratory facilities created an opportunity to transition undergraduate research experiences to remote, digital platforms, adding another level of pedagogy to their training. Basic bioinformatics skills together with critical analysis of scientific literature are essential for addressing research questions in modern biology. The work presented here describes a fully online, collaborative research experience created to allow undergraduate students to learn those skills. The research experience was focused on the development and implementation of the Organonitrogen Biodegradation Database (ONDB, z.umn.edu/ondb). The ONDB was developed to catalog information about the cost, chemical properties, and biodegradation potential of commonly used organonitrogen compounds. A cross-institutional team of undergraduate researchers worked in collaboration with two faculty members and a postdoctoral fellow to develop the database. Students carried out extensive online literature searches and used a biodegradation prediction website to research and represent the microbial catabolism of different organonitrogen compounds. Participants employed computational tools such as R, Shiny, and flexdashboard to construct the database pages and interactive web interface for the ONDB. Worksheets and forms were created to encourage other students and researchers to gather information about organonitrogen compounds and expand the database. Student progress was evaluated through biweekly project meetings, presentations, and a final reflection. The ONDB undergraduate research experience provided a platform for students to learn bioinformatics skills while simultaneously developing a teaching and research tool for others.}
}
@article{CHRISTAKOU2014302,
title = {Present simple and continuous: Emergence of self-regulation and contextual sophistication in adolescent decision-making},
journal = {Neuropsychologia},
volume = {65},
pages = {302-312},
year = {2014},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2014.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S0028393214003133},
author = {Anastasia Christakou},
keywords = {Decision-making, Adolescence, Self-regulation, Corticostriatal circuits},
abstract = {Sophisticated, intentional decision-making is a hallmark of mature, self-aware behaviour. Although neural, psychological, interpersonal, and socioeconomic elements that contribute to such adaptive, foresighted behaviour mature and/or change throughout the life-span, here we concentrate on relevant maturational processes that take place during adolescence, a period of disproportionate developmental opportunity and risk. A brief, eclectic overview is presented of recent evidence, new challenges, and current thinking on the fundamental mechanisms that mature throughout adolescence to support adaptive, self-controlled decision-making. This is followed by a proposal for the putative contribution of frontostriatal mechanisms to the moment-to-moment assembly of evaluative heuristics that mediate increased decision-making sophistication, promoting the maturation of self-regulated behaviour through adolescence and young adulthood.}
}
@article{KRELLENSTEIN1987155,
title = {A reply to ”parallel computation and the mind-body problem”},
journal = {Cognitive Science},
volume = {11},
number = {2},
pages = {155-157},
year = {1987},
issn = {0364-0213},
doi = {https://doi.org/10.1016/S0364-0213(87)80003-4},
url = {https://www.sciencedirect.com/science/article/pii/S0364021387800034},
author = {Marc Krellenstein}
}
@article{SELIG2025105923,
title = {Using the kinematics of the RC linkage to find the degree of the adjoint representation of SE(3)},
journal = {Mechanism and Machine Theory},
volume = {206},
pages = {105923},
year = {2025},
issn = {0094-114X},
doi = {https://doi.org/10.1016/j.mechmachtheory.2025.105923},
url = {https://www.sciencedirect.com/science/article/pii/S0094114X25000126},
author = {J.M. Selig},
keywords = {Adjoint representation, Birational mappings, Study quadric, Assembly configurations},
abstract = {This work studies the projective algebraic variety formed from the closure of the adjoint representation of the group of rigid-body displacements, SE(3). This is motivated by asking how many assembly configurations a mechanism would have in general, if it was designed to keep six given lines in six linear line complexes. The main result is to find the degree of the variety defined by the adjoint representation and hence answer the motivating question. A simple special case is discussed, a mechanism that maintains a single given line reciprocal to three fixed lines from the regulus of a cylindrical hyperboloid of one sheet. The three dimensional variety defined in this way can be realised by an RC linkage. More specifically, the variety splits into two components each of which can be realised by an RC linkage. The homology of these 3-dimensional varieties, as subvarieties of the Study quadric, is found and used to determine the degree of the adjoint representation as an algebraic variety. The possible equations defining the variety determined by the adjoint representation of SE(3), are also discussed but no definitive result is found.}
}
@article{ACAR2016861,
title = {Soundscapes of Digital Morphogenesis in Architecture which Created from Musical Algorithm},
journal = {Procedia - Social and Behavioral Sciences},
volume = {216},
pages = {861-873},
year = {2016},
note = {Urban Planning and Architectural Design for Sustainable Development (UPADSD)},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2015.12.083},
url = {https://www.sciencedirect.com/science/article/pii/S1877042815062631},
author = {Didem Acar},
keywords = {Transcoding, Acoustic, Computational Design, Transdisciplinary framework, Architectural design},
abstract = {Music and architecture have made use of mathematical proportions throughout the history for the purpose of creating acoustic and visual forms. The reason for this is the aesthetic pursuit of both disciplines since centuries. Mathematics is one of the most important factors that influence aesthetic results. While forming their abstract aesthetic compositions the musicians use the musical notes that have definite frequency values. Each of these frequency values are defined by one integer. Every classical music artist uses the fractal sequencing of these frequencies. On the other hand we encounter hundreds of silent formats which are produced using mathematical ideas. In this context if we think of the interdisciplinary interaction between music and architecture no form is ever silent. In this study, the intersection of two disciplines will be examined in the perspective of architecture; a stumper and interrogative start for pursuit of architectural forms of the present day with the transformation of auditory forms to visual forms will be made; and a basis will be provided to be able to discuss the innovations that the spaces, structures and auditory experiences which can be formed by obtaining musical codes bring.}
}
@article{AYERS201861,
title = {A first step toward a practice-based theory of pedagogical content knowledge in secondary economics},
journal = {The Journal of Social Studies Research},
volume = {42},
number = {1},
pages = {61-79},
year = {2018},
issn = {0885-985X},
doi = {https://doi.org/10.1016/j.jssr.2017.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0885985X17300177},
author = {Cheryl A. Ayers},
keywords = {Secondary economic education, Pedagogical content knowledge, Horizon content knowledge, Specialized content knowledge, Knowledge of content and teaching, Knowledge of content and students},
abstract = {The purpose of this qualitative case study was to gain an in-depth understanding of how three award-winning secondary economics teachers demonstrated their pedagogical content knowledge (PCK), specifically horizon content knowledge, specialized content knowledge, knowledge of content and teaching, and knowledge of content and students. The teachers consistently connected economic content to other grades, subjects, and economic concepts and skills. Economic content was also regularly used to prepare students for citizenship, including casting more informed votes and understanding current events. However, authentic discussions, including ones about controversial issues, were mostly lacking. An emphasis was placed on developing students’ economic reasoning skills, including real-world applications of the economic way of thinking and decision-making models. Additionally, active learning instructional practices were frequently incorporated, and economic content was almost always related to students’ interests and experiences. A detailed description of a first step toward a practice-based theory of PCK in secondary economics concludes the article.}
}
@article{WANG2023120829,
title = {DBCT-Net:A dual branch hybrid CNN-transformer network for remote sensing image fusion},
journal = {Expert Systems with Applications},
volume = {233},
pages = {120829},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.120829},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423013313},
author = {Quanli Wang and Xin Jin and Qian Jiang and Liwen Wu and Yunchun Zhang and Wei Zhou},
keywords = {Image fusion, Convolutional neural network, Pansharpening, Transformer},
abstract = {Remote sensing image fusion aims at fusing high spatial resolution single-band panchromatic (PAN) image with spectrally informative multispectral (MS) image to generate panchromatic sharpened image with high resolution and color information, it is also called pansharpening. Most of the proposed single convolutional neural network (CNN) or transformer-based pansharpening methods own several problems, such as inability to acquire long-range features or difficult to train, resulting the loss of spatial details and colors. In addition, the computational complexity of transformer cannot be ignored. In this work, we propose a dual-branch hybrid CNN-Transformer network (DBCT-Net) that utilizes the local specificity of CNN and models the global dependencies by transformer. First, a multi-branch dense connected block (MDCB-4) network is designed to obtain spectral and textural information in MS and PAN images, respectively. Next, an encoder–decoder transformer based on the self-attention and co-attention modules is able to inject the missing local and global information, which can further enhance the results. It is worth noting that an inverted multi-head transposed attention (IMTA) is applied here to build attention maps from feature dimensions, which greatly reduces the computation time. Finally, an image reconstruction module is employed to effectively fuse the acquired texture and spectral features. Furthermore, to generate visually better pansharpened images, we propose a combined loss function that includes a focal frequency loss. Extensive experiments on WorldView II (WV2), GF-2,and QuickBird (QB) datasets show that DBCT-Net can perform better in spatial preservation and spectral feature recovery.}
}
@article{BALAKRISHNAN2025109810,
title = {Alzheimer's Disease detection and classification using optimized neural network},
journal = {Computers in Biology and Medicine},
volume = {187},
pages = {109810},
year = {2025},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2025.109810},
url = {https://www.sciencedirect.com/science/article/pii/S001048252500160X},
author = {Nair Bini Balakrishnan and Anitha S. Pillai and Jisha {Jose Panackal} and P.S. Sreeja},
keywords = {Recurrent neural network, Moth flame optimization, Deep reinforcement learning, Alzheimer's detection},
abstract = {Alzheimer's disease (AD) is a degenerative neurological condition characterized by a progressive decline in cognitive abilities, resulting in memory impairment and limitations in performing daily tasks. Timely and precise identification of AD holds paramount importance for prompt intervention and enhanced patient prognosis. In this research, a novel approach to AD mechanism was developed by combining Deep Reinforcement Learning (DRL) with a Moth Flame Optimized Recurrent Neural Network (MFORNN). Initially, the brain MRI samples are gathered and preprocessed to discard the noise features and to improve their quality. Consequently, the MFO algorithm captures and selects the most informative and highly correlative features from the preprocessed images, making it easier for Recurrent Neural Networks (RNNs) to learn the temporal dependencies and patterns differentiating normal and AD-affected images. The DRL component fine-tunes the parameters of RNN through its reward-based mechanism, ensuring that the classifier produces accurate outcomes and reduces computational complexity. The Python tool was utilized to implement the outlined framework, with the outcomes showcased that the designed algorithm attained an accuracy of 99.31 %, precision of 99.24 %, recall of 99.43 %, and f-measure of 99.35 %. Ultimately, a comparative analysis was performed against established classifier models, affirming the superior performance of the proposed technique over conventional algorithms.}
}
@article{VIJAYALAKSHMI2022103179,
title = {Predicting Hepatitis B to be acute or chronic in an infected person using machine learning algorithm},
journal = {Advances in Engineering Software},
volume = {172},
pages = {103179},
year = {2022},
issn = {0965-9978},
doi = {https://doi.org/10.1016/j.advengsoft.2022.103179},
url = {https://www.sciencedirect.com/science/article/pii/S0965997822000898},
author = {C. Vijayalakshmi and S. Pakkir Mohideen},
keywords = {Hepatitis B, Machine learning, SVM, Stochastic gradient algorithm, Dataset},
abstract = {Hepatitis B is a viral infection which causes liver damage. It can lead to death. This hepatitis B along with Hepatitis C can cause hepatocellular carcinoma and liver cirrhosis. In this paper it is discussed about Hepatitis B found positive in a person's blood test is acute or chronic. This research work plans to code an endurance forecast model for the dataset which contains the boundaries or data of Hepatitis-B patients. At first the information will be pre-prepared, to improve fit for additional handling and for being in satisfactory configuration for the calculations. At that point, several calculations to indicate the forecast and draw out the precision of the model. What's more, further contrast those calculations with indicate the calculation with most adequacy. The precision is determined by contrasting the anticipated result and ongoing result of the patient. In light of thinking about different boundaries, the model will anticipate the danger of a patient of his endurance rate of acute or chronic infected person accuracy. In this paper we use Stochastic Gradient algorithm to find the Co-connection between boundaries of the date set, kernel approximation to finalise the resulting accuracy of the acute or choric prediction of patients and SVM method we use to clustering the kernel approximation calculation and connection analysis.}
}
@article{HO2024124656,
title = {Unraveling the complexity of amorphous solid as direct ingredient for conventional oral solid dosage form: The story of Elagolix Sodium},
journal = {International Journal of Pharmaceutics},
volume = {665},
pages = {124656},
year = {2024},
issn = {0378-5173},
doi = {https://doi.org/10.1016/j.ijpharm.2024.124656},
url = {https://www.sciencedirect.com/science/article/pii/S0378517324008901},
author = {Raimundo Ho and Richard S. Hong and Joseph Kalkowski and Kevin C. Spence and Albert W. Kruger and Jayanthy Jayanth and Nandkishor K. Nere and Samrat Mukherjee and Ahmad Y. Sheikh and Shailendra V. Bordawekar},
keywords = {Amorphous drug substance, Impinging jet precipitation, Scale-up, Glass transition, Microstructure, Physical property control, Multi-scale modeling},
abstract = {Conventional solid oral dosage form development is not typically challenged by reliance on an amorphous drug substance as a direct ingredient in the drug product, as this may result in product development hurdles arising from process design and scale-up, control of physical quality attributes, drug product processability and stability. Here, we present the Chemistry, Manufacturing and Controls development journey behind the successful commercialization of an amorphous drug substance, Elagolix Sodium, a first-in-class, orally active gonadotropin-releasing hormone antagonist. The reason behind the lack of crystalline state was assessed via Molecular Dynamics (MD) at the molecular and inter-molecular level, revealing barriers for nucleation due to prevalence of intra-molecular hydrogen bond, repulsive interactions between active pharmaceutical ingredient (API) molecules and strong solvation effects. To provide a foundational basis for the design of the API manufacturing process, we modeled the solvent-induced plasticization behavior experimentally and computationally via MD for insights into molecular mobility. In addition, we applied material science tetrahedron concepts to link API porosity to drug product tablet compressibility. Finally, we designed the API isolation process, incorporating computational fluid dynamics modeling in the design of an impinging jet mixer for precipitation and solvent-dependent glass transition relationships in the cake wash, blow-down and drying process, to enable the consistent manufacture of a porous, non-sintered amorphous API powder that is suitable for robust drug product manufacturing.}
}
@article{POLHILL2023103121,
title = {Cognition and hypocognition: Discursive and simulation-supported decision-making within complex systems},
journal = {Futures},
volume = {148},
pages = {103121},
year = {2023},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2023.103121},
url = {https://www.sciencedirect.com/science/article/pii/S0016328723000253},
author = {J. Gareth Polhill and Bruce Edmonds},
keywords = {Simulation, Cognition, Hypocognition, Divination, Ecocyborgs, Blasphemy},
abstract = {Homo sapiens is currently believed to have evolved in the African savannah several hundreds of thousands of years ago. Since then, human societies have become, through technological innovation and application, powerful influencers of the planet’s ecological, hydrological and meteorological systems – for good and ill. They have experimented with many different systems of governance, in order to manage their societies and the environments they inhabit – using computer simulations as a tool to help make decisions concerning highly complex systems, is only the most recent of these. In questioning whether, when and how computer simulations should play a role in determining decision-making in these systems of governance, it is also worth reflecting on whether, when and how humans, or groups of humans, have the capability to make such decisions without the aid of such technology. This paper looks at and compares the characteristics of natural language-based and simulation-based decision-making. We argue that computational tools for decision-making can and should be complementary to natural language discourse approaches, but that this requires that both systems are used with their limitations in mind. All tools and approaches – physical, social and mental – have dangers when used inappropriately, but it seems unlikely humankind can survive without them. The challenge is how to do so.}
}
@article{WIERZBICKI2007610,
title = {Modelling as a way of organising knowledge},
journal = {European Journal of Operational Research},
volume = {176},
number = {1},
pages = {610-635},
year = {2007},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2005.08.018},
url = {https://www.sciencedirect.com/science/article/pii/S0377221705007010},
author = {Andrzej P. Wierzbicki},
keywords = {OR in research and development, Knowledge-based systems, Mathematical modelling, Knowledge management, Hard and soft systems approaches, Tacit knowledge and intuition, Epistemology},
abstract = {The paper is motivated by the need of to address a new the old topic of operational research and hard (but also soft) systems science: what is the role of mathematical modelling, how does it relate to knowledge, to creativity, to human concerns? Such a need arises because of the great change observed today, of informational revolution, of transition towards knowledge-based economy, towards networked organization of our social and economic life. During last 50years operational research, mathematical modelling and computerised techniques of model analysis and optimisation contributed essentially to the change of perception of contemporary world, characteristic for the current informational revolution indicating the change of civilisation eras. These contributions have been noted during these years inside operational research, but analysed mostly from so-called soft systems thinking perspective. Main contributions to the actual formation of the new era, however, came from the hard systems research, in particular, as we shall show, from mathematical modelling in applications to the development of technological systems. The new civilisation era of information and knowledge-based economy started around 1980. It is a long duration historical era, characterised by a new way of understanding the world. This understanding is systemic and chaotic; in particular, it assumes the emergence of qualitatively new properties of complex systems on higher layers of complexity, which cannot be reduced to the properties of system components. On this background, it is necessary to reflect a new on the theory of knowledge. The paper presents a discussion of the concept of knowledge from several perspectives, such as the perspective of operational research, of systems science, of mathematical modelling, of knowledge-based economy, of knowledge engineering and knowledge management, of interactive model-based decision support. The human-centred development of informational technology necessitates a re-appraisal of soft systems approaches; their values and limitations are discussed. Additionally, a rational theory of intuition is recalled to show its relation with the concept of tacit knowledge, of knowledge creation and with harmonious approaches to knowledge characterising Far East philosophy as well as Japanese approaches to knowledge management and creation. Epistemological conclusions from the rational theory of intuition are discussed, including a new concept of micro-theories of knowledge creation and the concept of Creative Space.}
}
@article{SHEKHAR2024820,
title = {Topological data analysis enhanced prediction of hydrogen storage in metal–organic frameworks (MOFs)††Electronic supplementary information (ESI) available: Figure showing the effect of training set size. See DOI: https://doi.org/10.1039/d3ma00591g},
journal = {Materials Advances},
volume = {5},
number = {2},
pages = {820-830},
year = {2024},
issn = {2633-5409},
doi = {https://doi.org/10.1039/d3ma00591g},
url = {https://www.sciencedirect.com/science/article/pii/S2633540924000550},
author = {Shivanshu Shekhar and Chandra Chowdhury},
abstract = {Metal–organic frameworks (MOFs) have the capacity to serve as gas capturing, sensing, and storing systems. It is usual practice to select the MOF from a vast database with the best adsorption property in order to do an adsorption calculation. The costs of computing thermodynamic values are sometimes a limiting factor in high-throughput computational research, inhibiting the development of MOFs for separations and storage applications. In recent years, machine learning has emerged as a promising substitute for traditional methods like experiments and simulations when trying to foretell material properties. The most difficult part of this process is choosing characteristics that produce interpretable representations of materials that may be used for a variety of prediction tasks. We investigate a feature-based representation of materials using tools from topological data analysis. In order to describe the geometry of MOFs with greater accuracy, we use persistent homology. We show our method by forecasting the hydrogen storage capacity of MOFs during a temperature and pressure swing from 100 bar/77 K to 5 bar/160 K, using the synthetically compiled CoRE MOF-2019 database of 4029 MOFs. Our topological descriptor is used in conjunction with more conventional structural features, and their usefulness to prediction tasks is explored. In addition to demonstrating significant progress over the baseline, our findings draw attention to the fact that topological features capture information that is supplementary to the structural features.}
}
@article{COIERA2007S98,
title = {Putting the technical back into socio-technical systems research},
journal = {International Journal of Medical Informatics},
volume = {76},
pages = {S98-S103},
year = {2007},
note = {Information Technology in Health Care: Sociotechnical Approaches},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2006.05.026},
url = {https://www.sciencedirect.com/science/article/pii/S1386505606001481},
author = {Enrico Coiera},
keywords = {Human–computer interaction, Information system design, Information system evaluation, Socio-technical systems},
abstract = {Socio-technical systems (STS) analysis has provided us with a powerful framework with which to analyse the reasons behind the poor acceptability, uptake and performance of many information or communication technology systems (ICT). However, for the contribution of STS thinking to be more than simply a means of critiquing current practices and ICT systems, it needs to also contribute to the process of developing new and more effective ICT systems. Specifically, we need to develop a formal design language for translating our insights about the socio-technical nature of work, into design specifications that result in better interventions in the work place. We need to get ‘technical’ about what we mean and about what we want from a design, and we need to work alongside technologists to shape technology, as well as the processes, organisations and cultures within which they will be embedded. Indeed the process of design itself can be seen as a socio-technical one, and understanding the decision to design itself may allow us one day to stop designing for people, and create STS that sustainably design themselves.}
}
@article{TEMPL20249,
title = {Advancing forensic research: An examination of compositional data analysis with an application on petrol fraud detection},
journal = {Science & Justice},
volume = {64},
number = {1},
pages = {9-18},
year = {2024},
issn = {1355-0306},
doi = {https://doi.org/10.1016/j.scijus.2023.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1355030623001223},
author = {M. Templ and J. Gonzalez-Rodriguez},
keywords = {Forensic science, Petrol data, Chemical compounds, Compositional data analysis, Classification},
abstract = {In recent years, numerous studies have examined the chemical compounds of petrol and petrol data for forensic research. Standard quantitative methods often assume that the variables or compounds do not have compositional constraints or are not part of a constrained whole, operating within an Euclidean vector space. However, chemical compounds are typically part of a whole, and the appropriate vector space for their analysis is the simplex. Biased and arbitrary results result when statistical analysis are applied on such data without proper pre-processing of such data. Compositional analysis of data has not yet been considered in forensic science. Therefore, we compare classical statistical analysis as applied in forensic research and the new proposed paradigm of compositional data analysis (CoDa). It is demonstrated how such analysis improves the analysis in petrol and forensic science. Our study shows how principal component analysis (PCA) and classification results are affected by the preprocessing steps performed on the raw data. Our results indicate that results from a log ratio analysis provides a better separation between subgroups of the data and leads to an easier interpretation of the results. In addition, with a compositional analysis a higher classification accuracy is obtained. Even a non-linear classification method - in our case a random forest - was shown to perform poorly when applied without using compositional methods. Moreover, normalization of samples due to laboratory/unit-of-measurement effects is no longer necessary, since the composition of an observation is in compositional thinking equivalent to a multiple of it, because the used (log) ratios on raw and log ratio transformed data are equal. Petrol data from different petrol stations in Brazil are used for the demonstration. This data is highly susceptible to counterfeit petrol. Forensic analysis of its chemical elements requires non-biased statistical analysis designed for compositional data to detect fraud. Based on these results, we recommend the use of compositional data methods for gasoline and petrol chemical element analysis and gasoline product characterization, authentication and fraud detection in forensic sciences.}
}
@article{TRAN2019284,
title = {Creating material data for thermoset injection molding simulation process},
journal = {Polymer Testing},
volume = {73},
pages = {284-292},
year = {2019},
issn = {0142-9418},
doi = {https://doi.org/10.1016/j.polymertesting.2018.11.042},
url = {https://www.sciencedirect.com/science/article/pii/S0142941818316295},
author = {Ngoc Tu Tran and Michael Gehde},
keywords = {Thermoset injection molding, Reactive viscosity and cure kinetics model, Thermoset material data, Reactive injection molding simulation, Wall slip boundary condition},
abstract = {Thermoset material data for reactive injection molding simulation process is found in limited sources and seldom available from data bank of simulation tools because of complication not only in rheological and thermal properties measurement but also in writing optimization algorithm to model rheological and thermal mathematical equations. In this paper, rheological and thermal properties of thermoset injection molding compounds were successfully measured. In addition, a numerical method was developed to create material data of thermoset injection molding compounds, which was directly imported into a simulation tool, namely, Moldex3D to investigate its application in thermoset injection molding simulation process. Furthermore, a strong slip phenomenon on the interface between thermoset melt and wall surface which was investigated and detected during injection molding experiments was taken into account in the filling simulation process. The computation was found to be in good agreement with the experimental results, indicating that the new generated material data is reasonable and the influence of wall slip on the mold filling characterization of thermoset injection compounds during simulation process is not ignorable.}
}
@article{YEUNG2024104999,
title = {A systematic review of Drone integrated STEM education at secondary schools (2005–2023): Trends, pedagogies, and learning outcomes},
journal = {Computers & Education},
volume = {212},
pages = {104999},
year = {2024},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2024.104999},
url = {https://www.sciencedirect.com/science/article/pii/S0360131524000137},
author = {Richard Chung Yiu Yeung and Chi Ho Yeung and Daner Sun and Chee-Kit Looi},
keywords = {Systematic review, Drone-integrated learning, STEM education, Secondary schools},
abstract = {As the prominence of drone technology continues to captivate interest for its myriad applications in education, an understanding of the current status of drone-integrated education becomes imperative. This systematic review endeavors to furnish an updated and comprehensive analysis of the drone education studies across academic levels, with a specific emphasis on secondary education settings. To accomplish this objective, a review study with 181 publications was conducted, with a particular focus on 41 publications explicitly addressing the integration of drones in secondary STEM education. Employing a systematic approach, this review identifies, analyzes, and synthesizes pertinent literature, ensuring a thorough comprehension of the current state of the field. The key findings of this review can be summarized as follows: 1) Among the diverse array of subjects incorporating drones, STEM disciplines emerge as the most prominently featured. 2) Experiential and project-based learning stand out as the most commonly adopted pedagogical methods in drone-integrated STEM education. The incorporation of teamwork and hands-on activities is frequently cited as instructional strategies aimed at enhancing drone-integrated STEM learning experiences. 3) Beyond the acquisition of drone-related technical skills, the reported learning outcomes encompass a spectrum of aspects, including heightened STEM career awareness, increased engagement and learning interest, and collaborative problem-solving abilities. The findings underscore the potential of drones to ignite passion for STEM subjects among secondary students, achieved through interdisciplinary, hands-on applications that foster problem-solving and design competencies.}
}
@article{WANG201837,
title = {Linguistic terms with weakened hedges: A model for qualitative decision making under uncertainty},
journal = {Information Sciences},
volume = {433-434},
pages = {37-54},
year = {2018},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2017.12.036},
url = {https://www.sciencedirect.com/science/article/pii/S0020025517311593},
author = {Hai Wang and Zeshui Xu and Xiao-Jun Zeng},
keywords = {Decision making, Linguistic hedges, Linguistic term sets, Multi-granularity linguistic decision making, Semantics},
abstract = {When expressing the experts’ opinions in qualitative decision making (QDM), linguistic hedges can be considered to modify the force expressed by a predefined linguistic term. If an expert is not sure to select one term, weakened hedges would be a natural way to express the uncertainty. This is usually implemented by using a hedge to modify the most possible term, like the expression “more or less good”. To model the uncertainty implied by hedges in QDM, this paper presents a novel linguistic representational and computational model in which the linguistic expressions take the form of a weakened hedge and a linguistic term, which is named as linguistic term with weakened hedge (LTWH). The syntax of LTWHs is defined by a set of hedges and a set of linguistic terms. The semantics of a LTWH is determined, objectively, based on the semantics of the term and a similarity measure of the reference domain. Accordingly, the negation, order relations and some basic operations of LTWHs are defined. To illustrate the effectiveness of LTWHs in granular computing, the connection to some multi-granularity linguistic models is exploited and a process for unifying multi-granularity linguistic information is developed. The major contritions of this paper are: (1) The proposed model enables a new manner to express and operate uncertain linguistic information in QDM; (2) it possesses clear syntax and semantics and the computational results are very interpretable; and (3) the proposed solution of multi-granularity linguistic unification maintains the semantics of the original linguistic information.}
}
@article{YAN2025129868,
title = {SPRInT: Scaling Programmatic Reasoning for INstruction Tuning in mathematics},
journal = {Neurocomputing},
volume = {634},
pages = {129868},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.129868},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225005405},
author = {Yan Yan and Lin Li and Bo-Wen Zhang},
keywords = {Programmatic mathematical reasoning, Data augmentation, Data synthesis, Decoupled numeric dependencies, Logical inconsistencies},
abstract = {We present SPRInT, a novel approach for large-scale, cost-effective synthesis of instruction-tuning datasets, leveraging Program-of-Thoughts (PoT) to enhance mathematical reasoning capabilities. Through the SPRInT framework, we synthesized data from seven high-quality open-source math datasets (including GSM8K, MATH, AQuA), and developed InfinityMATH-a dataset containing over 100,000 samples generated from QA pairs, offering extensive coverage across various mathematical domains. The SPRInT model series, fine-tuned on InfinityMATH using open-source language and code models such as Llama2-7B, Mistral-7B, and CodeLlama-7B, achieved remarkable improvements in mathematical reasoning, with performance gains between 184.7% and 514.3%. In zero-shot settings, our SPRInT-CodeLlama-7B model surpassed MAmmoTH-Coder on widely-used benchmarks, including GSM8K (65.80% vs. 56.86%) and MATH (34.06% vs. 29.88%). To assess logical consistency in numerical transformations, we created the GSM8K+ and MATH＋ test sets by modifying the numerical values in the original datasets. While traditional models struggled with these alterations, the SPRInT models exhibited superior robustness. The InfinityMATH dataset is publicly available at https://huggingface.co/datasets/BAAI/InfinityMATH.}
}
@incollection{SUKHAI2017249,
title = {22 - Simulation learning},
editor = {Mahadeo A. Sukhai and Chelsea E. Mohler},
booktitle = {Creating a Culture of Accessibility in the Sciences},
publisher = {Academic Press},
pages = {249-255},
year = {2017},
isbn = {978-0-12-804037-9},
doi = {https://doi.org/10.1016/B978-0-12-804037-9.00022-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012804037900022X},
author = {Mahadeo A. Sukhai and Chelsea E. Mohler},
keywords = {Simulation learning, accommodation, teaching tool, computer technology, application of best practices},
abstract = {Simulation learning can be a valuable tool deployed in support of the learning of students with disabilities in the sciences. In thinking about simulation learning, we must consider two scenarios: (1) When simulation learning will benefit a student with a disability, because other accommodation methods are not appropriate or feasible; and, (2) When simulation learning is applied to all students, where accessibility considerations of the simulation must be taken into account for students with disabilities in the class. In this chapter, we will review the application of both scenarios for simulation learning to students with disabilities in the sciences.}
}
@incollection{EDELMAN2015596,
title = {Marr, David (1945–80)},
editor = {James D. Wright},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {596-598},
year = {2015},
isbn = {978-0-08-097087-5},
doi = {https://doi.org/10.1016/B978-0-08-097086-8.61085-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780080970868610851},
author = {Shimon Edelman and Lucia M Vaina},
keywords = {Biological information processing, Brain function, Cognitive psychology, Computational theory and modeling, Neuroscience, Scientific methodology, Vision},
abstract = {David Courtnay Marr was born in 1945 in Essex, England. Marr's dissertation, written at Trinity College, Cambridge and published between 1969 and 1971, presented a theory of mammalian brain function, parts of which remain relevant to the present day, despite vast advances in neurobiology in the past decades. In 1973, Marr joined the Artificial Intelligence Laboratory at the Massachusetts Institute of Technology, where he was made a tenured full professor in 1980. Marr died in November 1980, of leukemia. His highly influential book, Vision: A Computational Investigation into the Human Representation and Processing of Visual Information, which has redefined and revitalized the study of human and machine vision, was published posthumously, in 1982, with a new edition appearing in 2010.}
}
@article{JADHAV2022127935,
title = {Scale-up of the bioelectrochemical system: Strategic perspectives and normalization of performance indices},
journal = {Bioresource Technology},
volume = {363},
pages = {127935},
year = {2022},
issn = {0960-8524},
doi = {https://doi.org/10.1016/j.biortech.2022.127935},
url = {https://www.sciencedirect.com/science/article/pii/S0960852422012688},
author = {Dipak A. Jadhav and Ashvini D. Chendake and Vandana Vinayak and Abdulaziz Atabani and Mohammad {Ali Abdelkareem} and Kyu-Jung Chae},
keywords = {Energy balance, Microbial electrochemical technology, Net energy recovery, Normalization of performance, Resource recovery, Techno-economic feasibility},
abstract = {Electrochemists and ecological engineers find environmental bioelectrochemistry appealing; however, there is a big gap between expectations and actual progress in bioelectrochemical system (BES). Implementing such technology opens new opportunities for novel electrochemical reactions for resource recovery and effective wastewater treatment. Loopholes of BES exist in its scaling-up applications, and numerous attempts toward practical applications (200, 1000, and 1500 L) are key successive indicators toward its commercialization. This review emphasized the critical rethinking of standardization of performance indices i.e. current generation (A/m2), net energy recovery (kWh/kg·COD), product/resource yield (mM), and economic feasibility ($/kWh) to make fair comparison with the existing treatment system. Therefore, directional perspectives, including modularity, energy-cost balance, energy and resource recovery, have been proposed for the sustainable market of BES. The current state of the art and up-gradation in resource recovery and contaminant removal warrants a systematic rethinking of functional worth and niches of BES for practical applications.}
}
@article{MAHMOUD202263,
title = {Where to from here? On the future development of autonomous vehicles from a cognitive systems perspective},
journal = {Cognitive Systems Research},
volume = {76},
pages = {63-77},
year = {2022},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2022.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S1389041722000444},
author = {Sara Mahmoud and Erik Billing and Henrik Svensson and Serge Thill},
keywords = {Artificial cognition, Self-driving cars, Cognitive paradigms},
abstract = {Self-driving cars not only solve the problem of navigating safely from location A to location B; they also have to deal with an abundance of (sometimes unpredictable) factors, such as traffic rules, weather conditions, and interactions with humans. Over the last decades, different approaches have been proposed to design intelligent driving systems for self-driving cars that can deal with an uncontrolled environment. Some of them are derived from computationalist paradigms, formulating mathematical models that define the driving agent, while other approaches take inspiration from biological cognition. However, despite the extensive work in the field of self-driving cars, many open questions remain. Here, we discuss the different approaches for implementing driving systems for self-driving cars, as well as the computational paradigms from which they originate. In doing so, we highlight two key messages: First, further progress in the field might depend on adapting new paradigms as opposed to pushing technical innovations in those currently used. Specifically, we discuss how paradigms from cognitive systems research can be a source of inspiration for further development in modelling driving systems, highlighting emergent approaches as a possible starting point. Second, self-driving cars can themselves be considered cognitive systems in a meaningful sense, and are therefore a relevant, yet underutilized resource in the study of cognitive mechanisms. Overall, we argue for a stronger synergy between the fields of cognitive systems and self-driving vehicles.}
}
@article{WANG2024109848,
title = {An effective DOA estimation method for low SIR in small-size hydrophone array},
journal = {Applied Acoustics},
volume = {217},
pages = {109848},
year = {2024},
issn = {0003-682X},
doi = {https://doi.org/10.1016/j.apacoust.2023.109848},
url = {https://www.sciencedirect.com/science/article/pii/S0003682X23006461},
author = {Wenbo Wang and Ye Li and TongSheng Shen and Feng Liu and DeXin Zhao},
abstract = {The estimation ability of traditional direction of arrival (DOA) estimation methods is relatively fragile in small-size hydrophone arrays with limited space. Especially in low signal to interference ratio (SIR), the strong interference signals may submerge some weak signals of interest (SOI) and make DOA estimation difficult in response to this issue. This paper introduces an improved sparse DOA estimation method for practical multi-objective DOA estimation in complex scenarios. The main work is to introduce a noise weight constraint in the sparse iterative covariance process. It leads the algorithm to output sparse peaks and smooth spatial energy spectra and achieve faster fitting while reducing the probability of false peaks. The algorithm can complete DOA estimation of the multi-target reliably without prior information of sources. Then, we propose a fast region grid refinement method based on allocation reconstruction to increase angle resolution. The method increases the accuracy of multi-objective DOA estimation while reducing computational costs. Finally, simulation and experiment have verified the method's effectiveness.}
}
@article{THEOFILIDIS2024219,
title = {Mental Imagery: Investigating the Limits of Mental Partitioning},
journal = {Revista Colombiana de Psiquiatría (English ed.)},
volume = {53},
number = {3},
pages = {219-228},
year = {2024},
issn = {2530-3120},
doi = {https://doi.org/10.1016/j.rcpeng.2024.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S2530312024000602},
author = {Antonios Theofilidis and Maria-Valeria Karakasi and Filippos Kargopoulos},
keywords = {Mental imagery, Mental partitioning, Memory, Cognition, Neuroscience, Imaginería mental, Partición mental, Memoria, Cognición, Neurociencia},
abstract = {Introduction
Do we form mental models which bear an analogical relation to the real world like those of a photograph? Has the language of thought an analogue nature (it makes use of mental imagery) or whether it is exclusively of digital nature like language?
Objectives
The basic aim of the present study is to contribute to the ongoing work on mental imagery by extending the research to an unexplored area that of mental partitioning.
Methods
The present research sample consisted of 498 participants (234 males and 264 females). We used the SPSS software package in order to analyze our data.
Results
According to our results, we detected significant peculiarities in the cognitive performance of the participants in the tasks of mental partitioning of the Moebius strip, indicating certain limitations inherent in human thinking.
Conclusions
The position we are led to adopt is closer to that of Pylyshyn (2003), who maintained that visual mental imagery depends on abstract form of thought and on previous knowledge. Specifically, it rests on previous abstract propositional thought and knowledge rather than on concrete perceptual processes like the ones proposed by Kosslyn and Sheppard. The present work investigates a potentially valuable theoretical basis in imagery research for understanding maladaptive imagery across various related clinical disorders, while encouraging multidisciplinary approaches among cognitive psychological/neuroscientific and clinical domains.
Resumen
Introducción
¿Formamos modelos mentales que guardan una relación analógica con el mundo real como los de una fotografía? ¿Tiene el lenguaje del pensamiento una naturaleza analógica (hace uso de imágenes mentales) o es exclusivamente de naturaleza digital como el lenguaje?
Objetivos
El objetivo básico del presente estudio es contribuir al trabajo en curso sobre la imaginería mental extendiendo la investigación a un área inexplorada que es la partición mental.
Métodos
La muestra de la presente investigación estuvo compuesta por 498 participantes (234 varones y 264 mujeres). Usamos el paquete de software SPSS® para analizar nuestros datos.
Resultados
De acuerdo con nuestros resultados, detectamos peculiaridades significativas en el desempeño cognitivo de los participantes en las tareas de partición mental de la tira de Moebius, indicando ciertas limitaciones inherentes al pensamiento humano.
Conclusiones
La posición a la que nos vemos llevados a adoptar se acerca más a la de Pylyshyn (2003), quien sostenía que la imaginería mental visual depende de formas abstractas de pensamiento y de conocimientos previos. Específicamente, se basa en el pensamiento y el conocimiento proposicionales abstractos previos más que en procesos de percepción concretos como los propuestos por Kosslyn y Sheppard. El presente trabajo investiga una base teórica potencialmente valiosa en la investigación de imágenes para comprender las imágenes desadaptativas en varios trastornos clínicos relacionados, al tiempo que fomenta enfoques multidisciplinarios entre los dominios cognitivos psicológicos/neurocientíficos y clínicos.}
}
@article{CHIU2024100282,
title = {Developing and validating measures for AI literacy tests: From self-reported to objective measures},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100282},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100282},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000857},
author = {Thomas K.F. Chiu and Yifan Chen and King Woon Yau and Ching-sing Chai and Helen Meng and Irwin King and Savio Wong and Yeung Yam},
keywords = {AI literacy, Instrument, K-12 education, AI education, Co-design process, Measures},
abstract = {The majority of AI literacy studies have designed and developed self-reported questionnaires to assess AI learning and understanding. These studies assessed students' perceived AI capability rather than AI literacy because self-perceptions are seldom an accurate account of true measures. International assessment programs that use objective measures to assess science, mathematical, digital, and computational literacy back up this argument. Furthermore, because AI education research is still in its infancy, the current definition of AI literacy in the literature may not meet the needs of young students. Therefore, this study aims to develop and validate an AI literacy test for school students within the interdisciplinary project known as AI4future. Engineering and education researchers created and selected 25 multiple-choice questions to accomplish this goal, and school teachers validated them while developing an AI curriculum for middle schools. 2390 students in grades 7 to 9 took the test. We used a Rasch model to investigate the discrimination, reliability, and validity of the items. The results showed that the model met the unidimensionality assumption and demonstrated a set of reliable and valid items. They indicate the quality of the test items. The test enables AI education researchers and practitioners to appropriately evaluate their AI-related education interventions.}
}
@article{KHAN2024e31470,
title = {Catch-up growth with alpha and beta decoupling and their relationships between CO2 emissions by GDP, population, energy production, and consumption},
journal = {Heliyon},
volume = {10},
number = {11},
pages = {e31470},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e31470},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024075017},
author = {Rabnawaz Khan},
keywords = {Economic growth, Alpha and beta decoupling, CO emissions, Energy production and consumption, Populace},
abstract = {This study explores the relationship between CO2 emissions by GDP, population, energy production, and consumption in the United States, China, Romania, and Thailand economies from 1990 to 2019. It evaluates the phenomenon of catch-up growth, which transpires when an lagging economy goes through an expansionary phase after a period of below-average performance. We used the stochastic model to illustrate in terms of alpha and beta decoupling techniques. The outcomes validated by positive and negative decoupling attitudes play a crucial role in predicting a rise in CO2 emissions owing to oil, gas, and coal use in comparison to Romania. Thailand and Romania have a more viable road to sustainability than the United States and China. The United States and China appear to have an antagonistic relationship, as suggested by decoupling attitudes. Thailand and Romania are considered to be highly environmentally sustainable countries on account of their minimal carbon emissions, efficient energy usage, and forward-thinking environmental policies. Accordingly, policy recommendations are offered based on CO2 emissions and effective mitigation policies, since this allows for determining which countries with high emissions need technological advances, best practices, and intersectoral policies.}
}
@article{ALLISON2018147,
title = {Dilemmas of modelling and decision-making in environmental research},
journal = {Environmental Modelling & Software},
volume = {99},
pages = {147-155},
year = {2018},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2017.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S1364815217300749},
author = {Andrew E.F. Allison and Mark E. Dickson and Karen T. Fisher and Simon F. Thrush},
keywords = {Wicked problems, Agent-based modelling, Post-normal science, Social-ecological systems, Shallow coastal systems},
abstract = {Multiple dilemmas confound social-ecological modelling. This review paper focuses on two: a modeller's dilemma associated with determining appropriate levels of model simplification, and a dilemma of decision-making relating to the use of models that were never designed to predict. We analyse approaches for addressing these dilemmas as they relate to shallow coastal systems and conclude that wicked problems cannot be adequately addressed using traditional disciplinary or systems engineering modelling. Simplified inter- and trans-disciplinary models have the potential to identify directions of system change, challenge thinking in disciplinary silos, and ultimately confront the dilemmas of social-ecological modelling.}
}
@article{TANTILLO2021n/a,
title = {Dynamic effects on organic reactivity—Pathways to (and from) discomfort},
journal = {Journal of Physical Organic Chemistry},
volume = {34},
number = {6},
pages = {n/a},
year = {2021},
issn = {0894-3230},
doi = {https://doi.org/10.1002/poc.4202},
url = {https://www.sciencedirect.com/science/article/pii/S0894323022006889},
author = {Dean J. Tantillo},
keywords = {bifurcation, dynamics, entropy},
abstract = {Recent computational studies highlighting the importance of accounting for dynamic effects on organic reactivity are discussed, accompanied by descriptions of the factors that led the author to pursue these projects.}
}
@article{ROGOWSKI2024109246,
title = {Unlocking massively parallel spectral proper orthogonal decompositions in the PySPOD package},
journal = {Computer Physics Communications},
volume = {302},
pages = {109246},
year = {2024},
issn = {0010-4655},
doi = {https://doi.org/10.1016/j.cpc.2024.109246},
url = {https://www.sciencedirect.com/science/article/pii/S0010465524001693},
author = {Marcin Rogowski and Brandon C.Y. Yeung and Oliver T. Schmidt and Romit Maulik and Lisandro Dalcin and Matteo Parsani and Gianmarco Mengaldo},
keywords = {Spectral proper orthogonal decomposition, SPOD, Parallel, Distributed, MPI, Modal decomposition, Dynamical systems},
abstract = {We propose a parallel (distributed) version of the spectral proper orthogonal decomposition (SPOD) technique. The parallel SPOD algorithm distributes the spatial dimension of the dataset preserving time. This approach is adopted to preserve the non-distributed fast Fourier transform of the data in time, thereby avoiding the associated bottlenecks. The parallel SPOD algorithm is implemented in the PySPOD library and makes use of the standard message passing interface (MPI) library, implemented in Python via mpi4py. An extensive performance evaluation of the parallel package is provided, including strong and weak scalability analyses. The open-source library allows the analysis of large datasets of interest across the scientific community. Here, we present applications in fluid dynamics and geophysics, that are extremely difficult (if not impossible) to achieve without a parallel algorithm. This work opens the path toward modal analyses of big quasi-stationary data, helping to uncover new unexplored spatio-temporal patterns.
Program summary
Program Title: PySPOD CPC Library link to program files: https://doi.org/10.17632/jf5bf26jcj.1 Developer's repository link: https://github.com/MathEXLab/PySPOD Licensing provisions: MIT License Programming language: Python Nature of problem: Large spatio-temporal datasets may contain coherent patterns that can be leveraged to better understand, model, and possibly predict the behavior of complex dynamical systems. To this end, modal decomposition methods, such as the proper orthogonal decomposition (POD) and its spectral counterpart (SPOD), constitute powerful tools. The SPOD algorithm allows the systematic identification of space-time coherent patterns. This can be used to understand better the physics of the process of interest, and provide a path for mathematical modeling, including reduced order modeling. The SPOD algorithm has been successfully applied to fluid dynamics, geophysics and other domains. However, the existing open-source implementations are serial, and they prevent running on the increasingly large datasets that are becoming available, especially in computational physics. The inability to analyze via SPOD large dataset in turn prevents unlocking novel mechanisms and dynamical behaviors in complex systems. Solution method: We provide an open-source parallel (MPI distributed) code, namely PySPOD, that is able to run on large datasets (the ones considered in the present paper reach about 200 Terabytes). The code is built on the previous serial open-source code PySPOD that was published in https://joss.theoj.org/papers/10.21105/joss.02862.pdf. The new parallel implementation is able to scale on several nodes (we show both weak and strong scalability) and solve some of the bottlenecks that are commonly found at the I/O stage. The current parallel code allows running on datasets that was not easy or possible to analyze with serial SPOD algorithms, hence providing a path towards unlocking novel findings in computational physics. Additional comments including restrictions and unusual features: The code comes with a set of built-in postprocessing tools, for visualizing the results. It also comes with extensive continuous integration, documentation, and tutorials, as well as a dedicated website in addition to the associated GiHub repository. Within the package we also provide a parallel implementation of the proper orthogonal decomposition (POD), that leverages the I/O parallel capabilities of the SPOD algorithm.}
}