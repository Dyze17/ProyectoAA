@article{FUCHS2023103688,
title = {A post-Cartesian economic and Buddhist view on tourism},
journal = {Annals of Tourism Research},
volume = {103},
pages = {103688},
year = {2023},
issn = {0160-7383},
doi = {https://doi.org/10.1016/j.annals.2023.103688},
url = {https://www.sciencedirect.com/science/article/pii/S0160738323001615},
author = {Matthias Fuchs},
keywords = {Economic growth ideology, Post-Cartesian ontology, Post-mechanistic economic theory, Buddhist philosophy, Transformative tourism},
abstract = {Insuperable socio-economic and ecological crises demonstrate the need to challenge economic growth ideology that is often embedded in contemporary tourism science. By borrowing from Buddhist philosophy this essay describes inconsistencies in economic theorizing due to its adoption of the Cartesian ontology implying a mechanistic thinking form. Following philosopher Brodbeck (2014), economic science is neither an empirically exact science nor value-free but represents an implicit ethics. To build on this, the elements of a post-mechanistic economic theory are sketched (Brodbeck, 2001). The applicability of this concept is corroborated by instances of current tourism research. After reinterpreting the homo economicus and the nature of money an agenda for a transformative tourism science building upon post-Cartesian economic thinking and Buddhist philosophy is elaborated.}
}
@incollection{DELLANGELO2022299,
title = {13 - Computational chemistry and the study and design of catalysts},
editor = {Liliana Mammino},
booktitle = {Green Chemistry and Computational Chemistry},
publisher = {Elsevier},
pages = {299-332},
year = {2022},
series = {Advances in Green and Sustainable Chemistry},
isbn = {978-0-12-819879-7},
doi = {https://doi.org/10.1016/B978-0-12-819879-7.00010-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128198797000106},
author = {David Dell’Angelo},
keywords = {CO capture, conversion and utilization, Energy storage, Free energy techniques, Metal-organic frameworks (MOFs), Nanohazard simulations, Photocatalysis technologies, Roles of catalysis in green chemistry, Simulation methods in molecular modelling, Solvent effects on chemical reactivity, Zeolites and catalysis},
abstract = {Several theoretical and computational chemistry works may yield results that prove useful for a better understanding of phenomena relevant to green chemistry, or may specifically focus on addressing green chemistry issues. This chapter presents an overview of results of this type, considering their various application areas. At the same time, it devotes particular attention to the roles that computationally obtained information may play for an efficient design of catalysts and for a better understanding of catalytic processes. This particular attention is motivated by the fundamental roles of catalysis in the design of ‘greener’ processes, where ‘greener’ may refer to a variety of aspects, such as the use of safer reactants and products, the use of benign solvents, the increase in energy efficiency and other features that make a process more environmentally friendly.}
}
@article{SUO2024109268,
title = {A review of three-way decision: Triadic understanding, organization, and perspectives},
journal = {International Journal of Approximate Reasoning},
volume = {173},
pages = {109268},
year = {2024},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2024.109268},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X24001555},
author = {Langwangqing Suo and Han Yang and Qiaoyi Li and Hai-Long Yang and Yiyu Yao},
keywords = {Three-way decision, Triadic thinking, Three-way literature review,  method, Three-way bibliometrics analytics},
abstract = {A theory of three-way decision is about thinking, problem-solving, and computing in threes or through triads. In this paper, we review fifteen years of research on three-way decision by using the philosophy-theory-application triad and the who-what-when triad. First, we discuss the philosophy, theory, and application of three-way decision. At the philosophy level, we delve into the philosophical roots and fundamental nature of three-way decision to reveal the underlying philosophical thinking. At the theory level, we provide an insightful analysis of the theory and methodology of three-way decision. At the application level, we examine the integration of three-way decision with other theories and their applications and effectiveness in real-world scenarios. Second, we focus on bibliometrics analytics by using the who-what-when triad, which attempts to answer a fundamental question of “who did what when”. We propose a 3×3 model by applying the 3×3 method of three-way decision. The first 3 is the author-topic-time triad. The second 3 represents a three-level analysis for each of the first three: (1) categorizing authors into the three levels of prolific authors, frequent authors, and occasional authors, (2) classifying topics into the three levels of the core topics, emerging topics, and to-be-explored topics, and (3) dividing articles into the three levels of initial investigations, further developments, and most recent studies. Finally, we perform a bibliometrics analysis of three-way decision articles by using the 3×3 model of three-way decision. The results not only reveal the current status and trend of three-way decision research but also provide a road map for future research.}
}
@article{FERGUSON2024286,
title = {Social uncertainty in the digital world},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {4},
pages = {286-289},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324000329},
author = {Amanda M. Ferguson and Georgia Turner and Amy Orben},
keywords = {Bayesian inference, digital affordances, social media, social uncertainty},
abstract = {The social world is inherently uncertain. We present a computational framework for thinking about how increasingly popular online environments modulate the social uncertainty we experience, depending on the type of social inferences we make. This framework draws on Bayesian inference, which involves combining multiple informational sources to update our beliefs.}
}
@article{BOERS2025100095,
title = {Exploring cognitive strategies in human-AI interaction: ChatGPT's role in creative tasks},
journal = {Journal of Creativity},
volume = {35},
number = {1},
pages = {100095},
year = {2025},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2025.100095},
url = {https://www.sciencedirect.com/science/article/pii/S2713374525000020},
author = {Jelle Boers and Terra Etty and Martine Baars and Kim {van Boekhoven}},
keywords = {Human-AI interaction, Cognitive strategies, Creativity, Higher education},
abstract = {This study investigated the cognitive strategies employed by dyads when utilizing ChatGPT's examples to generate ideas in creative tasks. Fourteen university students generated ideas for both function-first and form-first creative tasks in interaction with ChatGPT. Their 591 turns were analyzed using both self-reports and coded transcripts to categorize cognitive strategies such as conceptual combination, inspiration, improvement, and repetition. The results indicated that students less frequently employ cognitive strategies focusing on human-AI interaction (e.g., inspiration, improve, combine), but that most of the ideas were produced by repeating ChatGPT's idea. This tendency suggests that, when given freedom, students may rely heavily on AI-generated suggestions rather than actively engaging in more complex cognitive processes. A key practical implication of these findings is the importance of educating students on different cognitive strategies they can adopt in collaboration with AI tools. By guiding students to employ more diverse and active cognitive strategies, ChatGPT has the potential to become a more effective tool for enhancing creative thinking in higher education.}
}
@incollection{JUDD2006881,
title = {Chapter 17 Computationally Intensive Analyses in Economics},
editor = {L. Tesfatsion and K.L. Judd},
series = {Handbook of Computational Economics},
publisher = {Elsevier},
volume = {2},
pages = {881-893},
year = {2006},
issn = {1574-0021},
doi = {https://doi.org/10.1016/S1574-0021(05)02017-4},
url = {https://www.sciencedirect.com/science/article/pii/S1574002105020174},
author = {Kenneth L. Judd},
keywords = {computational economics, economic methodology},
abstract = {Computer technology presents economists with new tools, but also raises novel methodological issues. This essay discusses the challenges faced by computational researchers, and proposes some solutions.}
}
@article{LIU2024100642,
title = {A systematic review on how educators teach AI in K-12 education},
journal = {Educational Research Review},
volume = {45},
pages = {100642},
year = {2024},
issn = {1747-938X},
doi = {https://doi.org/10.1016/j.edurev.2024.100642},
url = {https://www.sciencedirect.com/science/article/pii/S1747938X24000514},
author = {Xiaofan Liu and Baichang Zhong},
keywords = {K-12 education, AI education, AI literacy, Research design, Teaching practice},
abstract = {Developing Artificial Intelligence (AI) education in K-12 contexts, i.e., teaching students about AI, is critical to promote students' AI literacy. However, the state-of-the-art of AI education is not clear enough. To this end, this study reviewed 45 high-quality empirical studies on K-12 AI education over the past decade from both research and instruction perspectives. Regarding the research design, this study revealed the relationship between publication year, sample size, learning stage, educational setting, research method, research focus and duration. Regarding the instruction design, this study revealed the relationship between learning stage, pedagogical strategy, learning tool, learning activity, learning content, assessment method and learning effect. Besides, this study also derived recommendations for research (i.e., time allocation, samples selection, longitudinal design, rigorous methodology and technical democracy) and instruction (i.e., group learning, authentic context, teacher involvement, triangular evidence and learning scaffolding). Overall, the main findings indicate that K-12 AI education has the potential to develop students’ AI literacy, which contains AI knowledge, AI affectivity, and AI thinking. However, deficiencies in research and instructional design still remain, including short durations, small sample sizes, non-standardized research methods, lack of long-term and cross-age AI curriculum, etc. This study also discussed several critical topics for future research and instruction.}
}
@article{FIGLIOLIA2020102968,
title = {An FPGA multiprocessor architecture for Bayesian online change point detection using stochastic computation},
journal = {Microprocessors and Microsystems},
volume = {74},
pages = {102968},
year = {2020},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2019.102968},
url = {https://www.sciencedirect.com/science/article/pii/S0141933119304727},
author = {Tomas Figliolia and Andreas G. Andreou},
keywords = {Changepoint analysis, Changepoint detection, Image segmentation, Bayesian inference, On-line algorithm, Stochastic processing, Precision on demand, ASIC, VHDL, Probabilistic event representation},
abstract = {In this paper we report on an event-based stochastic architecture for the Adams/McKay Bayesian Online Change Point Detection algorithm (BOCPD) [1]. In the stochastic computational structures, probabilities are represented natively as stochastic events and computation is carried out directly with these probabilities and not probability density functions. A fully programmable BOCPD processor is synthesized in VHDL. The BOCPD algorithm with on-line learning, to perform foreground/background image segmentation with online learning. Running on a single Kintex 7 FPGA (Opal Kelly XEM7350-K410T) the architecture is capable of real-time processing a 160 × 120 pixels image, at 10 frames per second.}
}
@article{REN201310351,
title = {Challenges in the assignment of relative and absolute configurations of complex molecules: computation can resolve conflicts between theory and experiment},
journal = {Tetrahedron},
volume = {69},
number = {48},
pages = {10351-10356},
year = {2013},
issn = {0040-4020},
doi = {https://doi.org/10.1016/j.tet.2013.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S004040201301538X},
author = {Jie Ren and Guo-You Li and Lan Shen and Guo-Lin Zhang and Laurance A. Nafie and Hua-Jie Zhu},
keywords = {Absolute configuration reassignment, DFT, Chiroptical spectroscopy, Transition state, X-ray},
abstract = {The configuration of (−)-brevianamides was assigned as (2S,13S) based on X-ray structure analysis and hydrolysis experiments. However, our theoretical investigation of its chiroptical properties strongly implied that the correct configuration should be (2R,13R). The reasons for the incorrect earlier assignment are analyzed by calculations of conversion energy barriers among different intermediates, starting materials and final products. This study demonstrates that conflicting theoretical and, experimental results suggest that it is premature to assign the configuration of a natural product.}
}
@article{PSYCHARIS2011547,
title = {The computational experiment and its effects on approach to learning and beliefs on physics},
journal = {Computers & Education},
volume = {56},
number = {3},
pages = {547-555},
year = {2011},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2010.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S0360131510002642},
author = {Sarantos Psycharis},
keywords = {ICT, Programming, Interactive learning environments, Physics learning, Computational experiment},
abstract = {Contemporary instructional approaches expect students to be active producers of knowledge. This leads to the need for creation of instructional tools and tasks that can offer students opportunities for active learning. This study examines the effect of a computational experiment as an instructional tool-for Grade 12 students, using a computer simulation environment created in Java for the domain of “linear oscillations without damping”. In this study we use the computational experiment as an integration of the computational science with the discovery learning method. The computational experiment supports both types of research, the exploratory as well as the inventive research, helping the learners to develop not only exploratory but also expressive models. The aim of the paper is threefold. At first we want to examine the influence of the computational experiment on students’ learning performance. The other two aims are related to the investigation of the experiment’s influence on students’ approach to learning and their beliefs on physics. Our results indicate that there is a strong shift on students’ conceptual understanding and to the consideration of the coherence of physics, as well as to the realization that physics is strongly connected to mathematics. Finally students realized that mathematics, physics and information theory are strongly connected cognitive disciplines.}
}
@article{XU2011331,
title = {New Recursive Construction of Magic Squares Using Kronecker Compositional Operations and Its Application in Engineering Computation},
journal = {Systems Engineering Procedia},
volume = {2},
pages = {331-337},
year = {2011},
note = {Complexity System and Engineering Management},
issn = {2211-3819},
doi = {https://doi.org/10.1016/j.sepro.2011.10.046},
url = {https://www.sciencedirect.com/science/article/pii/S2211381911001354},
author = {Dandan Xu and Zisen Mao and Bei Chen and Ping Huang},
keywords = {Magic squares, symmetrical, pandiagonal, construction, engineering computation},
abstract = {Owing to the depth research on the remarkable properties of magic squares, a new recursive method for constructing high order magic squares will be firstly presented, based on the matrix operations, we refer to as the Kronecker compositional operations. Furthermore, popularizing this method,, we successfully demonstrate that large size magic squares of odd order with symmetrical and pandiagonal features can be generated by lower order initiators,which leads to the impressive application in engineering computation. Finally, we enumerate two small symmetrical and pandiagonal magic squares.}
}
@article{MOHAMMADIZIABARI2018376,
title = {Computational Analysis of Gender Differences in Coping with Extreme Stressful Emotions},
journal = {Procedia Computer Science},
volume = {145},
pages = {376-385},
year = {2018},
note = {Postproceedings of the 9th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2018 (Ninth Annual Meeting of the BICA Society), held August 22-24, 2018 in Prague, Czech Republic},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.11.088},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918323767},
author = {S. Sahand {Mohammadi Ziabari} and Jan Treur},
keywords = {Adaptive Network, Rumination, Extreme Emotion, Gender},
abstract = {In this paper a computational analysis is presented of differences between men and women in coping with extreme emotions. This analysis is based on an adaptive temporal-causal network model. It takes into account the suppression of connections between preparation states and sensory representations of action effects due to an extreme stressful emotion. It is shown how this model can be used to represent the difference between males and females facing an extreme emotion, thereby performing their own methods in coping with the extreme emotion, for males fight or flight and for females tend-and-befriend.}
}
@article{DAYAN2011661,
title = {Networks, circuits and computation},
journal = {Current Opinion in Neurobiology},
volume = {21},
number = {5},
pages = {661-663},
year = {2011},
note = {Networks, circuits and computation},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2011.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S0959438811001267},
author = {Peter Dayan and Marla Feller and Dan Feldman}
}
@article{WESTERA201732,
title = {How people learn while playing serious games: A computational modelling approach},
journal = {Journal of Computational Science},
volume = {18},
pages = {32-45},
year = {2017},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2016.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S1877750316304483},
author = {Wim Westera},
keywords = {Serious gaming, Learning, Simulation, Modelling, Flow theory, Methodology},
abstract = {This paper proposes a computational modelling approach for investigating the interplay of learning and playing in serious games. A formal model is introduced that allows for studying the details of playing a serious game under diverse conditions. The dynamics of player action and motivation is based on cognitive flow theory, which is expressed in quantitative terms for this purpose. Seven extensive simulation studies involving over 100,000 iterations have demonstrated the stability of the model and its potential as a research instrument for serious gaming. The model allows researchers to deeply investigate quantitative dependences between relevant game variables, gain deeper understanding of how people learn from games, and develop approaches to improving serious game design.}
}
@article{SADEGHIPOUR2012213,
title = {Gesture processing as grounded motor cognition: Towards a computational model},
journal = {Procedia - Social and Behavioral Sciences},
volume = {32},
pages = {213-223},
year = {2012},
note = {The 4th International Conference of Cognitive Science},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2012.01.032},
url = {https://www.sciencedirect.com/science/article/pii/S187704281200033X},
author = {Amir Sadeghipour and Stefan Kopp},
keywords = {Motor Cognition, embodiment, grounded cognition, gestures, social interaction, computational model, embodied conversational agents},
abstract = {In this paper, we present an approach to treat and model the processing (i.e. recognition and production) of communicative gestures as grounded motor cognition. We first review cognitive theories and neuropsychological studies on human motor cognition. On this basis, we propose a computational framework that connects the sensorimotor processing of hand gestures in representational structures of meaning (visuospatial imagery), other modalities (language), and communicative intentions. We present an implementation that enables an embodied virtual agent to engage in gesture-based interaction with a human user.}
}
@article{ZAROUALI2024108024,
title = {Personality and susceptibility to political microtargeting: A comparison between a machine-learning and self-report approach},
journal = {Computers in Human Behavior},
volume = {151},
pages = {108024},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2023.108024},
url = {https://www.sciencedirect.com/science/article/pii/S0747563223003758},
author = {Brahim Zarouali and Tom Dobber and Jurrian Schreuder},
keywords = {Political microtargeting, Persuasion, Personality, Social media, Algorithms},
abstract = {Based on recent technological advances, campaigners and political actors can use psychographic-based political marketing. Yet, empirical evidence about its effectiveness is still very limited. Based on self-congruity theory, a pre-registered experiment (N = 280) investigated the persuasion effects of personality-congruent political microtargeting on the attitude toward the political party and voting intentions of citizens. More precisely, the focus was on the thinking vs feeling personality dimension (MBTI), and it was tested whether this personality “interacts” with exposure to a matching advertising appeal: rational vs. emotional political ad. To do so, two different methodological approaches were used: 1) a machine learning approach; 2) a self-report survey measure of personality. Results revealed significant “congruence effects” between personality and ad appeal, and showed that perceived ad relevance was serving as the underlying mechanism (mediator). However, these results were only found when the self-report measure of personality was used. When the algorithmic approach was used, no significant results were found. These findings feed into timely societal, methodological, and theoretical contributions.}
}
@article{YANG2012852,
title = {Computational Optimization, Modelling and Simulation: Smart Algorithms and Better Models},
journal = {Procedia Computer Science},
volume = {9},
pages = {852-856},
year = {2012},
note = {Proceedings of the International Conference on Computational Science, ICCS 2012},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2012.04.091},
url = {https://www.sciencedirect.com/science/article/pii/S1877050912002128},
author = {Xin-She Yang and Slawomir Koziel and Leifur Leifsson},
keywords = {algorithm, black-box modelling, computational optimization, derivative-free method, optimization algorithm, modelling, nonlinear optimization, surragate-based optimization, simulation},
abstract = {Computational optimization is becoming a standard tool that is widely used in engineering design and industrial applications. Products and services are often concerned with the maximization of profits and reduction of cost, but also aim at being more energy-efficient, environment-friendly and safety-ensured; at the same time they are limited by resources, time and money. Despite of increasing computer power and availability of better simulation packages, there are a number of challenges remaining when applying numerical optimization methods for real-world engineering problems. Also, new challenges emerge when attempting to attack problems whose solution by means of simulation-based optimization was not even possible in the past. This third workshop on Computational Optimization, Modelling and Simulation (COMS 2012) at ICCS 2012 will further summarize the latest developments of optimization and modelling and their applications in science, engineering and industry.}
}
@article{CARUSI20171,
title = {Validation and models in computational biomedical sciences: Philosophy, science, engineering},
journal = {Progress in Biophysics and Molecular Biology},
volume = {129},
pages = {1-2},
year = {2017},
note = {Validation of Computer Modelling},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2017.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S007961071730192X},
author = {Annamaria Carusi and Blanca Rodriguez and Kevin Burrage}
}
@article{OZKAYA2006381,
title = {Requirement-driven design: assistance for information traceability in design computing},
journal = {Design Studies},
volume = {27},
number = {3},
pages = {381-398},
year = {2006},
note = {Digital Design},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2005.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X0500089X},
author = {Ipek Ozkaya and Ömer Akin},
keywords = {requirement-driven design, information processing, design knowledge, design process, design methods},
abstract = {We describe requirement-driven computational design thinking as an approach to leverage the distinctive characteristics of the digital design process. We primarily focus on information continuity and traceability in the digital medium. Requirement-driven design is an information-based approach facilitating consistent design rationale tracking and evaluation, verification, and validation of design. We present the characteristics of requirement-driven design, which leverage the pervasive nature of digital design thinking. We demonstrate a requirement–design coupling approach, modeling a continuous and interactive design process for integrating problem formulation and form exploration.}
}
@article{CALVIN20241192,
title = {ShopMe: a mobile app to introduce Indonesian local MSMEs},
journal = {Procedia Computer Science},
volume = {245},
pages = {1192-1201},
year = {2024},
note = {9th International Conference on Computer Science and Computational Intelligence 2024 (ICCSCI 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.349},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924031570},
author = {Jeremiah Calvin and Yudhistya Ayu Kusumawati and Asri Radhitanti},
keywords = {Economic Inequality, MSMEs, Income, Platform, Poverty},
abstract = {The poverty rate in Malang Raya is decreasing, although this is a good thing, another problem is emerging, namely economic inequality. Economic inequality impacts many parties, both rich and poor. This problem started with the COVID-19 pandemic, with uncertain economic stability. With this reality, one of the factors that will have an impact on the current economy is MSMEs. Moreover, with the increasing economic inequality in Malang, MSMEs will have minimal income and if MSMEs do not run as they should, the country's economy will not be good. be good. This research aims to find a solution by creating a platform to unite MSMEs that are under the radar to improve their playing field, especially F&B MSMEs, with the main benefits being given to MSMEs. To understand this problem, this research uses a design thinking process, with interviews and questionnaires as the main research, as well as a literature review as the method for conducting this research. The result of this research is the development of a mobile app which can be a bridge for MSMEs to become better known to the public. With the publication of this research, it is hoped that it will be an inspiration for the public to find ways to overcome these problems.}
}
@article{COOPER201442,
title = {Implementations are not specifications: Specification, replication and experimentation in computational cognitive modeling},
journal = {Cognitive Systems Research},
volume = {27},
pages = {42-49},
year = {2014},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2013.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041713000314},
author = {Richard P. Cooper and Olivia Guest},
keywords = {Theory specification, Implementation detail, Replication, Sensitivity analysis, Computational experimentation},
abstract = {Contemporary methods of computational cognitive modeling have recently been criticized by Addyman and French (2012) on the grounds that they have not kept up with developments in computer technology and human–computer interaction. They present a manifesto for change according to which, it is argued, modelers should devote more effort to making their models accessible, both to non-modelers (with an appropriate easy-to-use user interface) and modelers alike. We agree that models, like data, should be freely available according to the normal standards of science, but caution against confusing implementations with specifications. Models may embody theories, but they generally also include implementation assumptions. Cognitive modeling methodology needs to be sensitive to this. We argue that specification, replication and experimentation are methodological approaches that can address this issue.}
}
@article{KNIGHT20151,
title = {Computational making},
journal = {Design Studies},
volume = {41},
pages = {1-7},
year = {2015},
note = {Special Issue: Computational Making},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2015.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X15000721},
author = {Terry Knight and Theodora Vardouli}
}
@article{JONCZYK2024120752,
title = {Operating in a second language lowers cognitive interference during creative idea generation: Evidence from brain oscillations in bilinguals},
journal = {NeuroImage},
volume = {297},
pages = {120752},
year = {2024},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2024.120752},
url = {https://www.sciencedirect.com/science/article/pii/S1053811924002490},
author = {Rafał Jończyk and Iga Krzysik and Olga Witczak and Katarzyna Bromberek-Dyzman and Guillaume Thierry},
keywords = {Creativity, Bilingualism, EEG, Alternate uses task, Alpha frequency, Beta frequency},
abstract = {Tasks measuring human creativity overwhelmingly rely on both language comprehension and production. Although most of the world's population is bilingual, few studies have investigated the effects of language of operation on creative output. This is surprising given that fluent bilinguals master inhibitory control, a mechanism also at play in creative idea evaluation. Here, we compared creative output in the two languages of Polish(L1)-English(L2) bilinguals engaged in a cyclic adaptation of the Alternative Uses Task increasing the contribution of idea evaluation (convergent thinking). We show that Polish-English bilinguals suffer less cognitive interference when generating unusual uses for common objects in the L2 than the L1, without incurring a significant drop in idea originality. Right posterior alpha oscillation power, known to reflect creative thinking, increased over cycles. This effect paralleled the increase in originality ratings over cycles, and lower alpha power (8–10 Hz) was significantly greater in the L1 than the L2. Unexpectedly, we found greater beta (16.5–28 Hz) desynchronization in the L2 than the L1, suggesting that bilingual participants suffered less interference from competing mental representations when performing the task in the L2. Whereas creative output seems unaffected by language of operation overall, the drop in beta power in the L2 suggests that bilinguals are not subjected to the same level of semantic flooding in the second language as they naturally experience in their native language.}
}
@incollection{RAMOS2018720,
title = {8.36 - Bioinformatics and Computational Biology in Toxicology: Gateways for Precision Medicine☆},
editor = {Charlene A. McQueen},
booktitle = {Comprehensive Toxicology (Third Edition)},
publisher = {Elsevier},
edition = {Third Edition},
address = {Oxford},
pages = {720-728},
year = {2018},
isbn = {978-0-08-100601-6},
doi = {https://doi.org/10.1016/B978-0-12-801238-3.99176-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128012383991761},
author = {K.S. Ramos and M. Martin and I.N. Ramos and G.A. Rempala},
keywords = {Bioinformatics, Computational biology, Precision medicine, Systems biology},
abstract = {The National Center for Biotechnology Information (NCBI) defines bioinformatics as “… the field of science in which biology, computer science, and information technology merge to form a single discipline”. As such, the field of bioinformatics includes computer scientists who develop algorithms for sequence analysis, biostatisticians who develop and implement methods of analyses for large clinical datasets, mathematicians or physical scientists who develop models to describe the interactions of genes, proteins, and small molecules within cells, and all those engaged in the development of software and databases for manipulation, storage, and retrieval of information in support of their research. This chapter focuses on how computational biology has been enabled by molecular informatics to provide the basis for in silico studies that facilitate the collection, organization, and analysis of datasets that explain biological phenomena and that help to drive biological discovery with applications in precision medicine.}
}
@incollection{SEDERBERG2010145,
title = {Learning and Memory: Computational Models},
editor = {George F. Koob and Michel Le Moal and Richard F. Thompson},
booktitle = {Encyclopedia of Behavioral Neuroscience},
publisher = {Academic Press},
address = {Oxford},
pages = {145-153},
year = {2010},
isbn = {978-0-08-045396-5},
doi = {https://doi.org/10.1016/B978-0-08-045396-5.00140-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780080453965001408},
author = {P.B. Sederberg and K.A. Norman},
keywords = {Computational models, Context, Cortex, Episodic memory, Hippocampus, Learning, Memory, Neural networks, Recognition, Recall, Semantic memory, Synaptic plasticity},
abstract = {The goal of learning and memory research is to understand how we store and retrieve information based on our experiences. Computational models provide formal implementations of memory theories that attempt to predict both behavior and neural data. This article describes computational models of declarative memory, including episodic memory (memory for specific events) and semantic memory (memory for meanings), with a particular focus on the role of context in supporting both types of memory.}
}
@article{DUAN2025127718,
title = {LSBT-Net: A lightweight framework for fault diagnosis of bearings based on an interpretable spatial-temporal model},
journal = {Expert Systems with Applications},
volume = {281},
pages = {127718},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.127718},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425013405},
author = {Yicheng Duan and Tongguang Yang and Chenlin Wang and Yongjian Zhang and Qingkai Han and Shuangping Guo},
keywords = {Intelligent Diagnosis, Insulated Bearings, LSBT-Net Framework, Interpretability},
abstract = {Intelligent fault diagnosis based on deep learning has emerged as a research focus in mechanical equipment due to its adaptive feature extraction capability. However, current models struggle with low accuracy, high computational costs, and poor interpretability when detecting faults in insulated bearings. To address these challenges, this paper proposes a novel lightweight spatiotemporal model-based intelligent diagnostic framework, named LSBT-Net, which aims to identify motor insulating bearing faults in practical engineering applications more accurately. Specifically, this research breaks the conventional thinking of “learning fault data feature information” by innovatively developing a spatiotemporal information fusion module. This module is cleverly integrated into the LSBT-Net framework, enabling the extraction of both local and global high-dimensional fault feature information from insulating bearings. At the same time, based on a lightweight design, it significantly reduces the total number of parameters and computational resources required by the framework, thus lowering its computational complexity. The t-SNE algorithm is introduced into the LSBT-Net framework to achieve local or global interpretability. Furthermore, by calculating the gradient information of the LSBT-Net framework on the fault types of insulating bearings through backpropagation, the interpretability of the framework with respect to the physical information is enhanced. Using insulating bearings and typical fault experiments as examples, the LSBT-Net framework demonstrates excellent diagnostic capability and generalization performance compared to other advanced methods.}
}
@article{VALENTINOV2015491,
title = {Nonprofit organizations, institutional economics, and systems thinking},
journal = {Economic Systems},
volume = {39},
number = {3},
pages = {491-501},
year = {2015},
note = {Symposium: Financial System and Development in China},
issn = {0939-3625},
doi = {https://doi.org/10.1016/j.ecosys.2014.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0939362515000278},
author = {Vladislav Valentinov and Stefan Hielscher and Ingo Pies},
keywords = {Nonprofit organizations, John Kenneth Galbraith, Countervailing power, Niklas Luhmann},
abstract = {The present paper applies the logic of John Kenneth Gailbraith's institutional economics analysis of corporate power to inquiring into the societal role of the nonprofit sector. Building on Galbraith's insight that corporations cause subtle but pervasive societal imbalances, the paper locates the role of nonprofit organizations in compensating for these imbalances, thus showing corporations and nonprofit organizations to be mutually complementary rather than antagonistic actors. This argument is supported by Niklas Luhmann's vision of the precarious relationship between the complexity and sustainability of social systems as well as by Kenneth Boulding's analysis of the farmer and labor movement. Luhmann's and Boulding's perspectives show profit-seeking corporations to be social systems developing high technological complexity at the cost of sacrificing their societal sustainability, while the improvement of the latter constitutes the rationale of many nonprofit organizations. The same systems-theoretic logic suggests, however, that nonprofit organizations may tend to underestimate the technological complexity of implementing their mission-related activities, thereby undermining their own effectiveness.}
}
@article{LEE2023101274,
title = {Storytelling as a learning tool in creative education: A case study in an architecture design studio},
journal = {Thinking Skills and Creativity},
volume = {48},
pages = {101274},
year = {2023},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2023.101274},
url = {https://www.sciencedirect.com/science/article/pii/S1871187123000445},
author = {Keunhye Lee and Eunki Kang and Eun Joo Park},
keywords = {Storytelling, Creative thinking, Architecture design studio, Creative education, Communicative representation},
abstract = {This paper investigates the significant aspects of storytelling, when used as a pedagogical method to enhance students critical and creative thinking and communicative technique, by applying it to first-year students in the architecture design studio. Creativity is a substantial part of architectural education as it improves students’ design processes in innovative ways. This paper considers how the architecture design studio can form a creative design solution that can be learned and developed by learner-centred activity; it concentrates on aspects of storytelling, which many scholars have begun to discuss its significance in creative education. Thus, this paper aims to develop a creative learning strategy for use in the architecture design studio and suggest a new learning method by engaging storytelling in the design process. This paper starts with discussions about storytelling and its usages in the architecture design studio, referring to several theorists and educators, particularly focusing on McDrury and Alterio (2003); it helps to create a framework and develop a curriculum for the architecture design studio. The overall results suggest that using storytelling as a learning method in an architecture design studio is important in contextualising and articulating design work, from ideas to analysis, visualisation and expression, in a coherent context. It helps students gain better design skills and a greater understanding of the design process across the disciplines of the design studio, improving students creative thinking during the unique design process.}
}
@article{SU2022100049,
title = {Artificial intelligence in early childhood education: A scoping review},
journal = {Computers and Education: Artificial Intelligence},
volume = {3},
pages = {100049},
year = {2022},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2022.100049},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X22000042},
author = {Jiahong Su and Weipeng Yang},
keywords = {Artificial intelligence, Early childhood education, Teaching and learning, Machine learning, Computer science},
abstract = {Artificial intelligence (AI) tools are increasingly being used in the field of early childhood education (ECE) to enhance learning and development among young children. Previous proof-of-concept studies have demonstrated that AI can effectively improve teaching and learning in ECE; however, there is a scarcity of knowledge about how these studies are conducted and how AI is used across these studies. We conducted this scoping review to evaluate, synthesize and display the latest literature on AI in ECE. This review analyzed 17 eligible studies conducted in different countries from 1995 to 2021. Although few studies on this critical issue have been found, the existing references provide up-to-date insights into different aspects (knowledge, tools, activities, and impacts) of AI for children. Most studies have shown that AI has significantly improved children's concepts regarding AI, machine learning, computer science, and robotics and other skills such as creativity, emotion control, collaborative inquiry, literacy skills, and computational thinking. Future directions are also discussed for researching AI in ECE.}
}
@article{WHALLEY2001743,
title = {Reliability and uncertainty in flow measurement techniques - some current thinking},
journal = {Physics and Chemistry of the Earth, Part C: Solar, Terrestrial & Planetary Science},
volume = {26},
number = {10},
pages = {743-749},
year = {2001},
issn = {1464-1917},
doi = {https://doi.org/10.1016/S1464-1917(01)95019-6},
url = {https://www.sciencedirect.com/science/article/pii/S1464191701950196},
author = {N. Whalley and R.S. Iredale and A.F. Clare},
keywords = {flow measurement, current meter gauging, flow measurement structures, calibration, stage-discharge relationship},
abstract = {Improvements in the quality and availability of flow measurement equipment are undoubtedly capable of enhancing the reliability and accuracy of the hydrometric data that we require. However much of the UK's hydrometric data is acquired by the tried and trusted methods that have remained the mainstay of flow monitoring for many years. Should the results provided by these established techniques always be so readily accepted given the range of assumptions on which they are based? Current meter gauging is the principle technique used for the establishment of stage discharge relationships in the UK. Either directly for the establishment of stage-discharge relationships in open channels, indirectly for calibration of flow measurement equipment (e.g. ultrasonic Doppler velocity meters) or as a means of verification of existing flow measurement structures. Recent projects involving current meter gauging techniques have provoked much thought as to the validity of established techniques and in particular the assumptions on which they are based. The chosen case studies highlight a number of projects where there have been questions regarding the reliability and uncertainty of the flow measurement techniques employed. The alternative approaches required to deal with such problems are also discussed.}
}
@article{LISSACK2024389,
title = {Responsible Use of Large Language Models: An Analogy with the Oxford Tutorial System},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {10},
number = {4},
pages = {389-413},
year = {2024},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2024.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S2405872624000959},
author = {Michael Lissack and Brenden Meagher},
keywords = {responsible AI, Oxford Tutorial, large language models (LLMs), human-AI collaboration, critical thinking},
abstract = {In the rapidly evolving landscape of artificial intelligence, large language models (LLMs) have emerged as powerful tools with the potential to revolutionize how we process information, generate content, and solve complex problems. However, integrating these sophisticated AI systems into academic and professional practices raises critical questions about responsible use, ethical considerations, and the preservation of human expertise. This article introduces a novel framework for understanding and implementing responsible AI use by drawing an analogy between the optimal use of LLMs and the role of the second student in an Oxford Tutorial. Through an in-depth exploration of the Oxford Tutorial system and its parallels with LLM interaction, we propose a nuanced approach to leveraging AI language models while maintaining human agency, fostering critical thinking, and upholding ethical standards. The article examines the implications of this analogy, discusses potential risks of misuse, and provides detailed practical scenarios across various fields. By grounding the use of cutting-edge AI technology in a well-established and respected educational model, this research contributes to the ongoing discourse on AI ethics. It offers valuable insights for academics, professionals, and policymakers grappling with the challenges and opportunities presented by LLMs.}
}
@article{FIELDS2025256,
title = {Thoughts and thinkers: On the complementarity between objects and processes},
journal = {Physics of Life Reviews},
volume = {52},
pages = {256-273},
year = {2025},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2025.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S1571064525000089},
author = {Chris Fields and Michael Levin},
keywords = {Active inference, Cognitive light cone, Emergence, Evo/devo/eco, Multiscale competency architecture, Niche construction, Semantics},
abstract = {We argue that “processes versus objects” is not a useful dichotomy. There is, instead, substantial theoretical utility in viewing “objects” and “processes” as complementary ways of describing persistence through time, and hence the possibility of observation and manipulation. This way of thinking highlights the role of memory as an essential resource for observation, and makes it clear that “memory” and “time” are also mutually inter-defined, complementary concepts. We formulate our approach in terms of the Free Energy Principle (FEP) of Friston and colleagues and the fundamental idea from quantum theory that physical interactions can be represented by linear operators. Following Levin (2024) [30], we emphasize that memory is, first and foremost, an interpretative function, from which the idea of memory as a record, at some level of accuracy, of past events is derivative. We conclude that the distinction between objects and processes is always contrived, and always misleading, and that science would be better served by abandoning it entirely.}
}
@article{BILORIA2012259,
title = {Interactive morphologies: An investigation into integrated nodal networks and embedded computation processes for developing real-time responsive spatial systems},
journal = {Frontiers of Architectural Research},
volume = {1},
number = {3},
pages = {259-271},
year = {2012},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2012.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S2095263512000465},
author = {Nimish Biloria},
keywords = {Real-time interaction, Sensing and actuation, Performance, Adaptation, Emergence},
abstract = {The design-research illustrated in this research article focus on the emerging field of interactive architecture focusing on developing real-time information exchanging architectural bodies. These interactive bodies demonstrate a fusion between the material, the electronic and the digital domains. This fusion is explicitly attained through a synergistic merger between the fields of ambient sensing, control systems, ubiquitous computing, architectural design, pneumatic systems and computation. The resultant spatial bodies are thus visualised as complex adaptive systems, continually engaged in activities of data-exchange resulting in physical and ambient adaptations of their constituting components in response to contextual variations. Interdependent nodal networks, where every node/junction of a spatial prototype becomes a potential information hub by means of its ability to collect, process and communicate contextual data apart from working as an actuated detail owing to its ability to kinetically re-position itself in three-dimensional space is thus a critical outcome of this inter-disciplinary way of working. A strategy apt for binding material logistics with the digital to materialize dynamic spatial behaviours owing to real time data exchange between the prototypes and their context is thus embarked upon via three research and design projects, namely: Electronic Media Augmented Spatial Skins, The InteractiveWall and the Muscle Re-configured.}
}
@article{KLIEMANN20181,
title = {The social neuroscience of mentalizing: challenges and recommendations},
journal = {Current Opinion in Psychology},
volume = {24},
pages = {1-6},
year = {2018},
note = {Social Neuroscience},
issn = {2352-250X},
doi = {https://doi.org/10.1016/j.copsyc.2018.02.015},
url = {https://www.sciencedirect.com/science/article/pii/S2352250X17302786},
author = {Dorit Kliemann and Ralph Adolphs},
abstract = {Our ability to understand and think about the mental states of other people is referred to as ‘mentalizing’ or ‘theory of mind’. It features prominently in all social behavior, is essential for maintaining relationships, and shows pronounced individual differences. Here we review new approaches to study the underlying psychological mechanisms and discuss how they could best be investigated using modern tools from social neuroscience. We list key desiderata for the field, such as validity, specificity, and reproducibility, and link them to specific recommendations for the future. We also discuss new computational modeling approaches, and the application to psychopathology.}
}
@article{LI2025126039,
title = {Correct like humans: Progressive learning framework for Chinese text error correction},
journal = {Expert Systems with Applications},
volume = {265},
pages = {126039},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.126039},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424029063},
author = {Yinghui Li and Shirong Ma and Shaoshen Chen and Haojing Huang and Shulin Huang and Yangning Li and Hai-Tao Zheng and Ying Shen},
keywords = {Chinese text error correction, Progressive learning, Natural language processing, Computational linguistics},
abstract = {Chinese Text Error Correction (CTEC) aims to detect and correct errors in the input text, which benefits human daily life and various downstream tasks. With the extensive research on Pre-trained Language Models (PLMs), Chinese Spelling Correction (CSC) and Chinese Grammatical Error Correction (CGEC), two subtasks of CTEC, have achieved good results. However, researchers usually study these two tasks separately. In addition, we argue that previous studies still overlook the importance of human thinking patterns. To enhance the development of PLMs for CTEC, inspired by humans’ daily error-correcting behavior, we propose a novel model-agnostic progressive learning framework, named ProTEC, which guides PLMs-based CTEC models to learn to correct like humans and can be applied to various existing CTEC models in both CSC and CGEC. During the training process, ProTEC guides the model to learn text error correction by incorporating these sub-tasks into a progressive paradigm. During the inference process, the model completes these sub-tasks in turn to generate the correction results. Extensive experiments and detailed analyses demonstrate the effectiveness and efficiency of our proposed model-agnostic ProTEC framework.}
}
@article{YANG2018242,
title = {Multi-disciplinary and multi-objective optimization problem re-formulation in computational design exploration: A case of conceptual sports building design},
journal = {Automation in Construction},
volume = {92},
pages = {242-269},
year = {2018},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2018.03.023},
url = {https://www.sciencedirect.com/science/article/pii/S0926580517309317},
author = {Ding Yang and Shibo Ren and Michela Turrin and Sevil Sariyildiz and Yimin Sun},
keywords = {Multi-disciplinary optimization, Multi-objective optimization, Computational design exploration, Knowledge extraction, Statistical analysis techniques, Optimization problem re-formulation, Sports buildings, Architectural performance, Climate performance, Structural performance},
abstract = {The benefits of applying multi-objective optimization (MOO) in building design have been increasingly recognized in recent decades. The existing or traditional computational design optimization (CDO) approaches mostly focus on optimization problem solving (OPS), as they often conduct optimizations directly by assuming the optimization problems in question are good enough. In contrast, the computational design exploration (CDE) approaches defined in this research mainly focus on optimization problem formulation (OPF), which are considered more essential and aim to achieve or ensure appropriate optimization problems before conducting optimizations. However, the application of the CDE is very limited especially in conceptual architectural design. The necessity of re-formulating original optimization problems and its potential impacts on optimization results are often overlooked or not emphasized enough. This paper proposes a new CDE approach that highlights the knowledge-supported re-formulation of a changeable initial optimization problem. It improves upon the traditional CDO approach by introducing a changeable initial OPF and inserting a CDE module. The changeable initial OPF allows expanding the dimensionality of an objective space and design space being investigated, and the CDE module can re-formulate the changeable optimization problem using the information and knowledge extracted from statistical analyses. To facilitate designers in achieving the proposed approach, an improved computational platform is used which combines parametric modeling software (including simulation plug-ins) and design optimization software. Assisted by the platform, the proposed approach is applied to the conceptual design of an indoor sports building that considers multi-disciplinary performance criteria (including architecture-, climate- and structure-related criteria) and a wide range of geometric variations. Through the case study, this paper demonstrates the use of the proposed approach, verifies its benefits over the traditional method, and unveils the factors that may affect the behaviour of the proposed approach. Besides, it also shows the suitability of the computational platform used.}
}
@article{CONSTABLE201760,
title = {The practice of chemistry still needs to change},
journal = {Current Opinion in Green and Sustainable Chemistry},
volume = {7},
pages = {60-62},
year = {2017},
note = {New Synthetic Methods 2017},
issn = {2452-2236},
doi = {https://doi.org/10.1016/j.cogsc.2017.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S2452223617300755},
author = {David J.C. Constable},
abstract = {There is now over a 20-year history of green and sustainable chemistry efforts in the US, but for a majority of chemicals that have been synthesized, chemists and chemical engineers lack key information about what it takes to commercialize them, their toxicity to humans or the environment, their degradability (biological or otherwise), their ability to be recycled or reused, or their ability to be source renewably. While the depth, breadth, and variety of innovations in chemistry gives one hope that chemists and chemical engineers will make many significant advances in the next 20 years, there is still a need to incorporate systems and life cycle thinking into chemistry. This is especially true as one considers limitations in the supply of key elements chemists rely on very heavily. Recent advances in computational chemistry and machine learning show great promise for moving chemistry toward a more sustainable practice of chemistry.}
}
@article{CROLLEN2019549,
title = {Recruitment of the occipital cortex by arithmetic processing follows computational bias in the congenitally blind},
journal = {NeuroImage},
volume = {186},
pages = {549-556},
year = {2019},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2018.11.034},
url = {https://www.sciencedirect.com/science/article/pii/S1053811918321153},
author = {Virginie Crollen and Latifa Lazzouni and Mohamed Rezk and Antoine Bellemare and Franco Lepore and Marie-Pascale Noël and Xavier Seron and Olivier Collignon},
keywords = {Blindness, Mental arithmetic, Multiplication, Neural correlates, Subtraction},
abstract = {Arithmetic reasoning activates the occipital cortex of congenitally blind people (CB). This activation of visual areas may highlight the functional flexibility of occipital regions deprived of their dominant inputs or relate to the intrinsic computational role of specific occipital regions. We contrasted these competing hypotheses by characterizing the brain activity of CB and sighted participants while performing subtraction, multiplication and a control letter task. In both groups, subtraction selectively activated a bilateral dorsal network commonly activated during spatial processing. Multiplication triggered activity in temporal regions thought to participate in memory retrieval. No between-group difference was observed for the multiplication task whereas subtraction induced enhanced activity in the right dorsal occipital cortex of the blind individuals only. As this area overlaps with regions showing selective tuning to auditory spatial processing and exhibits increased functional connectivity with a dorsal “spatial” network, our results suggest that the recruitment of occipital regions during high-level cognition in the blind actually relates to the intrinsic computational role of the activated regions.}
}
@article{MOGHADDAM2020112879,
title = {A neuro-inspired computational model for adaptive fault diagnosis},
journal = {Expert Systems with Applications},
volume = {140},
pages = {112879},
year = {2020},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2019.112879},
url = {https://www.sciencedirect.com/science/article/pii/S0957417419305895},
author = {Mohsen Moghaddam and Qiliang Chen and Abhijit V. Deshmukh},
keywords = {Machine consciousness, Deep learning, Convolutional neural networks, Transfer learning},
abstract = {Fault diagnosis is a key process to ensure reliable and cost-effective performance of time-critical engineered systems. This article develops a data-driven computational model for adaptive fault diagnosis by drawing an analogy with the neurobiological process of conscious attention—a dynamic process that brings only the most novel 0.01% of the signals we receive with our five senses to our conscious experience. A model of conscious attention based on the theory of dynamic core hypothesis is first outlined, followed by a computational model that mimics key stages of the conscious attention process. Convolutional neural networks serve as a basis for modeling perceptual categorization and concept formation through automatic feature extraction, due to their analogy with the processes of neural group selection and reentry in the brain. Further, the process of incremental learning and its impact on signal novelty are modeled via transfer learning. The model is tested on the NASA C-MAPSS turbofan engine model, which indicated 95–99% fault diagnosis accuracy. This study aims at familiarizing the engineering community with the neurobiological process of conscious attention and its applications for adaptive process monitoring and improvement in engineered systems.}
}
@article{WANG2024,
title = {News Coverage of the COVID-19 Pandemic on Social Media and the Public’s Negative Emotions: Computational Study},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/48491},
url = {https://www.sciencedirect.com/science/article/pii/S143888712400308X},
author = {Hanjing Wang and Yupeng Li and Xuan Ning},
keywords = {web news coverage, emotions, social media, Facebook, COVID-19},
abstract = {Background
Social media has become an increasingly popular and critical tool for users to digest diverse information and express their perceptions and attitudes. While most studies endeavor to delineate the emotional responses of social media users, there is limited research exploring the factors associated with the emergence of emotions, particularly negative ones, during news consumption.
Objective
We aim to first depict the web coverage by news organizations on social media and then explore the crucial elements of news coverage that trigger the public’s negative emotions. Our findings can act as a reference for responsible parties and news organizations in times of crisis.
Methods
We collected 23,705 Facebook posts with 1,019,317 comments from the public pages of representative news organizations in Hong Kong. We used text mining techniques, such as topic models and Bidirectional Encoder Representations from Transformers, to analyze news components and public reactions. Beyond descriptive analysis, we used regression models to shed light on how news coverage on social media is associated with the public’s negative emotional responses.
Results
Our results suggest that occurrences of issues regarding pandemic situations, antipandemic measures, and supportive actions are likely to reduce the public’s negative emotions, while comments on the posts mentioning the central government and the Government of Hong Kong reveal more negativeness. Negative and neutral media tones can alleviate the rage and interact with the subjects and issues in the news to affect users’ negative emotions. Post length is found to have a curvilinear relationship with users’ negative emotions.
Conclusions
This study sheds light on the impacts of various components of news coverage (issues, subjects, media tone, and length) on social media on the public’s negative emotions (anger, fear, and sadness). Our comprehensive analysis provides a reference framework for efficient crisis communication for similar pandemics at present or in the future. This research, although first extending the analysis between the components of news coverage and negative user emotions to the scenario of social media, echoes previous studies drawn from traditional media and its derivatives, such as web newspapers. Although the era of COVID-19 pandemic gradually brings down the curtain, the commonality of this research and previous studies also contributes to establishing a clearer territory in the field of health crises.}
}
@article{SLOOT2010131,
title = {The cross-disciplinary road to true computational science},
journal = {Journal of Computational Science},
volume = {1},
number = {3},
pages = {131},
year = {2010},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2010.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S1877750310000451},
author = {Peter M.A. Sloot}
}
@article{NIGHTINGALE2016558,
title = {Impact responses of the cervical spine: A computational study of the effects of muscle activity, torso constraint, and pre-flexion},
journal = {Journal of Biomechanics},
volume = {49},
number = {4},
pages = {558-564},
year = {2016},
issn = {0021-9290},
doi = {https://doi.org/10.1016/j.jbiomech.2016.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0021929016000154},
author = {Roger W. Nightingale and Jake Sganga and Hattie Cutcliffe and Cameron R. ‘Dale’ Bass},
keywords = {Biomechanics, Cervical spine, Bilateral facet Dislocation, Buckling, Muscle, Initial conditions, Compression, Pre-flexion, Preflexion, Alignment},
abstract = {Cervical spine injuries continue to be a costly societal problem. Future advancements in injury prevention depend on improved physical and computational models, which are predicated on a better understanding of the neck response during dynamic loading. Previous studies have shown that the tolerance of the neck is dependent on its initial position and its buckling behavior. This study uses a computational model to examine three important factors hypothesized to influence the loads experienced by vertebrae in the neck under compressive impact: muscle activation, torso constraints, and pre-flexion angle of the cervical spine. Since cadaver testing is not practical for large scale parametric analyses, these factors were studied using a previously validated computational model. On average, simulations with active muscles had 32% larger compressive forces and 25% larger shear forces—well in excess of what was expected from the muscle forces alone. In the short period of time required for neck injury, constraints on torso motion increased the average neck compression by less than 250N. The pre-flexion hypothesis was tested by examining pre-flexion angles from neutral (0°) to 64°. Increases in pre-flexion resulted in the largest increases in peak loads and the expression of higher-order buckling modes. Peak force and buckling modality were both very sensitive to pre-flexion angle. These results validate the relevance of prior cadaver models for neck injury and help explain the wide variety of cervical spine fractures that can result from ostensibly similar compressive loadings. They also give insight into the mechanistic differences between burst fractures and lower cervical spine dislocations.}
}
@article{HERAS2011685,
title = {fKenzo: A user interface for computations in Algebraic Topology},
journal = {Journal of Symbolic Computation},
volume = {46},
number = {6},
pages = {685-698},
year = {2011},
issn = {0747-7171},
doi = {https://doi.org/10.1016/j.jsc.2011.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S0747717111000174},
author = {J. Heras and V. Pascual and J. Rubio and F. Sergeraert},
keywords = {Symbolic computation systems, User interface, Constructive Algebraic Topology},
abstract = {fKenzo (= friendly Kenzo) is a graphical user interface providing a user-friendly front-end for the Kenzo system, a Common Lisp program devoted to Algebraic Topology. The fKenzo system provides the user interface itself, an XML intermediary generator-translator and, finally the Kenzo kernel. We describe in this paper the main points of fKenzo, and we explain also the advantages and limitations of fKenzo with respect to Kenzo itself. The text is separated into two parts, trying to cover both the user and the developer perspectives.}
}
@article{ARSLAN2024340,
title = {Computational analysis of linguistic features in speech samples of first-episode bipolar disorder and psychosis},
journal = {Journal of Affective Disorders},
volume = {363},
pages = {340-347},
year = {2024},
issn = {0165-0327},
doi = {https://doi.org/10.1016/j.jad.2024.07.102},
url = {https://www.sciencedirect.com/science/article/pii/S0165032724011595},
author = {Berat Arslan and Elif Kizilay and Burcu Verim and Cemal Demirlek and Muhammed Demir and Ezgi Cesim and Merve S. Eyuboglu and Simge Uzman Ozbek and Ekin Sut and Berna Yalincetin and Emre Bora},
keywords = {Psychosis, Bipolar, First-episode, Natural language processing, Semantic similarity},
abstract = {Background
In recent years, automated analyses using novel NLP methods have been used to investigate language abnormalities in schizophrenia. In contrast, only a few studies used automated language analyses in bipolar disorder. To our knowledge, no previous research compared automated language characteristics of first-episode psychosis (FEP) and bipolar disorder (FEBD) using NLP methods.
Methods
Our study included 53 FEP, 40 FEBD and 50 healthy control participants who are native Turkish speakers. Speech samples of the participants in the Thematic Apperception Test (TAT) underwent automated generic and part-of-speech analyses, as well as sentence-level semantic similarity analysis based on SBERT.
Results
Both FEBD and FEP were associated with the use of shorter sentences and increased sentence-level semantic similarity but less semantic alignment with the TAT pictures. FEP also demonstrated reduced verbosity and syntactic complexity. FEP differed from FEBD in reduced verbosity, decreased first-person singular pronouns, fewer conjunctions, increased semantic similarity as well as shorter sentence and word length. The mean classification accuracy was 82.45 % in FEP vs HC, 71.1 % in FEBD vs HC, and 73 % in FEP vs FEBD. After Bonferroni correction, the severity of negative symptoms in FEP was associated with reduced verbal output and increased 5th percentile of semantic similarity.
Limitations
The main limitation of this study was the cross-sectional nature.
Conclusion
Our findings demonstrate that both patient groups showed language abnormalities, which were more severe and widespread in FEP compared to FEBD. Our results suggest that NLP methods reveal transdiagnostic linguistic abnormalities in FEP and FEBD.}
}
@article{ROLLS2007962,
title = {A computational neuroscience approach to consciousness},
journal = {Neural Networks},
volume = {20},
number = {9},
pages = {962-982},
year = {2007},
note = {Brain and Consciousness},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2007.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S089360800700189X},
author = {Edmund T. Rolls},
keywords = {Consciousness, Higher order thought, Synchrony, Oscillations, Backward masking, Binding},
abstract = {Simultaneous recordings from populations of neurons in the inferior temporal visual cortex show that most of the information about which stimulus was shown is available in the number of spikes (or firing rate) of each neuron, and not from stimulus-dependent synchrony, so that it is unlikely that stimulus-dependent synchrony (or indeed oscillations) is an essential aspect of visual object perception. Neurophysiological investigations of backward masking show that the threshold for conscious visual perception may be set to be higher than the level at which small but significant information is present in neuronal firing and which allows humans to guess which stimulus was shown without conscious awareness. The adaptive value of this may be that the systems in the brain that implement the type of information processing involved in conscious thoughts are not interrupted by small signals that could be noise in sensory pathways. I then consider what computational processes are closely related to conscious processing, and describe a higher order syntactic thought (HOST) computational theory of consciousness. It is argued that the adaptive value of higher order thoughts is to solve the credit assignment problem that arises if a multistep syntactic plan needs to be corrected. It is then suggested that it feels like something to be an organism that can think about its own linguistic, and semantically-based thoughts. It is suggested that qualia, raw sensory and emotional feels, arise secondarily to having evolved such a higher order thought system, and that sensory and emotional processing feels like something because it would be unparsimonious for it to enter the planning, higher order thought, system and not feel like something.}
}
@article{COX2005104,
title = {Metacognition in computation: A selected research review},
journal = {Artificial Intelligence},
volume = {169},
number = {2},
pages = {104-141},
year = {2005},
note = {Special Review Issue},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2005.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S0004370205001530},
author = {Michael T. Cox},
keywords = {Cognitive monitoring, Computational introspection, Limited rationality, Metacognition, Meta-explanation, Metaknowledge, Meta-level architecture, Metareasoning, Self-reference, Reflection},
abstract = {Various disciplines have examined the many phenomena of metacognition and have produced numerous results, both positive and negative. I discuss some of these aspects of cognition about cognition and the results concerning them from the point of view of the psychologist and the computer scientist, and I attempt to place them in the context of computational theories. I examine metacognition with respect to both problem solving (e.g., planning) and to comprehension (e.g., story understanding) processes of cognition.}
}
@article{WHITE1985287,
title = {Thinking about learning about thinking: An interview with Seymour Papert},
journal = {New Ideas in Psychology},
volume = {3},
number = {3},
pages = {287-292},
year = {1985},
issn = {0732-118X},
doi = {https://doi.org/10.1016/0732-118X(85)90025-X},
url = {https://www.sciencedirect.com/science/article/pii/0732118X8590025X},
author = {Barbara Y. White}
}
@article{PAPAVLASOPOULOU201850,
title = {How do you feel about learning to code? Investigating the effect of children’s attitudes towards coding using eye-tracking},
journal = {International Journal of Child-Computer Interaction},
volume = {17},
pages = {50-60},
year = {2018},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2018.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S2212868917300259},
author = {Sofia Papavlasopoulou and Kshitij Sharma and Michail N. Giannakos},
keywords = {Children’s attitudes, Eye-tracking, Coding, Computational thinking, Constructionism},
abstract = {Computational thinking and coding for children are attracting increasing attention. There are several efforts around the globe to implement coding frameworks for children, and there is a need to develop an empirical knowledge base of methods and tools. One major problem for integrating study results into a common body of knowledge is the relatively limited measurements applied, and the relation of the widely used self-reporting methods with more objective measurements, such as biophysical ones. In this study, eye-tracking activity was used to measure children’s learning and activity indicators. The goal of the study is to utilize eye-tracking to understand children’s activity while they learn how to code and to investigate any potential association between children’s attitudes and their gaze. In this contribution, we designed an experiment with 44 children (between 8 and 17 years old) who participated in a full-day construction-based coding activity. We recorded their gaze while they were working and captured their attitudes in relation to their learning, excitement and intention. The results showed a significant relation between children’s attitudes (what they think about coding) and their gaze patterns (how they behaved during coding). Eye-tracking data provide initial insights into the behaviour of children, for example if children have difficulty in extracting information or fail to accomplish an expected task. Therefore, further studies need to be conducted to shed additional light on children’s experience and learning duringcoding.}
}
@incollection{SEJNOWSKI200919,
title = {Computational Methods},
editor = {Larry R. Squire},
booktitle = {Encyclopedia of Neuroscience},
publisher = {Academic Press},
address = {Oxford},
pages = {19-22},
year = {2009},
isbn = {978-0-08-045046-9},
doi = {https://doi.org/10.1016/B978-008045046-9.01396-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780080450469013966},
author = {T.J. Sejnowski},
keywords = {Brain theory, Computational models, Mathematical analysis},
abstract = {Computational neuroscience is a relatively recent approach to understanding how nervous systems develop and interact with a changing and uncertain world. Computational models can be used to interpret experimental data in new ways, to confirm and extend existing hypotheses, and to generate new hypotheses for the function of neural systems. These hypotheses provide links between levels of description, from the molecular level to the systems level. Hypotheses that are tested and validated provide a conceptual framework that can lead to more abstract theories. The ultimate aim of theoretical and computational neuroscience is to provide linking principles from neural mechanisms to behavior.}
}
@incollection{CHOE2005187,
title = {Thinking about Visual Behavior; Learning about Photoreceptor Function},
series = {Current Topics in Developmental Biology},
publisher = {Academic Press},
volume = {69},
pages = {187-213},
year = {2005},
booktitle = {Neural Development},
issn = {0070-2153},
doi = {https://doi.org/10.1016/S0070-2153(05)69007-2},
url = {https://www.sciencedirect.com/science/article/pii/S0070215305690072},
author = {Kwang‐Min Choe and Thomas R. Clandinin},
abstract = {Visual behavioral assays in Drosophila melanogaster were initially developed to explore the genetic control of behavior, but have a rich history of providing conceptual openings into diverse questions in cell and developmental biology. Here, we briefly summarize the early efforts to employ three of these behaviors: phototaxis, the UV‐visible light choice, and the optomotor response. We then discuss how each of these assays has expanded our understanding of neuronal connection specificity and synaptic function. All of these studies have contributed to the development of sophisticated tools for manipulating gene expression, assessing cell fate specification, and visualizing neuronal development. With these tools in hand, the field is now poised to return to the original goal of understanding visual behavior using genetic approaches.}
}
@article{FILOMENA201914,
title = {A computational approach to ‘The Image of the City’},
journal = {Cities},
volume = {89},
pages = {14-25},
year = {2019},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2019.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0264275118309776},
author = {Gabriele Filomena and Judith A. Verstegen and Ed Manley},
keywords = {Image of the City, Cognitive maps, Kevin Lynch, Street network, GIScience},
abstract = {In The Image of the City Lynch describes how individuals perceive and recall features in urban spaces. The most distinctive elements in the urban landscape - categorised in paths, nodes, edges, districts and landmarks - give shape to individuals' mental representation of the city. Lynch’s approach has stimulated research into spatial cognition, urban design and artificial intelligence, and it still represents an essential pillar in the analysis of urban dynamics. Nevertheless, an explicit link between The Image of the City and GIScience has not been completely explored yet. In this paper, a computational approach to The Image of the City is proposed. Different perspectives in spatial cognition and GIS research are integrated to obtain a complete Image of the City, in which the most salient elements are shared by a large part of citizens. Nodes, paths and districts were identified through network science techniques. Methods drawn from the information approach to The Image of the City are used to detect landmarks, integrating the complexity of points of reference in their visual, structural and semantic components, as conceptualised by Lynch and successive research. The methods were applied to the central area of Boston and built using freely available spatial datasets. Results were compared to Lynch’s maps to evaluate the methodology: besides a considerable discrepancy with regard to landmarks, a good correspondence for paths, nodes, edges and districts was found.}
}
@article{TOZZI2018133,
title = {Syntax meets semantics during brain logical computations},
journal = {Progress in Biophysics and Molecular Biology},
volume = {140},
pages = {133-141},
year = {2018},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2018.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S0079610717303140},
author = {Arturo Tozzi and James F. Peters and Andrew A. Fingelkurts and Alexander A. Fingelkurts and Leonid Perlovsky},
keywords = {Borsuk-ulam, Brouwer, Computation, Meaning, Truth, Syntactic},
abstract = {The discrepancy between syntax and semantics is a painstaking issue that hinders a better comprehension of the underlying neuronal processes in the human brain. In order to tackle the issue, we at first describe a striking correlation between Wittgenstein's Tractatus, that assesses the syntactic relationships between language and world, and Perlovsky's joint language-cognitive computational model, that assesses the semantic relationships between emotions and “knowledge instinct”. Once established a correlation between a purely logical approach to the language and computable psychological activities, we aim to find the neural correlates of syntax and semantics in the human brain. Starting from topological arguments, we suggest that the semantic properties of a proposition are processed in higher brain's functional dimensions than the syntactic ones. In a fully reversible process, the syntactic elements embedded in Broca's area project into multiple scattered semantic cortical zones. The presence of higher functional dimensions gives rise to the increase in informational content that takes place in semantic expressions. Therefore, diverse features of human language and cognitive world can be assessed in terms of both the logic armor described by the Tractatus, and the neurocomputational techniques at hand. One of our motivations is to build a neuro-computational framework able to provide a feasible explanation for brain's semantic processing, in preparation for novel computers with nodes built into higher dimensions.}
}
@article{KUGEL1986137,
title = {Thinking may be more than computing},
journal = {Cognition},
volume = {22},
number = {2},
pages = {137-198},
year = {1986},
issn = {0010-0277},
doi = {https://doi.org/10.1016/0010-0277(86)90057-0},
url = {https://www.sciencedirect.com/science/article/pii/0010027786900570},
author = {Peter Kugel},
abstract = {The uncomputable parts of thinking (if there are any) can be studied in much the same spirit that Turing (1950) suggested for the study of its computable parts. We can develop precise accounts of cognitive processes that, although they involve more than computing, can still be modelled on the machines we call ‘computers’. In this paper, I want to suggest some ways that this might be done, using ideas from the mathematical theory of uncomputability (or Recursion Theory). And I want to suggest some uses to which the resulting models might be put. (The reader more interested in the models and their uses than the mathematics and its theorems, might want to skim or skip the mathematical parts.)
Résumé
Les éléments du raisonnement ne relevant pas du calculable (uncomputable), (s'il en existe), peuvent s'etudier dans I'optique suggérée par Turing (1950) pour l'étude des éléments calculables (computable). On peut rendre compte avec précision des processus cognitifs qui, bien qu'impliquant plus que des calculs, peuvent cependant être modélisés sur ordinateurs. Dans cet article l'auteur propose des modalités pour arriver à ces résultats en utilisant les idées de la théorie mathdmatique de la Récursion (uncomputability). L'auteur suggère aussi des utilisations pour les modéles que en découlent (Il est possible au lecteur plus intéressé par les modèles et leurs utilisations que par les mathématiques et les théorèmes de passer rapidement sur la partie mathématique ou d'omettre de la lire.)}
}
@incollection{BLACK2021105,
title = {10 - Mutual benefit from library collaboration with computational biologists: the cropPAL project at the University of Western Australia},
editor = {Jeremy Atkinson},
booktitle = {Technology, Change and the Academic Library},
publisher = {Chandos Publishing},
pages = {105-114},
year = {2021},
series = {Chandos Information Professional Series},
isbn = {978-0-12-822807-4},
doi = {https://doi.org/10.1016/B978-0-12-822807-4.00010-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128228074000105},
author = {Kylie Black},
keywords = {cropPAL, partnerships, collaboration, commercialisation, market research, DeweyFish, ON Prime},
abstract = {In 2016–17, the University of Western Australia (UWA) Library partnered with researchers in the Australian Research Council’s Centre of Excellence in Plant Energy Biology to produce cropPAL2, a database providing the subcellular locations for proteins in crops significant for food production. The project team consisted of computational biologists, software engineers and a librarian, in which the Library contributed expertise in developing search strategies, research data management and enhancing discoverability of cropPAL2 and its dataset. The Library continues to be a key player in this collaboration, a first for UWA, both in the innovative process and as a key driver in directing the development of commercial software for the wider benefit of researchers at UWA and beyond.}
}
@article{MOLINSRUANO2018428,
title = {Phogo: A low cost, free and “maker” revisit to Logo},
journal = {Computers in Human Behavior},
volume = {80},
pages = {428-440},
year = {2018},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2017.09.029},
url = {https://www.sciencedirect.com/science/article/pii/S0747563217305551},
author = {Pablo Molins-Ruano and Carlos Gonzalez-Sacristan and Carlos Garcia-Saura},
keywords = {Computational thinking, Technology education, Educational robots, LOGO, Pre-university education},
abstract = {Today it is almost impossible to spend a single day without depending on an information system, a computer or any other form of computation. Though the starting barrier is low, fundamental concepts are still required in order to manage the technicalities of the engineering environment and everyday computational systems. In 1967, Logo proposed to teach abstract programming concepts by providing a set of functions that had intuitive, visible effects over a robotic Turtle. LOGO was a success, but the robots quickly migrated into computer simulations. From LOGO, many followed. Scratch and Lego Mindstorm are some of the most notorious examples. Both introduced graphical block-based programming interfaces. We propose to bring back the powerful ideas behind LOGO by updating it with state of the art technologies. Phogo combines Python, Arduino and 3D printing into a low cost robot that is easy to build and control. The robot has a pen to draw shapes and can be commanded from a computer via a wireless link that is transparent to the students. The use of a physical robot can make programming more accessible for students with disabilities. The open and maker philosophies behind Phogo makes it more interesting as students will be able to access and study the electronic components. The textual programing language can be a long life companion for the students. In this work we discuss LOGO and other projects inspired by it, and we also share the methodology and design decisions behind Phogo, the results of its application in a workshop and the improvements we are currently developing.}
}
@article{CHEN2016222,
title = {Constraint local principal curve: Concept, algorithms and applications},
journal = {Journal of Computational and Applied Mathematics},
volume = {298},
pages = {222-235},
year = {2016},
issn = {0377-0427},
doi = {https://doi.org/10.1016/j.cam.2015.11.041},
url = {https://www.sciencedirect.com/science/article/pii/S0377042715005956},
author = {Dewang Chen and Jiateng Yin and Shiying Yang and Lingxi Li and Peter Pudney},
keywords = {Constraint local principal curve (CLPC), GPS, Local optimization, Adaptive radius, Principal of nearest neighbor},
abstract = {Existing principal curve algorithms have some drawbacks such as time consuming and narrow application scope in practice, since these algorithms are mainly based on global optimization. In this paper, we present the concept of Constraint Local Principal Curve (CLPC), which uses local optimization methods and restricts the principal curve with two fixed endpoints to reduce the computational complexity. In addition, we propose three CLPC algorithms by Local Optimization and Adaptive Radius to expand the range of applications and increase the solution quality. The first algorithm, i.e., CLPCg is based on greedy thinking. The second algorithm, i.e., CLPCs uses one dimensional search and the last algorithm CLPCc combines the greedy thinking and one dimensional search. Then, we define six performance indices to evaluate the performance of the CLPC algorithms. Finally, we present some numerical experiments with three simulation data sets and two GPS measured data sets in both highway and railway. The results indicate that all of the three CLPC algorithms can obtain high-accuracy data from multiple low-accuracy data efficiently. The CLPC algorithms can improve the accuracy and computational speed compared with the existing K-segment principal curve (KPC) algorithm. In addition, CLPCc outperforms CLPCg and CLPCs according to the comprehensive experiments while CLPCg runs much faster than other ones.}
}
@article{STOLPE2024100159,
title = {Artificial intelligence literacy for technology education},
journal = {Computers and Education Open},
volume = {6},
pages = {100159},
year = {2024},
issn = {2666-5573},
doi = {https://doi.org/10.1016/j.caeo.2024.100159},
url = {https://www.sciencedirect.com/science/article/pii/S2666557324000016},
author = {Karin Stolpe and Jonas Hallström},
keywords = {AI literacy, Ethical issues, AI in education},
abstract = {The interest in artificial intelligence (AI) in education has erupted during the last few years, primarily due to technological advances in AI. It is therefore argued that students should learn about AI, although it is debated exactly how it should be applied in education. AI literacy has been suggested as a way of defining competencies for students to acquire to meet a future everyday- and working life with AI. This study argues that researchers and educators need a framework for integrating AI literacy into technological literacy, where the latter is viewed as a multiliteracy. This study thus aims to critically analyse and discuss different components of AI literacy found in the literature in relation to technological literacy. The data consists of five AI literacy frameworks related to three traditions of technological knowledge: technical skills, technological scientific knowledge, and socio-ethical technical understanding. The results show that AI literacy for technology education emphasises technological scientific knowledge (e.g., knowledge about what AI is, how to recognise AI, and systems thinking) and socio-ethical technical understanding (e.g., AI ethics and the role of humans in AI). Technical skills such as programming competencies also appear but are less emphasised. Implications for technology education are also discussed, and a framework for AI literacy for technology education is suggested.}
}
@article{LEE2025100890,
title = {Generative ecodesign for mechanical products: A design workflow},
journal = {Cleaner Engineering and Technology},
volume = {24},
pages = {100890},
year = {2025},
issn = {2666-7908},
doi = {https://doi.org/10.1016/j.clet.2025.100890},
url = {https://www.sciencedirect.com/science/article/pii/S2666790825000138},
author = {Amos Wei Lun Lee and Kevin Kai Wern Seah and Bing Feng Ng and Ee Teng Zhang and Wen Feng Lu and Jonathan Sze Choong Low},
keywords = {Carbon emission, Generative design, Product design, Environmental sustainability, Ecodesign},
abstract = {Harnessing advancements in artificial intelligence, generative design holds great potential to support designers in their ecodesign efforts by enabling them to explore design solutions beyond the limits of their imagination and expertise. However, a systematic literature review on the application of generative design in ecodesign reveals a clear underrepresentation, highlighting a missed opportunity in the field. To bridge this gap, a seven-component generative ecodesign workflow for mechanical products was developed. This workflow combines generative design algorithms, typically used for geometry lightweighting, with life cycle thinking. It facilitates the generation, evaluation, and identification of design solutions by considering the design tri-factor: material choice, manufacturing process, and geometry. This represents the first reported product ecodesign tool to integrate generative design with ecodesign principles while simultaneously addressing all three elements of the design tri-factor. To showcase its utility, environmentally optimal design alternatives were created for a mountain bicycle's handlebar stem.}
}
@article{JARMAN2022225,
title = {Critical measurement issues in the assessment of social media influence on body image},
journal = {Body Image},
volume = {40},
pages = {225-236},
year = {2022},
issn = {1740-1445},
doi = {https://doi.org/10.1016/j.bodyim.2021.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S1740144521001583},
author = {Hannah K. Jarman and Siân A. McLean and Scott Griffiths and Samantha J. Teague and Rachel F. Rodgers and Susan J. Paxton and Emma Austen and Emily Harris and Trevor Steward and Adrian Shatte and Long {Khanh-Dao Le} and Tarique Anwar and Cathrine Mihalopoulos and Alexandra G. Parker and Zali Yager and Matthew Fuller-Tyszkiewicz},
keywords = {Social media, Body image, Qualitative, Survey, Experimental, Momentary assessment, Web scraping, Computational modelling, Measurement, Assessment},
abstract = {Progress towards understanding how social media impacts body image hinges on the use of appropriate measurement tools and methodologies. This review provides an overview of common (qualitative, self-report survey, lab-based experiments) and emerging (momentary assessment, computational) methodological approaches to the exploration of the impact of social media on body image. The potential of these methodologies is detailed, with examples illustrating current use as well as opportunities for expansion. A key theme from our review is that each methodology has provided insights for the body image research field, yet is insufficient in isolation to fully capture the nuance and complexity of social media experiences. Thus, in consideration of gaps in methodology, we emphasise the need for big picture thinking that leverages and combines the strengths of each of these methodologies to yield a more comprehensive, nuanced, and robust picture of the positive and negative impacts of social media.}
}
@article{FIGUEIRASAMPAIO2009484,
title = {A constructivist computational tool to assist in learning primary school mathematical equations},
journal = {Computers & Education},
volume = {53},
number = {2},
pages = {484-492},
year = {2009},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2009.03.012},
url = {https://www.sciencedirect.com/science/article/pii/S036013150900075X},
author = {Aleandra da Silva Figueira-Sampaio and Eliane Elias Ferreira {dos Santos} and Gilberto Arantes Carrijo},
keywords = {Elementary education, Improving classroom teaching, Interactive learning environments, Virtual reality},
abstract = {In constructivist principles, learning is a process in which individuals construct knowledge. Research in Mathematics Education looks for ways to make mathematics education less dry and more attractive. When solving polynomial equations of the first degree, it is very common for teachers to work with the mistaken idea of “changing the sign” when “moving” the member. To minimize this problem, a balance can be used to illustrate the idea of equilibrium and also properties of equality. The objectives of this study were (1) develop a computational tool to replace a conventional balance in practical mathematics exercises thereby solving two material challenges for Brazilian teachers: verifying the accuracy of balances and the lack of student physical and social activity through direct participation; (2) determine how substituting the conventional balance with a computational tool for the solution of first degree polynomial equations affected the aspects inherent in the learning process like motivation, cooperation, dialogue, discussion, reflection, reciprocity, negotiation and responsibility. The results indicate that the cognitive computational tool met the challenges of Brazilian teachers. First, because it lacks mechanisms that need to be verified for accuracy in order to demonstrate equilibrium. Second, because it allows the direct participation of students (physical experience) and the use of the tool in small groups (social experience). The hands on completion of the activity, realistic appearance, the interaction with the tool, visual feedback on the panel, and two students using the same tool awakened motivation, responsibility for completing the activity, dialogue, cooperation, discussion and reflection. Doing the experiment with others aroused concern about the learning of others and reciprocity of knowledge for the improvement of the procedure to be constructed for solving 1st degree equations.}
}
@article{DENHAAN2011175,
title = {Computational suite of models with heterogeneous agents II: Multi-country real business cycle models},
journal = {Journal of Economic Dynamics and Control},
volume = {35},
number = {2},
pages = {175-177},
year = {2011},
note = {Computational Suite of Models with Heterogeneous Agents II: Multi-Country Real Business Cycle Models},
issn = {0165-1889},
doi = {https://doi.org/10.1016/j.jedc.2010.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S0165188910002149},
author = {Wouter J. {Den Haan} and Kenneth L. Judd and Michel Juillard},
keywords = {Numerical solutions, Simulations, Approximations},
abstract = {This paper describes the second model considered in the computational suite project that compares the performance of different numerical algorithms. It is a multi-country model in which countries face different productivity shocks. Solving such models is a challenging numerical problem unless the number of countries is small. The solutions are functions of a large set of arguments and the functional forms are unknown. Moreover, the solution procedures have to deal with high-dimensional integration problems.}
}
@article{BRODLAND201562,
title = {How computational models can help unlock biological systems},
journal = {Seminars in Cell & Developmental Biology},
volume = {47-48},
pages = {62-73},
year = {2015},
note = {Coding and non-coding RNAs & Mammalian development},
issn = {1084-9521},
doi = {https://doi.org/10.1016/j.semcdb.2015.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S1084952115001287},
author = {G. Wayne Brodland},
keywords = {Review, Models, Computational modelling, Cell mechanics, Tissue mechanics, Embryo mechanics, Embryogenesis, Morphogenetic movements, Developmental mechanisms, Biological systems},
abstract = {With computation models playing an ever increasing role in the advancement of science, it is important that researchers understand what it means to model something; recognize the implications of the conceptual, mathematical and algorithmic steps of model construction; and comprehend what models can and cannot do. Here, we use examples to show that models can serve a wide variety of roles, including hypothesis testing, generating new insights, deepening understanding, suggesting and interpreting experiments, tracing chains of causation, doing sensitivity analyses, integrating knowledge, and inspiring new approaches. We show that models can bring together information of different kinds and do so across a range of length scales, as they do in multi-scale, multi-faceted embryogenesis models, some of which connect gene expression, the cytoskeleton, cell properties, tissue mechanics, morphogenetic movements and phenotypes. Models cannot replace experiments nor can they prove that particular mechanisms are at work in a given situation. But they can demonstrate whether or not a proposed mechanism is sufficient to produce an observed phenomenon. Although the examples in this article are taken primarily from the field of embryo mechanics, most of the arguments and discussion are applicable to any form of computational modelling.}
}
@article{LEE2012579,
title = {Developing an efficient computational method that estimates the ability of students in a Web-based learning environment},
journal = {Computers & Education},
volume = {58},
number = {1},
pages = {579-589},
year = {2012},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2011.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S0360131511002259},
author = {Young-Jin Lee},
keywords = {Ability estimation, Educational data mining, Item response theory, Log file analysis, Web-based learning environment},
abstract = {This paper presents a computational method that can efficiently estimate the ability of students from the log files of a Web-based learning environment capturing their problem solving processes. The computational method developed in this study approximates the posterior distribution of the student’s ability obtained from the conventional Bayes Modal Estimation (BME) approach to a simple Gaussian function in order to reduce the amount of computations required in the subsequent ability update processes. To verify the correctness and usefulness of this method, the abilities of 407 college students who solved 61 physics problems in a Web-based learning environment were estimated from the log files of the learning environment. The reduced chi-squared statistic and Pearson’s chi-square test for the goodness of fit indicate that the estimated abilities were able to successfully explain the observed problem solving performance of students within error. The educational implications of estimating the ability of students in Web-based learning environments were also discussed.}
}
@article{KLIMOVA20171,
title = {Where Youth strives in Computational Science: retrospective Analysis of Young Scientist Conference in HPC and Simulation},
journal = {Procedia Computer Science},
volume = {119},
pages = {1-7},
year = {2017},
note = {6th International Young Scientist Conference on Computational Science, YSC 2017, 01-03 November 2017, Kotka, Finland},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.11.153},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917323633},
author = {Alexandra Klimova and Anna Bilyatdinova and Jari Kortelainen and Peter M.A. Sloot and Alexander Boukhanovsky},
keywords = {computational science, high-performance computing, leading scientists program, international conference},
abstract = {This volume presents the selected papers of young computational scientists – participants of YSC-2017. Annual Young Scientist Conferences (YSC) in high performance computing, modeling and simulation are traditionally held since 2012 by the University of Amsterdam (the Netherlands) and ITMO University (St. Petersburg, Russia) as the open international events which aim to develop a dialogue about the present and future of computational science with a focus on applications of modeling and simulation solving a wide range of problems of science, industry, and business. The conference has already been organized for six times, which gives us an opportunity for retrospective analysis of conference’ results and trends in high performance computing (HPC). The results are presented in this editorial.}
}
@article{SWANSON2020100961,
title = {The relationship between executive processing and computational growth among monolingual and english learners with and without math difficulties: Does it help to be bilingual?},
journal = {Cognitive Development},
volume = {56},
pages = {100961},
year = {2020},
issn = {0885-2014},
doi = {https://doi.org/10.1016/j.cogdev.2020.100961},
url = {https://www.sciencedirect.com/science/article/pii/S0885201420301155},
author = {H. Lee Swanson},
keywords = {Math difficulties, English learner, Bilingual, Working memory, Cognition, Math computation},
abstract = {Does the commonly reported math achievement gap among elementary school monolingual and English learners (ELs) with and without math difficulties reflect variations in executive processing? This cohort-sequential study (N = 841) explored the cognitive processes that underlie in elementary school children’s math computational growth who are monolingual (English-only) or English learners with Spanish as a first language. Three language subgroups (proficient ELs [relatively proficient in both English and Spanish vocabulary], less proficient ELs [more proficient in English when compared to Spanish vocabulary] and monolingual [English-only]) children with and without math difficulties (MD) were compared on measures of math computation and cognitive growth. As expected, children with MD identified at wave 1 underperformed children without MD in their rate of growth and their level of computational and working memory (WM) performance in the final testing wave. However, two additional findings occurred. First, executive processing measures (working memory and inhibition) were significantly related to computational growth even when measures of reading, fluid intelligence, STM, naming speed and SES were partialed in the analysis. Second, no statistical advantages in executive processing or computation emerged in favor of EL children relative to monolingual children. Taken together, the results support the notion that (a) growth in math computation is tied to growth in the executive system and (b) EL children relatively proficient in English and Spanish experience no growth advantages in WM or computation compared to monolingual children.}
}
@article{YANG20101297,
title = {Computational optimization, modelling and simulation–a paradigm shift},
journal = {Procedia Computer Science},
volume = {1},
number = {1},
pages = {1297-1300},
year = {2010},
note = {ICCS 2010},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2010.04.144},
url = {https://www.sciencedirect.com/science/article/pii/S1877050910001456},
author = {Xin-She Yang and Slawomir Koziel},
keywords = {Algorithm, Black-box modelling, Computational optimization, Derivative-free method, Optimization algorithm, Modelling, Nonlinear optimization, Surragate-based optimization, Simulation},
abstract = {Computational optimization forms an integrated part of modern computational science. Any good design should intend to achieve certain optimality, though optimal solutions are often difficult to find in practice since uncertainty and nonlinearity always present in almost all real-world problems. As resources, time and money are always limited, optimization becomes even more important in practice. This workshop on Computational Optimization, Modelling and Simulation (COMS 2010) at ICCS 2010 will summarize the latest developments of optimization and modelling and their applications in science, engineering and industry}
}
@article{GONDOCS2024102769,
title = {AI in medical diagnosis: AI prediction & human judgment},
journal = {Artificial Intelligence in Medicine},
volume = {149},
pages = {102769},
year = {2024},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2024.102769},
url = {https://www.sciencedirect.com/science/article/pii/S0933365724000113},
author = {Dóra Göndöcs and Viktor Dörfler},
keywords = {Medical diagnosis, Melanoma, Human-computer interaction, Augmented intelligence, Explainability, Responsible AI},
abstract = {AI has long been regarded as a panacea for decision-making and many other aspects of knowledge work; as something that will help humans get rid of their shortcomings. We believe that AI can be a useful asset to support decision-makers, but not that it should replace decision-makers. Decision-making uses algorithmic analysis, but it is not solely algorithmic analysis; it also involves other factors, many of which are very human, such as creativity, intuition, emotions, feelings, and value judgments. We have conducted semi-structured open-ended research interviews with 17 dermatologists to understand what they expect from an AI application to deliver to medical diagnosis. We have found four aggregate dimensions along which the thinking of dermatologists can be described: the ways in which our participants chose to interact with AI, responsibility, ‘explainability’, and the new way of thinking (mindset) needed for working with AI. We believe that our findings will help physicians who might consider using AI in their diagnosis to understand how to use AI beneficially. It will also be useful for AI vendors in improving their understanding of how medics want to use AI in diagnosis. Further research will be needed to examine if our findings have relevance in the wider medical field and beyond.}
}
@article{LEE2023121253,
title = {Artificial intelligence enabled energy-efficient heating, ventilation and air conditioning system: Design, analysis and necessary hardware upgrades},
journal = {Applied Thermal Engineering},
volume = {235},
pages = {121253},
year = {2023},
issn = {1359-4311},
doi = {https://doi.org/10.1016/j.applthermaleng.2023.121253},
url = {https://www.sciencedirect.com/science/article/pii/S1359431123012826},
author = {Dasheng Lee and Shang-Tse Lee},
keywords = {Artificial intelligence (AI), Heating, ventilation and air conditioning (HVAC), Energy saving, Design thinking, Hardware upgrade},
abstract = {Literature search across different databases showed that the application of artificial intelligence (AI) in heating, ventilation and air conditioning (HVAC) equipment has been extensively studied. On the commercial front, Internet search suggested that numerous AI-equipped HVAC products have been launched. These products apply AI in very different ways, and their energy-saving effects are also different. Such divergence and uncertain energy-saving effects may hinder AI application. To overcome this difference and accelerate the development of AI applications, the present study proposed a double diamond preferred reporting items for systematic reviews and meta-analysis (PRISMA) method—an analysis method that combined literature review with design thinking. Through a process of divergence-convergence-re-divergence, this study described how to design AI functions for energy-efficient HVAC systems, taking into account more than 1,700 research papers it had reviewed. However, there was a limitation on the part re-divergence. Because the vast majority of research papers only published results of successful AI applications, no cases of failed applications were available for review, making it impossible to re-think profoundly. Instead, this study collected raw data from 88 research papers and used these data to analyze the effectiveness and ineffectiveness of AI in depth. It was concluded that AI application must be accompanied by necessary hardware improvements to achieve effective energy savings. AI-enabled energy-saving effects for chillers, air-handing units, heating systems, and air conditioners, as well as corresponding hardware upgrades, were discussed.}
}
@article{TOIVONEN202052,
title = {Computational creativity beyond machine learning},
journal = {Physics of Life Reviews},
volume = {34-35},
pages = {52-53},
year = {2020},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2020.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S1571064520300373},
author = {Hannu Toivonen}
}
@article{TURKHEIMER2015211,
title = {The brain's code and its canonical computational motifs. From sensory cortex to the default mode network: A multi-scale model of brain function in health and disease},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {55},
pages = {211-222},
year = {2015},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2015.04.014},
url = {https://www.sciencedirect.com/science/article/pii/S0149763415001189},
author = {Federico E. Turkheimer and Robert Leech and Paul Expert and Louis-David Lord and Anthony C. Vernon},
keywords = {Brain networks, Functional connectivity, Interneurons, Gamma-oscillations, NMDA, GABA, Lateral inhibition, Feedback inhibition, Feed-forward inhibition, Canonical neural computation, Motifs, Default mode network, fMRI, Schizophrenia},
abstract = {A variety of anatomical and physiological evidence suggests that the brain performs computations using motifs that are repeated across species, brain areas, and modalities. The computational architecture of cortex, for example, is very similar from one area to another and the types, arrangements, and connections of cortical neurons are highly stereotyped. This supports the idea that each cortical area conducts calculations using similarly structured neuronal modules: what we term canonical computational motifs. In addition, the remarkable self-similarity of the brain observables at the micro-, meso- and macro-scale further suggests that these motifs are repeated at increasing spatial and temporal scales supporting brain activity from primary motor and sensory processing to higher-level behaviour and cognition. Here, we briefly review the biological bases of canonical brain circuits and the role of inhibitory interneurons in these computational elements. We then elucidate how canonical computational motifs can be repeated across spatial and temporal scales to build a multiplexing information system able to encode and transmit information of increasing complexity. We point to the similarities between the patterns of activation observed in primary sensory cortices by use of electrophysiology and those observed in large scale networks measured with fMRI. We then employ the canonical model of brain function to unify seemingly disparate evidence on the pathophysiology of schizophrenia in a single explanatory framework. We hypothesise that such a framework may also be extended to cover multiple brain disorders which are grounded in dysfunction of GABA interneurons and/or these computational motifs.}
}
@article{ISMAILOVA2018183,
title = {Basic Constructions of the Computational Model of Support for Access Operations to the Semantic Network},
journal = {Procedia Computer Science},
volume = {123},
pages = {183-188},
year = {2018},
note = {8th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2017 (Eighth Annual Meeting of the BICA Society), held August 1-6, 2017 in Moscow, Russia},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.01.030},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918300310},
author = {Larisa Yu. Ismailova and Viacheslav E. Wolfengagen and Sergey V. Kosikov},
keywords = {informational objects, semantics, computational model, semantic network, intensional logic, access operation},
abstract = {The paper considers the approach to solving the task of storing data in the Web environment using semantic networks (SN). The control over the access to SN is identified as a critical task. An approach to the solution based on the use of the controlling SN is proposed. The rationale for the approach involves developing a computational model for supporting the access operations. The construction of a model based on intensional logic is proposed. The basic logical constructions, necessary for building a model, are considered. The testing of the model’s constructions was performed when building the tools of semantic support for the implementation of the best available technologies (BAT).}
}
@article{VANDENAMEELE2014334,
title = {Thinking out of the dish: what to learn about cortical development using pluripotent stem cells},
journal = {Trends in Neurosciences},
volume = {37},
number = {6},
pages = {334-342},
year = {2014},
issn = {0166-2236},
doi = {https://doi.org/10.1016/j.tins.2014.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S0166223614000447},
author = {Jelle {van den Ameele} and Luca Tiberi and Pierre Vanderhaeghen and Ira Espuny-Camacho},
abstract = {The development of the cerebral cortex requires the tightly coordinated generation of dozens of neuronal subtypes that will populate specific layers and areas. Recent studies have revealed how pluripotent stem cells (PSC), whether of mouse or human origin, can differentiate into a wide range of cortical neurons in vitro, which can integrate appropriately into the brain following in vivo transplantation. These models are largely artificial but recapitulate a substantial fraction of the complex temporal and regional patterning events that occur during in vivo corticogenesis. Here, we review these findings with emphasis on the new perspectives that they have brought for understanding of cortical development, evolution, and diseases.}
}
@incollection{MAERTENS2025358,
title = {Regrettable Substitutions},
editor = {Béla Török},
booktitle = {Encyclopedia of Green Chemistry (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {358-364},
year = {2025},
isbn = {978-0-443-28923-1},
doi = {https://doi.org/10.1016/B978-0-443-15742-4.00099-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443157424000995},
author = {Alexandra Maertens and Thomas Hartung},
keywords = {Alternative assessments, Chemical policy, Environmental justice, Exposure science, Green toxicology, Hazard, Life cycle analysis, Toxicity mechanisms},
abstract = {Regrettable substitutions refer to the unintended consequences that arise when replacing one substance with another, often resulting in new problems or uncertainties. Regrettable substitutions have been observed in various functional classes, such as flame retardants, where initial solutions aimed at enhancing fire safety but have raised concerns about persistent environmental pollution and potential health risks. Regrettable substitutions are often caused by a lack of data about hazard or exposure, life-cycle considerations or a failure to consider other functionality more broadly. Initial solutions aimed at enhancing fire safety, product performance or crop protection have ended up raising new concerns about persistent environmental pollution, ecosystem effects, occupational hazards and long-term health risks. To avoid future regrettable substitutions, a more holistic, data-driven approach to chemical alternatives assessment is needed. This should incorporate human-relevant mechanistic toxicity testing, quantitative exposure modeling, life cycle thinking, and consideration of safer chemistry solutions that maintain product functionality. Enhanced cross-sector collaboration, data sharing, and clear risk communication to consumers is also critical. Integrating these green toxicology principles into chemical design and evaluation can help achieve sustainable substitutions that maximize benefits and minimize risks.}
}
@article{CUI2022104203,
title = {Pore-network modeling of flow in shale nanopores: Network structure, flow principles, and computational algorithms},
journal = {Earth-Science Reviews},
volume = {234},
pages = {104203},
year = {2022},
issn = {0012-8252},
doi = {https://doi.org/10.1016/j.earscirev.2022.104203},
url = {https://www.sciencedirect.com/science/article/pii/S0012825222002872},
author = {Ronghao Cui and S. Majid Hassanizadeh and Shuyu Sun},
keywords = {Pore-network modeling, Shale rock, Nanoporous media, Flow theory, Thermodynamics},
abstract = {Hydrocarbons in subsurface nanoporous media, such as shale, are promising energy resources to compensate for the shortage of conventional reservoirs. Pore-network modeling serves as a valuable tool for simulating microscale fluid transport and elucidating flow physics in porous media. However, traditional pore-network models have failed to capture features of spatial structure and fluid flow in unconventional shale rock. This work presents a critical review of pore-network modeling of single-phase and two-phase flow in shale rock. Pore-network modeling advances of shale are reviewed based on three major parts: network morphology and geometries, flow principles in nanocapillaries, and pore-network computational algorithms. First, based on key geological features of shale rock, we analyze network topology, multiscale network, pore geometries, and network representativeness of shale pore-network models. Then, we discuss four important aspects that may influence flow principles of fluids in nanocapillaries: gas and liquid slippage, sorption and diffusion behavior, hydrocarbon thermodynamics, and the presence of water. Finally, we present pore-network modeling methods used for flow simulations in shale rock, including quasi-static and dynamic algorithms. We hope that this review could shed light on fundamentals of pore-network modeling of shale rock.}
}
@article{ATANCE2010297,
title = {Thinking about false belief: It’s not just what children say, but how long it takes them to say it},
journal = {Cognition},
volume = {116},
number = {2},
pages = {297-301},
year = {2010},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2010.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S0010027710001101},
author = {Cristina M. Atance and Daniel M. Bernstein and Andrew N. Meltzoff},
keywords = {Theory of mind, False-belief reasoning, Conceptual development, Response latencies},
abstract = {We examined 240 children’s (3.5-, 4.5-, and 5.5-year-olds) latency to respond to questions on a battery of false-belief tasks. Response latencies exhibited a significant cross-over interaction as a function of age and response type (correct vs. incorrect). 3.5-year-olds’ incorrect latencies were faster than their correct latencies, whereas the opposite pattern emerged for 4.5- and 5.5-year-olds. Although these results are most consistent with conceptual change theories of false-belief reasoning, no extant theory fully accounts for our data pattern. We argue that response latency data provide new information about underlying cognitive processes in theory of mind reasoning, and can shed light on concept acquisition more broadly.}
}
@article{BRASCH2012299,
title = {Thinking outside the cell: how cadherins drive adhesion},
journal = {Trends in Cell Biology},
volume = {22},
number = {6},
pages = {299-310},
year = {2012},
issn = {0962-8924},
doi = {https://doi.org/10.1016/j.tcb.2012.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S0962892412000529},
author = {Julia Brasch and Oliver J. Harrison and Barry Honig and Lawrence Shapiro},
abstract = {Cadherins are a superfamily of cell surface glycoproteins whose ectodomains contain multiple repeats of β-sandwich extracellular cadherin (EC) domains that adopt a similar fold to immunoglobulin domains. The best characterized cadherins are the vertebrate ‘classical’ cadherins, which mediate adhesion via trans homodimerization between their membrane-distal EC1 domains that extend from apposed cells, and assemble intercellular adherens junctions through cis clustering. To form mature trans adhesive dimers, cadherin domains from apposed cells dimerize in a ‘strand-swapped’ conformation. This occurs in a two-step binding process involving a fast-binding intermediate called the ‘X-dimer’. Trans dimers are less flexible than cadherin monomers, a factor that drives junction assembly following cell–cell contact by reducing the entropic cost associated with the formation of lateral cis oligomers. Cadherins outside the classical subfamily appear to have evolved distinct adhesive mechanisms that are only now beginning to be understood.}
}
@article{MAXIM2025,
title = {Identifying Key Principles and Commonalities in Digital Serious Game Design Frameworks: Scoping Review},
journal = {JMIR Serious Games},
volume = {13},
year = {2025},
issn = {2291-9279},
doi = {https://doi.org/10.2196/54075},
url = {https://www.sciencedirect.com/science/article/pii/S2291927925000315},
author = {Raluca Ionela Maxim and Joan Arnedo-Moreno},
keywords = {entertainment game design frameworks, serious game design frameworks, design principles, empathic design thinking, artificial intelligence},
abstract = {Background
Digital serious games (DSGs), designed for purposes beyond entertainment and consumed via electronic devices, have garnered attention for their potential to enhance learning and promote behavior change. Their effectiveness depends on the quality of their design. Frameworks for DSG design can guide the creation of engaging games tailored to objectives such as education, health, and social impact.
Objective
This study aims to review, analyze, and synthesize the literature on digital entertainment game design frameworks and DSG design frameworks (DSGDFWs). The focus is on conceptual frameworks offering high-level guidance for the game creation process rather than component-specific tools. We explore how these frameworks can be applied to create impactful serious games in fields such as health care and education. Key goals include identifying design principles, commonalities, dependencies, gaps, and opportunities in the literature. Suggestions for future research include empathic design thinking, artificial intelligence integration, and iterative improvements. The findings culminate in a synthesized 4-phase design process, offering generic guidelines for designers and developers to create effective serious games that benefit society.
Methods
A 2-phase methodology was used: a scoping literature review and cluster analysis. A targeted search across 7 databases (ACM, Scopus, Springer, IEEE, Elsevier, JMIR Publications, and SAGE) was conducted using PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) 2020 guidelines. Studies included academic or industry papers evaluating digital game design frameworks. Cluster analysis was applied to categorize the data, revealing trends and correlations among frameworks.
Results
Of 987 papers initially identified, 25 (2.5%) met the inclusion criteria, with an additional 22 identified through snowballing, resulting in 47 papers. These papers presented 47 frameworks, including 16 (34%) digital entertainment game design frameworks and 31 (66%) DSGDFWs. Thematic analysis grouped frameworks into categories, identifying patterns and relationships between design elements. Commonalities, dependencies, and gaps were analyzed, highlighting opportunities for empathic design thinking and artificial intelligence applications. Key considerations in DSG design were identified and presented in a 4-phase design baseline with the outcome of a list of design guidelines that might, according to the literature, be applied to an end-to-end process of designing and building future innovative solutions.
Conclusions
The main benefits of using DSGDFWs seem to be related to enhancing the effectiveness of serious games in achieving their intended objectives, such as learning, behavior change, and social impact. Limitations primarily seem to be related to constraints associated with the specific contexts in which the serious games are developed and used. Approaches in the future should be aimed at refining and adapting existing frameworks to different contexts and purposes, as well as exploring new frameworks that incorporate emerging technologies and design principles.}
}
@article{DOIRON2019iii,
title = {Editorial overview: Computational neuroscience},
journal = {Current Opinion in Neurobiology},
volume = {58},
pages = {iii-vii},
year = {2019},
note = {Computational Neuroscience},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2019.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S0959438819300728},
author = {Brent Doiron and Máté Lengyel}
}
@article{HAO20231,
title = {A Commentary on Towards autonomous artificial agents with an active self: Modeling sense of control in situated action},
journal = {Cognitive Systems Research},
volume = {79},
pages = {1-3},
year = {2023},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2022.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S1389041722001085},
author = {Chenxu Hao and Nele Russwinkel and Daniel F.B. Haeufle and Philipp Beckerle},
keywords = {Human–robot interaction, Unified models of HRI, Anticipatory thinking},
abstract = {Kahl et al., (2022) present a computational model of an autonomous agent implemented with an active self. With ideas based on the Free Energy Principle (Friston and Kiebel, 2009), their model tackles the challenge to unify higher-level cognitive activities and lower-level sensorimotor control as the autonomous agent maintains situational awareness while interacting with the environment. While Kahl et al., (2022) focus on modeling a single agent, we argue that this challenge similarly appears in modeling human–robot interaction (HRI). In this commentary, we discuss how the conceptual framework from Kahl et al., (2022) could inspire unified models of physical and cognitive HRI and how the modeling approach from Kahl et al., (2022) can potentially be applied to anticipatory thinking in robotics to support the human in daily life.}
}
@article{DOUKAS2013227,
title = {Modelling of linguistic variables in multicriteria energy policy support},
journal = {European Journal of Operational Research},
volume = {227},
number = {2},
pages = {227-238},
year = {2013},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2012.11.026},
url = {https://www.sciencedirect.com/science/article/pii/S0377221712008740},
author = {Haris Doukas},
keywords = {Decision support, Multicriteria analysis, Linguistic variables, Energy policy, Sustainable development},
abstract = {The climate change and the increasing complexity of the energy sector along with the prerequisite for sustainability have broadened the energy policy shaping field by bringing out new challenges. Decision support tools and methods, such as Multicriteria Decision Aid (MCDA), are necessary for energy policy, in the pursuit of appropriate approaches necessary to support the restructuring of the energy sector, concerning patterns of energy extraction, generation, transformation and use, from unsustainable to sustainable forms of development. Papers devoted to the investigation of MCDA models using linguistic variables for energy policy support seem to be not available in the international literature. The scope of this paper is to explore different linguistic representation and computational models in MCDA that are or can be applied to energy policy support and to establish a clear linkage between them. This paper argues that MCDA methodologies with direct computation on linguistic variables can support energy policy frameworks, bridging the gap between energy policy makers thinking, reasoning, representation and computing. Finally, current trends, open questions and prospects in this topic are pointed out.}
}
@article{SHARP2025118,
title = {Anxiety involves altered planning},
journal = {Trends in Cognitive Sciences},
volume = {29},
number = {2},
pages = {118-121},
year = {2025},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324002924},
author = {Paul B. Sharp},
keywords = {planning, anxiety, reinforcement learning},
abstract = {Clinicians have suggested but not shown how anxiety involves altered planning. Here, I synthesize and extend computational models of planning in a framework that can be used to explain planning biases in anxiety. To spur its development, I spotlight two of its promising areas: task construal and meta-control.}
}
@article{TREMOLIERE2012379,
title = {Mortality salience and morality: Thinking about death makes people less utilitarian},
journal = {Cognition},
volume = {124},
number = {3},
pages = {379-384},
year = {2012},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2012.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S0010027712001035},
author = {Bastien Trémolière and Wim De Neys and Jean-François Bonnefon},
keywords = {Mortality salience, Moral judgment, Utilitarian responses, Cognitive resources},
abstract = {According to the dual-process model of moral judgment, utilitarian responses to moral conflict draw on limited cognitive resources. Terror Management Theory, in parallel, postulates that mortality salience mobilizes these resources to suppress thoughts of death out of focal attention. Consequently, we predicted that individuals under mortality salience would be less likely to give utilitarian responses to moral conflicts. Two experiments corroborated this hypothesis. Experiment 1 showed that utilitarian responses to non-lethal harm conflicts were less frequent when participants were reminded of their mortality. Experiment 2 showed that the detrimental effect of mortality salience on utilitarian conflict judgments was comparable to that of an extreme concurrent cognitive load. These findings raise the question of whether private judgment and public debate about controversial moral issues might be shaped by mortality salience effects, since these issues (e.g., assisted suicide) often involve matters of life and death.}
}
@article{COWARD2014164,
title = {Brain Computational Primitives},
journal = {Procedia Computer Science},
volume = {41},
pages = {164-175},
year = {2014},
note = {5th Annual International Conference on Biologically Inspired Cognitive Architectures, 2014 BICA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.11.100},
url = {https://www.sciencedirect.com/science/article/pii/S1877050914015452},
author = {L. Andrew Coward},
abstract = {The brain uses computational primitives that are analogous with but qualitatively different from the computational primitives used in electronic computer systems. The primary computational primitives of the brain are described, and their implementation in anatomy and physiology discussed. Combinations and sequences of these primitives implement cognitive tasks. Many of the primitives have also been implemented electronically. The brain is a very effective general learning system, and although an artificial general intelligence system will be required to learn a different range of behaviours from the brain, the computational primitives used by the brain are the best available guide to appropriate primitives for such an AGI system.}
}
@article{BEYTIA2022101732,
title = {Towards a Digital Reflexive Sociology: Using Wikipedia's Biographical Repository as a Reflexive Tool},
journal = {Poetics},
volume = {95},
pages = {101732},
year = {2022},
issn = {0304-422X},
doi = {https://doi.org/10.1016/j.poetic.2022.101732},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X22001140},
author = {Pablo Beytía and Hans-Peter Müller},
keywords = {Reflexive sociology, digital sociology, sociology of knowledge, computational social science, digital methods},
abstract = {We propose the development of 'digital reflexive sociology', understood as the use of digital methods and Big Data to reflect on the social and historical circumstances of sociologists and sociological thinking. To show this approach's potential, we employ Wikipedia as a ‘reflexive tool’, i.e., an external artefact of self-observation that can help sociologists to notice conventions, biases, and blind spots within their discipline. We analyse the collective patterns of the 500 most notable sociologists on Wikipedia, performing structural, network, and text analyses of their biographies. Our exploration reveals patterns in their historical frequency, gender composition, geographical concentration, birth-death mobility, centrality degree, biographical clustering, and proximity between countries, also stressing institutions, events, places, and relevant dates from a biographical point of view. Linking these patterns in a diachronic way, we distinguish five generations of sociologists recorded on Wikipedia and emphasise the high historical concentration of the discipline in geographical areas, gender, and schools of thought. Drawing on these results, we discuss the potential of using digital repositories and methods to enhance reflexivity within sociology.}
}
@incollection{YERPUDE2022335,
title = {CHAPTER FOURTEEN - Computational analysis of nanofluids-based drug delivery system: Preparation, current development and applications of nanofluids},
editor = {Shriram S. Sonawane and Hussein A. Mohammed and Arvind Kumar Mungray and Shirish H. Sonawane},
booktitle = {Applications of Nanofluids in Chemical and Bio-medical Process Industry},
publisher = {Elsevier},
pages = {335-364},
year = {2022},
isbn = {978-0-323-90564-0},
doi = {https://doi.org/10.1016/B978-0-323-90564-0.00014-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780323905640000143},
author = {S.T. Yerpude and A.K. Potbhare and P.R. Bhilkar and Parag Thakur and Pratiksha Khiratkar and Martin F. Desimone and P.R. Dhongle and Shriram S. Sonawane and Clara Goncalves and R.G. Chaudhary},
keywords = {CFD, Computational analysis, Drug delivery, Mathematical modeling, Nanofluids, Nano-drugs},
abstract = {Nanoparticles have been widely employed as a drug delivery carrier and a direct targeting agent. Off course, nanoparticles have been precisely and accurately designed to improve their therapeutical efficacy. Nowadays, computational modeling is frequently used to design novel and smart nanoparticles. In this chapter, we provide an overview and general idea about nanofluids in association with computational applications aimed at the improvement of nano-drug delivery coordination. Nanotechnology and nanobiotechnology-based conceptual innovations in combination with computational modeling are extensively employed in various areas of basic and applied sciences. On the same line, these technologies have a greater impact in the field of medicine and biology. We intended to look upon different aspects regarding nano-drugs and nanofluids comprising their preparation and stabilization methods and also focusing on mathematical modeling, stability mechanism, and biomedical applications of nanofluids. Similarly, imperative and special concern was given to the topic of computational fluid dynamics (CFD).}
}
@article{BELLO2025100031,
title = {Cloud computing for chatbot in the construction industry: An implementation framework for conversational-BIM voice assistant},
journal = {Digital Engineering},
volume = {5},
pages = {100031},
year = {2025},
issn = {2950-550X},
doi = {https://doi.org/10.1016/j.dte.2024.100031},
url = {https://www.sciencedirect.com/science/article/pii/S2950550X24000311},
author = {Sururah A. Bello and Lukumon O. Oyedele and Lukman A. Akanbi and Abdul-Lateef Bello},
keywords = {Software project management, Amazon web services, Cloud computing, Building information modelling (BIM), Conversational AI, Construction industry, Framework implementation, Chatbot, construction workers, Design thinking methodology, Focus group, Stakeholders management},
abstract = {This study presents a structural framework for selecting cloud services for the Conversational AI system implementation in the construction industry using Design Thinking Methodology. A focus group discussion approach was used to obtain user requirements from construction workers to implement the Conversational AI for BIM. This resulted in five factors: finance, speed of operation, privacy, estimation, and interface. The user specifications were mapped into technical modules, which were used to select cloud services employed to implement the virtual assistant for the construction industry. The study thus presented the comprehensive requirements for the different categories of construction workers to implement the Conversational-BIM Chatbot (Conversational-BIM) system. Furthermore, the study presented the architecture of Conversational-BIM using Amazon Web Services. The study is useful to researchers and IT developers in implementing chatbots for the construction industry as it presents the relevant considerations for conversational AI applications in the industry.}
}
@article{LEONARDI2018824,
title = {A Method for the computation of entropy in the Recurrence Quantification Analysis of categorical time series},
journal = {Physica A: Statistical Mechanics and its Applications},
volume = {512},
pages = {824-836},
year = {2018},
issn = {0378-4371},
doi = {https://doi.org/10.1016/j.physa.2018.08.058},
url = {https://www.sciencedirect.com/science/article/pii/S0378437118309981},
author = {Giuseppe Leonardi},
keywords = {Recurrence Quantification Analysis, Entropy, Categorical time series, Dynamical measures, Recurrence Plot},
abstract = {In this work, I propose a new method for the computation of informational entropy from Recurrence Plots when the analyzed time series are categorical in nature. In such cases, there is typically a simplification in choosing the parameters of the analysis, in the sense that no embedding in multidimensional space is usually assumed and that recurrence is restricted to exact matching (equivalence) of the numerically coded categories. However, such a simplified parameterization brings about some notable changes in the appearance of the obtained Recurrence Plots, which has consequences for the extraction of the standard dynamical measures. Specifically, a categorical Recurrence Plot is often composed of rectangular structures rather than line structures (diagonal and horizontal/vertical), over which the recurrence quantification measures were originally proposed. Starting from this observation, I consider alternative computational procedures to extract a non-biased measure of entropy for the categorical case, showing the viability of such a choice with simulated data}
}
@article{GEORGAKARAKOS2017291.e15,
title = {Custom-Made Conical Endograft in the Treatment of Saccular Abdominal Aortic Aneurysms with Tight and Calcified Distal Neck: Thinking Out of the Box},
journal = {Annals of Vascular Surgery},
volume = {39},
pages = {291.e15-291.e19},
year = {2017},
issn = {0890-5096},
doi = {https://doi.org/10.1016/j.avsg.2016.08.018},
url = {https://www.sciencedirect.com/science/article/pii/S0890509616312419},
author = {Efstratios Georgakarakos and Christos Argyriou and Nikolaos Schoretsanitis and George S. Georgiadis},
abstract = {Background
To describe the use of the combination of a conical custom-made TREO® (TREO CM) stent graft in the treatment of a saccular abdominal aortic endograft (AAA) with long but tight and calcified distal neck.
Materials and Methods
A 65-year-female patient was treated for a saccular 5.2 cm AAA with a 3-cm long but calcified and tight (16 mm) distal neck, precluding the safe use of a bifurcated endograft. Because the patient refused an open surgery, a conical TREO CM endograft was manufactured with 20% proximal oversizing, whereas the 3-cm caudal sealing segment demonstrated a conical configuration comprising a 2-cm and 1-cm nitinol-supported zones of 20% and 10% oversizing, respectively, to avoid excessive strain and incomplete expand at the most distal calcified area, leading ultimately to an insidious infolding and consequent type Ib endoleak. A 24 × 40 mm Treovance aortic cuff was centrally deployed resulting in a 30 mm overlap with the main endograft.
Results
After 6 months, there was complete sealing, and the AAA sac has been shrunk to 45 mm.
Conclusions
The use of a conical TREO CM endograft with a proximal cuff provides a firm fixation centrally and a sufficient distal sealing design in AAAs with calcified and tight distal aorta, constituting a reliable alternative to bifurcated endografts or aortouniliac configurations followed by crossover adjuncts.}
}
@article{YANG2013855,
title = {Computational Optimization, Modelling and Simulation: Recent Trends and Challenges},
journal = {Procedia Computer Science},
volume = {18},
pages = {855-860},
year = {2013},
note = {2013 International Conference on Computational Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2013.05.250},
url = {https://www.sciencedirect.com/science/article/pii/S1877050913003931},
author = {Xin-She Yang and Slawomir Koziel and Leifur Leifsson},
keywords = {algorithm, black-box modelling, computational optimization, optimization algorithm, modelling, metaheursitics, nonlinear optimization, stochastic optimization, surragate-based optimization, simulation ;},
abstract = {Modelling, simulation and optimization form an integrated part of modern design practice in engineering and industry. Tremendous progress has been observed for all three components over the last few decades. However, many challenging issues remain unresolved, and the current trends tend to use nature-inspired algorithms and surrogate-based techniques for modelling and optimization. This 4th workshop on Computational Optimization, Modelling and Simulation (COMS 2013) at ICCS 2013 will further summarize the latest developments of optimization and modelling and their applications in science, engineering and industry. In this review paper, we will analyse the recent trends in modelling and optimization, and their associated challenges. We will discuss important topics for further research, including parameter-tuning, large-scale problems, and the gaps between theory and applications.}
}
@article{MASELLI20235395,
title = {Computational analysis of five neurodegenerative diseases reveals shared and specific genetic loci},
journal = {Computational and Structural Biotechnology Journal},
volume = {21},
pages = {5395-5407},
year = {2023},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2023.10.031},
url = {https://www.sciencedirect.com/science/article/pii/S2001037023003835},
author = {Francesca Maselli and Salvatore D’Antona and Mattia Utichi and Matteo Arnaudi and Isabella Castiglioni and Danilo Porro and Elena Papaleo and Paolo Gandellini and Claudia Cava},
keywords = {Neurodegenerative diseases, Bioinformatics, GWAS, SNPs},
abstract = {Neurodegenerative diseases (ND) are heterogeneous disorders of the central nervous system that share a chronic and selective process of neuronal cell death. A computational approach to investigate shared genetic and specific loci was applied to 5 different ND: Amyotrophic lateral sclerosis (ALS), Alzheimer's disease (AD), Parkinson's disease (PD), Multiple sclerosis (MS), and Lewy body dementia (LBD). The datasets were analyzed separately, and then we compared the obtained results. For this purpose, we applied a genetic correlation analysis to genome-wide association datasets and revealed different genetic correlations with several human traits and diseases. In addition, a clumping analysis was carried out to identify SNPs genetically associated with each disease. We found 27 SNPs in AD, 6 SNPs in ALS, 10 SNPs in PD, 17 SNPs in MS, and 3 SNPs in LBD. Most of them are located in non-coding regions, with the exception of 5 SNPs on which a protein structure and stability prediction was performed to verify their impact on disease. Furthermore, an analysis of the differentially expressed miRNAs of the 5 examined pathologies was performed to reveal regulatory mechanisms that could involve genes associated with selected SNPs. In conclusion, the results obtained constitute an important step toward the discovery of diagnostic biomarkers and a better understanding of the diseases.}
}
@article{MISZTAL2017731,
title = {Invited review: efficient computation strategies in genomic selection},
journal = {Animal},
volume = {11},
number = {5},
pages = {731-736},
year = {2017},
issn = {1751-7311},
doi = {https://doi.org/10.1017/S1751731116002366},
url = {https://www.sciencedirect.com/science/article/pii/S1751731116002366},
author = {I. Misztal and A. Legarra},
keywords = {genomic selection, single-step, genomic relationship matrix, inverse, REML},
abstract = {The purpose of this study is review and evaluation of computing methods used in genomic selection for animal breeding. Commonly used models include SNP BLUP with extensions (BayesA, etc), genomic BLUP (GBLUP) and single-step GBLUP (ssGBLUP). These models are applied for genomewide association studies (GWAS), genomic prediction and parameter estimation. Solving methods include finite Cholesky decomposition possibly with a sparse implementation, and iterative Gauss–Seidel (GS) or preconditioned conjugate gradient (PCG), the last two methods possibly with iteration on data. Details are provided that can drastically decrease some computations. For SNP BLUP especially with sampling and large number of SNP, the only choice is GS with iteration on data and adjustment of residuals. If only solutions are required, PCG by iteration on data is a clear choice. A genomic relationship matrix (GRM) has limited dimensionality due to small effective population size, resulting in infinite number of generalized inverses of GRM for large genotyped populations. A specific inverse called APY requires only a small fraction of GRM, is sparse and can be computed and stored at a low cost for millions of animals. With APY inverse and PCG iteration, GBLUP and ssGBLUP can be applied to any population. Both tools can be applied to GWAS. When the system of equations is sparse but contains dense blocks, a recently developed package for sparse Cholesky decomposition and sparse inversion called YAMS has greatly improved performance over packages where such blocks were treated as sparse. With YAMS, GREML and possibly single-step GREML can be applied to populations with >50 000 genotyped animals. From a computational perspective, genomic selection is becoming a mature methodology.}
}
@article{VANDENBOS201842,
title = {Computational neuroscience across the lifespan: Promises and pitfalls},
journal = {Developmental Cognitive Neuroscience},
volume = {33},
pages = {42-53},
year = {2018},
note = {Methodological Challenges in Developmental Neuroimaging: Contemporary Approaches and Solutions},
issn = {1878-9293},
doi = {https://doi.org/10.1016/j.dcn.2017.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S1878929317301068},
author = {Wouter {van den Bos} and Rasmus Bruckner and Matthew R. Nassar and Rui Mata and Ben Eppinger},
keywords = {Computational neuroscience, Reinforcement learning, Risk-taking, Decision-making, Brain development, Identification, Strategies},
abstract = {In recent years, the application of computational modeling in studies on age-related changes in decision making and learning has gained in popularity. One advantage of computational models is that they provide access to latent variables that cannot be directly observed from behavior. In combination with experimental manipulations, these latent variables can help to test hypotheses about age-related changes in behavioral and neurobiological measures at a level of specificity that is not achievable with descriptive analysis approaches alone. This level of specificity can in turn be beneficial to establish the identity of the corresponding behavioral and neurobiological mechanisms. In this paper, we will illustrate applications of computational methods using examples of lifespan research on risk taking, strategy selection and reinforcement learning. We will elaborate on problems that can occur when computational neuroscience methods are applied to data of different age groups. Finally, we will discuss potential targets for future applications and outline general shortcomings of computational neuroscience methods for research on human lifespan development.}
}
@incollection{PHIPPEN20253,
title = {Artificial Intelligence},
editor = {David Baker and Lucy Ellis},
booktitle = {Encyclopedia of Libraries, Librarianship, and Information Science (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {3-11},
year = {2025},
isbn = {978-0-323-95690-1},
doi = {https://doi.org/10.1016/B978-0-323-95689-5.00098-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780323956895000985},
author = {Andy Phippen},
keywords = {Artificial intelligence, Computer science, Deep learning, Digital literacy, Ethics, Information science, Large language models, Machine learning, Natural language processing},
abstract = {Artificial Intelligence (AI) is attracting considerable, and justified, attention about its potential and impact on information systems. However, it is important to look at this evolution against its history. AI’s historical evolution has been beset with underperformance and ethical concerns in data training and responsible deployment. Information science has undergone significant changes with AI׳s integration, impacting information retrieval, classification, and library automation. More specifically Machine Learning plays a crucial role in understanding human requirements for information and processing large data set, but challenges like bias persist. Large Language Models (LLMs) like ChatGPT represent the vanguard of public adoption of AI driven information systems and have exhibited remarkable performance in natural language processing. While they enhance information searching and content creation, users must understand limitations, biases, and practice critical thinking for responsible utilisation in a digital age.}
}
@incollection{PENN2006338,
title = {Symbolic Computational Linguistics: Overview},
editor = {Keith Brown},
booktitle = {Encyclopedia of Language & Linguistics (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {338-352},
year = {2006},
isbn = {978-0-08-044854-1},
doi = {https://doi.org/10.1016/B0-08-044854-2/00875-0},
url = {https://www.sciencedirect.com/science/article/pii/B0080448542008750},
author = {G. Penn},
keywords = {computational linguistics, concept ontologies, lambda calculus, logic, phrase structure trees, typed feature structures},
abstract = {Symbolic computational linguistics is a diverse body of research that uses logical, graphical and other discrete mathematical representations to model structure and meaning at the various levels of linguistic investigation. This article provides an informal introduction to these representations, along with a discussion of their applications.}
}
@incollection{BARTHEYE2020385,
title = {Chapter 19 - Human-machine sense making in context-based computational decision},
editor = {William F. Lawless and Ranjeev Mittu and Donald A. Sofge},
booktitle = {Human-Machine Shared Contexts},
publisher = {Academic Press},
pages = {385-398},
year = {2020},
isbn = {978-0-12-820543-3},
doi = {https://doi.org/10.1016/B978-0-12-820543-3.00019-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128205433000195},
author = {Olivier Bartheye and Laurent Chaudron},
keywords = {Human/machine sense making, Knowledge processing, Decision mechanism, Causal break, Hopf algebras, Computational contexts, Continuous inference},
abstract = {In this chapter, we present what should be the inner structure of a decision algebra whose motivation is to fill a causal break induced by context invalidity to ultimately permit human-machine interactions. It turns out that such a decision structure can be qualified using the context change arrow as a disruptive process or as a phase transition according to the geometrical representation of computational contexts as double S-curves. In particular a computational context is always characterized by a shift between sense making and temporal causality. That is, once a causal break occurs, it has to be filled locally by a decision. A causal break is always continuous and never discrete; in effect, in the discrete case, combinatoric analysis causes unwanted complexity due to a lack of knowledge, whereas we need full knowledge thanks to a very precise semantic of a causal break. Intuitively, rather than separating brutally models and counter-models as a proof can do by setting a strong negation operator, we prefer to use the continuous inference as an implementation of sense making. Sense is that way taken as the rationality of the transition. Full knowledge requires a special structure, a Hopf algebra in which the continuous property we cannot implement is replaced by the computable co-continuous property in the co-algebraic component of the decision Hopf algebra. We hope that thanks to co-continuous structures and to co-dimensional exterior algebras, we’ll be able to find out a representation of the continuous inference able to compute a decision rather than admitting definitely and desperately that “such a mechanism is totally out of bounds” and will never ever concern a machine.}
}
@article{SCHORLEMMER2021118,
title = {A uniform model of computational conceptual blending},
journal = {Cognitive Systems Research},
volume = {65},
pages = {118-137},
year = {2021},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2020.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S1389041720300759},
author = {Marco Schorlemmer and Enric Plaza},
keywords = {Conceptual blending, Computational creativity, Amalgams, Category theory, Case-based reasoning},
abstract = {We present a mathematical model for the cognitive operation of conceptual blending that aims at being uniform across different representation formalisms, while capturing the relevant structure of this operation. The model takes its inspiration from amalgams as applied in case-based reasoning, but lifts them into category theory so as to follow Joseph Goguen’s intuition for a mathematically precise characterisation of conceptual blending at a representation-independent level of abstraction. We prove that our amalgam-based category-theoretical model of conceptual blending is essentially equivalent to the pushout model in the ordered category of partial maps as put forward by Goguen. But unlike Goguen’s approach, our model is more suitable to capture computational realisations of conceptual blending, and we exemplify this by concretising our model to computational conceptual blends for various representation formalisms and application domains.}
}
@incollection{OREILLY2019317,
title = {Chapter 17 - Computational models of motivated frontal function},
editor = {Mark D'Esposito and Jordan H. Grafman},
series = {Handbook of Clinical Neurology},
publisher = {Elsevier},
volume = {163},
pages = {317-332},
year = {2019},
booktitle = {The Frontal Lobes},
issn = {0072-9752},
doi = {https://doi.org/10.1016/B978-0-12-804281-6.00017-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128042816000173},
author = {Randall C. O’Reilly and Jacob Russin and Seth A. Herd},
keywords = {Computational models, Frontal cortex, Basal ganglia, Goal-directed, Motivation, Working memory, Reinforcement learning},
abstract = {Computational models of frontal function have made important contributions to understanding how the frontal lobes support a wide range of important functions, in their interactions with other brain areas including, critically, the basal ganglia (BG). We focus here on the specific case of how different frontal areas support goal-directed, motivated decision-making, by representing three essential types of information: possible plans of action (in more dorsal and lateral frontal areas), affectively significant outcomes of those action plans (in ventral, medial frontal areas including the orbital frontal cortex), and the overall utility of a given plan compared to other possible courses of action (in anterior cingulate cortex). Computational models of goal-directed action selection at multiple different levels of analysis provide insight into the nature of learning and processing in these areas and the relative contributions of the frontal cortex versus the BG. The most common neurologic disorders implicate these areas, and understanding their precise function and modes of dysfunction can contribute to the new field of computational psychiatry, within the broader field of computational neuroscience.}
}
@article{ZHOU2025100904,
title = {Exploring the development of pre-service teachers' epistemic agency in Chinese University knowledge building community},
journal = {Learning, Culture and Social Interaction},
volume = {52},
pages = {100904},
year = {2025},
issn = {2210-6561},
doi = {https://doi.org/10.1016/j.lcsi.2025.100904},
url = {https://www.sciencedirect.com/science/article/pii/S2210656125000236},
author = {Fuying Zhou and Shaoming Chai and Zhenhai He and Han Wu},
keywords = {Epistemic agency, Knowledge Building Community, Cognitive conflict, Teacher education},
abstract = {Epistemic agency, the capacity to effectively engage with knowledge and understand its nature, is crucial for successful learning and problem-solving in today's complex world. This study explores the non-linear development of epistemic agency among pre-service teachers engaged in principle-based Knowledge Building (KB) activities on the Knowledge Forum (KF) platform within a Chinese university setting. By analyzing interaction data, notes, and reflective reports from 38 participants, the findings reveal a positive correlation between the development of epistemic agency and strategies for handling cognitive conflicts. The research highlights a transition from reliance on authoritative knowledge to confidence in personal KB, and from simplistic understanding of problems to critical thinking about complex issues. These insights provide empirical support for the design of teacher education curricula, emphasizing the importance of creating opportunities for pre-service teachers to manage cognitive conflicts, thereby fostering their growth in epistemic agency.}
}
@article{NEWHALL2025105044,
title = {An introductory-level undergraduate CS course that introduces parallel computing},
journal = {Journal of Parallel and Distributed Computing},
volume = {199},
pages = {105044},
year = {2025},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2025.105044},
url = {https://www.sciencedirect.com/science/article/pii/S0743731525000115},
author = {Tia Newhall and Kevin C. Webb and Vasanta Chaganti and Andrew Danner},
keywords = {CS curriculum, Parallel computing, Introductory CS},
abstract = {We present the curricular design, pedagogy, and goals of an introductory-level course on computer systems that introduces parallel and distributed computing (PDC) to students who have only a CS1 background. With the ubiquity of multicore processors, cloud computing, and hardware accelerators, PDC topics have become fundamental knowledge areas in the undergraduate CS curriculum. As a result, it is increasingly important for students to learn a common core of introductory parallel and distributed computing topics and to develop parallel thinking skills early in their CS studies. Our introductory-level course focuses on three main curricular goals: 1) understanding how a computer runs a program, 2) evaluating system costs associated with running a program, and 3) taking advantage of the power of parallel computing. We elaborate on the goals and details of our course's key modules, and we discuss our pedagogical approach that includes active-learning techniques. We also include an evaluation of our course and a discussion of our experiences teaching it since Fall 2012. We find that the PDC foundation gained through early exposure in our course helps students gain confidence in their ability to expand and apply their understanding of PDC concepts throughout their CS education.}
}
@article{SNIDER2021108795,
title = {Reinforcer pathology in cocaine use disorder: Temporal window determines cocaine valuation},
journal = {Drug and Alcohol Dependence},
volume = {225},
pages = {108795},
year = {2021},
issn = {0376-8716},
doi = {https://doi.org/10.1016/j.drugalcdep.2021.108795},
url = {https://www.sciencedirect.com/science/article/pii/S0376871621002908},
author = {Sarah E. Snider and Jamie K. Turner and Samuel M. McClure and Warren K. Bickel},
keywords = {Reinforcer pathology, Experimental medicine approach, Episodic future thinking, Delay discounting, Behavioral economic demand, Cocaine use disorder},
abstract = {Aims
The Experimental Medicine Approach offers a unique perspective to determine clinical behavior change by engaging a target underlying the cause of a disorder. The present work engaged a novel target of addiction, Reinforcer Pathology, in two studies to test changes in behavior among individuals with cocaine use disorder.
Methods
In Study 1, n = 44 participants engaged the temporal window with episodic future thinking (EFT), a positive prospection exercise. Changes in temporal view and cocaine valuation were tested using delay discounting and behavioral economic demand, respectively. Additionally, a computational model assessed the relative reliance on the near- and far-sighted systems during EFT. In Study 2, n = 71 engaged the temporal window with a negatively-valenced hurricane scenario to test the opposite effects on window length and cocaine valuation.
Results
Results demonstrated systematic and symmetrical engagement of the behavioral target. Study 1 robustly replicated previous work, wherein EFT lengthened the temporal window and decreased cocaine valuation. Moreover, EFT increased the weighting of the modeled far-sighted system, increasing the relative impact of long-term discounting decisions. Study 2 produced opposite outcomes, shortened temporal window and increased cocaine valuation.
Conclusions
This approximately equal and opposite reaction to the manipulations supports reinforcer pathology theory and implicates the temporal window over which rewards are valued as a target to be pushed and pulled to produce clinically meaningful behavior change. Using the Experimental Medicine Approach as a guide, future work should identify new potential interventions to engage reinforcer pathology and use the clinically relevant outcomes as a litmus test for mechanism.}
}